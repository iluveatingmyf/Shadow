diff -urN -x __pycache__ -x '*.pyc' /tmp/homeassistant-2024.1.5/homeassistant/components/automation/__init__-bk-1224.py /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/components/automation/__init__-bk-1224.py
--- /tmp/homeassistant-2024.1.5/homeassistant/components/automation/__init__-bk-1224.py	1970-01-01 08:00:00.000000000 +0800
+++ /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/components/automation/__init__-bk-1224.py	2025-12-24 22:05:48.384820011 +0800
@@ -0,0 +1,1202 @@
+"""Allow to set up simple automation rules via the config file."""
+from __future__ import annotations
+#from homeassistant.helpers.provenance
+from homeassistant.util.dt import parse_datetime
+
+#lqg tag
+from homeassistant.helpers.provenance import(
+    log_trigger
+)
+
+
+import logging
+_LOGGER = logging.getLogger(__name__)
+
+
+RELATION_TYPE_WAS_ASSOCIATED_WITH = "wasAssociateWith"  # 活动与代理关联
+
+from abc import ABC, abstractmethod
+import asyncio
+from collections.abc import Callable, Mapping
+from dataclasses import dataclass
+from functools import partial
+import logging
+from typing import Any, Protocol, cast
+
+import voluptuous as vol
+
+from homeassistant.components import websocket_api
+from homeassistant.components.blueprint import CONF_USE_BLUEPRINT
+from homeassistant.const import (
+    ATTR_ENTITY_ID,
+    ATTR_MODE,
+    ATTR_NAME,
+    CONF_ALIAS,
+    CONF_CONDITION,
+    CONF_DEVICE_ID,
+    CONF_ENTITY_ID,
+    CONF_EVENT_DATA,
+    CONF_ID,
+    CONF_MODE,
+    CONF_PATH,
+    CONF_PLATFORM,
+    CONF_VARIABLES,
+    CONF_ZONE,
+    EVENT_HOMEASSISTANT_STARTED,
+    SERVICE_RELOAD,
+    SERVICE_TOGGLE,
+    SERVICE_TURN_OFF,
+    SERVICE_TURN_ON,
+    STATE_ON,
+)
+from homeassistant.core import (
+    CALLBACK_TYPE,
+    Context,
+    CoreState,
+    Event,
+    HomeAssistant,
+    ServiceCall,
+    callback,
+    split_entity_id,
+    valid_entity_id,
+)
+from homeassistant.exceptions import (
+    ConditionError,
+    ConditionErrorContainer,
+    ConditionErrorIndex,
+    HomeAssistantError,
+    ServiceNotFound,
+    TemplateError,
+)
+from homeassistant.helpers import condition
+import homeassistant.helpers.config_validation as cv
+from homeassistant.helpers.deprecation import (
+    DeprecatedConstant,
+    all_with_deprecated_constants,
+    check_if_deprecated_constant,
+    dir_with_deprecated_constants,
+)
+from homeassistant.helpers.entity import ToggleEntity
+from homeassistant.helpers.entity_component import EntityComponent
+from homeassistant.helpers.issue_registry import IssueSeverity, async_create_issue
+from homeassistant.helpers.restore_state import RestoreEntity
+from homeassistant.helpers.script import (
+    ATTR_CUR,
+    ATTR_MAX,
+    CONF_MAX,
+    CONF_MAX_EXCEEDED,
+    Script,
+    script_stack_cv,
+)
+from homeassistant.helpers.script_variables import ScriptVariables
+from homeassistant.helpers.service import (
+    ReloadServiceHelper,
+    async_register_admin_service,
+)
+from homeassistant.helpers.trace import (
+    TraceElement,
+    script_execution_set,
+    trace_append_element,
+    trace_get,
+    trace_path,
+)
+from homeassistant.helpers.trigger import (
+    TriggerActionType,
+    TriggerData,
+    TriggerInfo,
+    async_initialize_triggers,
+)
+from homeassistant.helpers.typing import ConfigType
+from homeassistant.loader import bind_hass
+from homeassistant.util.dt import parse_datetime
+
+from .config import AutomationConfig
+from .const import (
+    CONF_ACTION,
+    CONF_INITIAL_STATE,
+    CONF_TRACE,
+    CONF_TRIGGER,
+    CONF_TRIGGER_VARIABLES,
+    DEFAULT_INITIAL_STATE,
+    DOMAIN,
+    LOGGER,
+)
+from .helpers import async_get_blueprints
+from .trace import trace_automation
+
+ENTITY_ID_FORMAT = DOMAIN + ".{}"
+
+
+CONF_SKIP_CONDITION = "skip_condition"
+CONF_STOP_ACTIONS = "stop_actions"
+DEFAULT_STOP_ACTIONS = True
+
+EVENT_AUTOMATION_RELOADED = "automation_reloaded"
+EVENT_AUTOMATION_TRIGGERED = "automation_triggered"
+
+ATTR_LAST_TRIGGERED = "last_triggered"
+ATTR_SOURCE = "source"
+ATTR_VARIABLES = "variables"
+SERVICE_TRIGGER = "trigger"
+
+
+class IfAction(Protocol):
+    """Define the format of if_action."""
+
+    config: list[ConfigType]
+
+    def __call__(self, variables: Mapping[str, Any] | None = None) -> bool:
+        """AND all conditions."""
+
+
+# AutomationActionType, AutomationTriggerData,
+# and AutomationTriggerInfo are deprecated as of 2022.9.
+# Can be removed in 2025.1
+_DEPRECATED_AutomationActionType = DeprecatedConstant(
+    TriggerActionType, "TriggerActionType", "2025.1"
+)
+_DEPRECATED_AutomationTriggerData = DeprecatedConstant(
+    TriggerData, "TriggerData", "2025.1"
+)
+_DEPRECATED_AutomationTriggerInfo = DeprecatedConstant(
+    TriggerInfo, "TriggerInfo", "2025.1"
+)
+
+
+@bind_hass
+def is_on(hass: HomeAssistant, entity_id: str) -> bool:
+    """Return true if specified automation entity_id is on.
+
+    Async friendly.
+    """
+    return hass.states.is_state(entity_id, STATE_ON)
+
+
+def _automations_with_x(
+    hass: HomeAssistant, referenced_id: str, property_name: str
+) -> list[str]:
+    """Return all automations that reference the x."""
+    if DOMAIN not in hass.data:
+        return []
+
+    component: EntityComponent[BaseAutomationEntity] = hass.data[DOMAIN]
+
+    return [
+        automation_entity.entity_id
+        for automation_entity in component.entities
+        if referenced_id in getattr(automation_entity, property_name)
+    ]
+
+
+def _x_in_automation(
+    hass: HomeAssistant, entity_id: str, property_name: str
+) -> list[str]:
+    """Return all x in an automation."""
+    if DOMAIN not in hass.data:
+        return []
+
+    component: EntityComponent[BaseAutomationEntity] = hass.data[DOMAIN]
+
+    if (automation_entity := component.get_entity(entity_id)) is None:
+        return []
+
+    return list(getattr(automation_entity, property_name))
+
+
+@callback
+def automations_with_entity(hass: HomeAssistant, entity_id: str) -> list[str]:
+    """Return all automations that reference the entity."""
+    return _automations_with_x(hass, entity_id, "referenced_entities")
+
+
+@callback
+def entities_in_automation(hass: HomeAssistant, entity_id: str) -> list[str]:
+    """Return all entities in an automation."""
+    return _x_in_automation(hass, entity_id, "referenced_entities")
+
+
+@callback
+def automations_with_device(hass: HomeAssistant, device_id: str) -> list[str]:
+    """Return all automations that reference the device."""
+    return _automations_with_x(hass, device_id, "referenced_devices")
+
+
+@callback
+def devices_in_automation(hass: HomeAssistant, entity_id: str) -> list[str]:
+    """Return all devices in an automation."""
+    return _x_in_automation(hass, entity_id, "referenced_devices")
+
+
+@callback
+def automations_with_area(hass: HomeAssistant, area_id: str) -> list[str]:
+    """Return all automations that reference the area."""
+    return _automations_with_x(hass, area_id, "referenced_areas")
+
+
+@callback
+def areas_in_automation(hass: HomeAssistant, entity_id: str) -> list[str]:
+    """Return all areas in an automation."""
+    return _x_in_automation(hass, entity_id, "referenced_areas")
+
+
+@callback
+def automations_with_blueprint(hass: HomeAssistant, blueprint_path: str) -> list[str]:
+    """Return all automations that reference the blueprint."""
+    if DOMAIN not in hass.data:
+        return []
+
+    component: EntityComponent[BaseAutomationEntity] = hass.data[DOMAIN]
+
+    return [
+        automation_entity.entity_id
+        for automation_entity in component.entities
+        if automation_entity.referenced_blueprint == blueprint_path
+    ]
+
+
+@callback
+def blueprint_in_automation(hass: HomeAssistant, entity_id: str) -> str | None:
+    """Return the blueprint the automation is based on or None."""
+    if DOMAIN not in hass.data:
+        return None
+
+    component: EntityComponent[BaseAutomationEntity] = hass.data[DOMAIN]
+
+    if (automation_entity := component.get_entity(entity_id)) is None:
+        return None
+
+    return automation_entity.referenced_blueprint
+
+
+async def async_setup(hass: HomeAssistant, config: ConfigType) -> bool:
+    """Set up all automations."""
+    hass.data[DOMAIN] = component = EntityComponent[BaseAutomationEntity](
+        LOGGER, DOMAIN, hass
+    )
+
+    # Register automation as valid domain for Blueprint
+    async_get_blueprints(hass)
+
+    await _async_process_config(hass, config, component)
+
+    # Add some default blueprints to blueprints/automation, does nothing
+    # if blueprints/automation already exists
+    await async_get_blueprints(hass).async_populate()
+
+    async def trigger_service_handler(
+        entity: BaseAutomationEntity, service_call: ServiceCall
+    ) -> None:
+        """Handle forced automation trigger, e.g. from frontend."""
+        await entity.async_trigger(
+            {**service_call.data[ATTR_VARIABLES], "trigger": {"platform": None}},
+            skip_condition=service_call.data[CONF_SKIP_CONDITION],
+            context=service_call.context,
+        )
+
+    component.async_register_entity_service(
+        SERVICE_TRIGGER,
+        {
+            vol.Optional(ATTR_VARIABLES, default={}): dict,
+            vol.Optional(CONF_SKIP_CONDITION, default=True): bool,
+        },
+        trigger_service_handler,
+    )
+    component.async_register_entity_service(SERVICE_TOGGLE, {}, "async_toggle")
+    component.async_register_entity_service(SERVICE_TURN_ON, {}, "async_turn_on")
+    component.async_register_entity_service(
+        SERVICE_TURN_OFF,
+        {vol.Optional(CONF_STOP_ACTIONS, default=DEFAULT_STOP_ACTIONS): cv.boolean},
+        "async_turn_off",
+    )
+
+    async def reload_service_handler(service_call: ServiceCall) -> None:
+        """Remove all automations and load new ones from config."""
+        await async_get_blueprints(hass).async_reset_cache()
+        if (conf := await component.async_prepare_reload(skip_reset=True)) is None:
+            return
+        await _async_process_config(hass, conf, component)
+        hass.bus.async_fire(EVENT_AUTOMATION_RELOADED, context=service_call.context)
+
+    reload_helper = ReloadServiceHelper(reload_service_handler)
+
+    async_register_admin_service(
+        hass,
+        DOMAIN,
+        SERVICE_RELOAD,
+        reload_helper.execute_service,
+        schema=vol.Schema({}),
+    )
+
+    websocket_api.async_register_command(hass, websocket_config)
+
+    return True
+
+
+class BaseAutomationEntity(ToggleEntity, ABC):
+    """Base class for automation entities."""
+
+    _entity_component_unrecorded_attributes = frozenset(
+        (ATTR_LAST_TRIGGERED, ATTR_MODE, ATTR_CUR, ATTR_MAX, CONF_ID)
+    )
+    raw_config: ConfigType | None
+
+    @property
+    def capability_attributes(self) -> dict[str, Any] | None:
+        """Return capability attributes."""
+        if self.unique_id is not None:
+            return {CONF_ID: self.unique_id}
+        return None
+
+    @property
+    @abstractmethod
+    def referenced_areas(self) -> set[str]:
+        """Return a set of referenced areas."""
+
+    @property
+    @abstractmethod
+    def referenced_blueprint(self) -> str | None:
+        """Return referenced blueprint or None."""
+
+    @property
+    @abstractmethod
+    def referenced_devices(self) -> set[str]:
+        """Return a set of referenced devices."""
+
+    @property
+    @abstractmethod
+    def referenced_entities(self) -> set[str]:
+        """Return a set of referenced entities."""
+
+    @abstractmethod
+    async def async_trigger(
+        self,
+        run_variables: dict[str, Any],
+        context: Context | None = None,
+        skip_condition: bool = False,
+    ) -> None:
+        """Trigger automation."""
+
+
+class UnavailableAutomationEntity(BaseAutomationEntity):
+    """A non-functional automation entity with its state set to unavailable.
+
+    This class is instatiated when an automation fails to validate.
+    """
+
+    _attr_should_poll = False
+    _attr_available = False
+
+    def __init__(
+        self,
+        automation_id: str | None,
+        name: str,
+        raw_config: ConfigType | None,
+    ) -> None:
+        """Initialize an automation entity."""
+        self._name = name
+        self._attr_unique_id = automation_id
+        self.raw_config = raw_config
+
+    @property
+    def name(self) -> str:
+        """Return the name of the entity."""
+        return self._name
+
+    @property
+    def referenced_areas(self) -> set[str]:
+        """Return a set of referenced areas."""
+        return set()
+
+    @property
+    def referenced_blueprint(self) -> str | None:
+        """Return referenced blueprint or None."""
+        return None
+
+    @property
+    def referenced_devices(self) -> set[str]:
+        """Return a set of referenced devices."""
+        return set()
+
+    @property
+    def referenced_entities(self) -> set[str]:
+        """Return a set of referenced entities."""
+        return set()
+
+    async def async_trigger(
+        self,
+        run_variables: dict[str, Any],
+        context: Context | None = None,
+        skip_condition: bool = False,
+    ) -> None:
+        """Trigger automation."""
+
+
+class AutomationEntity(BaseAutomationEntity, RestoreEntity):
+    """Entity to show status of entity."""
+
+    _attr_should_poll = False
+
+    def __init__(
+        self,
+        automation_id: str | None,
+        name: str,
+        trigger_config: list[ConfigType],
+        cond_func: IfAction | None,
+        action_script: Script,
+        initial_state: bool | None,
+        variables: ScriptVariables | None,
+        trigger_variables: ScriptVariables | None,
+        raw_config: ConfigType | None,
+        blueprint_inputs: ConfigType | None,
+        trace_config: ConfigType,
+    ) -> None:
+        """Initialize an automation entity."""
+        self._name = name
+        self._trigger_config = trigger_config
+        self._async_detach_triggers: CALLBACK_TYPE | None = None
+        self._cond_func = cond_func
+        self.action_script = action_script
+        self.action_script.change_listener = self.async_write_ha_state
+        self._initial_state = initial_state
+        self._is_enabled = False
+        self._referenced_entities: set[str] | None = None
+        self._referenced_devices: set[str] | None = None
+        self._logger = LOGGER
+        self._variables = variables
+        self._trigger_variables = trigger_variables
+        self.raw_config = raw_config
+        self._blueprint_inputs = blueprint_inputs
+        self._trace_config = trace_config
+        self._attr_unique_id = automation_id
+
+    #lqg add
+    @property
+    def agent_id(self) -> str:
+        """生成自动化的唯一agent标识"""
+        return f"automation.{self.unique_id or self.entity_id}"  # 确保唯一性
+
+    @property
+    def name(self) -> str:
+        """Return the name of the entity."""
+        return self._name
+
+    @property
+    def extra_state_attributes(self) -> dict[str, Any]:
+        """Return the entity state attributes."""
+        attrs = {
+            ATTR_LAST_TRIGGERED: self.action_script.last_triggered,
+            ATTR_MODE: self.action_script.script_mode,
+            ATTR_CUR: self.action_script.runs,
+        }
+        if self.action_script.supports_max:
+            attrs[ATTR_MAX] = self.action_script.max_runs
+        return attrs
+
+    @property
+    def is_on(self) -> bool:
+        """Return True if entity is on."""
+        return self._async_detach_triggers is not None or self._is_enabled
+
+    @property
+    def referenced_areas(self) -> set[str]:
+        """Return a set of referenced areas."""
+        return self.action_script.referenced_areas
+
+    @property
+    def referenced_blueprint(self) -> str | None:
+        """Return referenced blueprint or None."""
+        if self._blueprint_inputs is None:
+            return None
+        return cast(str, self._blueprint_inputs[CONF_USE_BLUEPRINT][CONF_PATH])
+
+    @property
+    def referenced_devices(self) -> set[str]:
+        """Return a set of referenced devices."""
+        if self._referenced_devices is not None:
+            return self._referenced_devices
+
+        referenced = self.action_script.referenced_devices
+
+        if self._cond_func is not None:
+            for conf in self._cond_func.config:
+                referenced |= condition.async_extract_devices(conf)
+
+        for conf in self._trigger_config:
+            referenced |= set(_trigger_extract_devices(conf))
+
+        self._referenced_devices = referenced
+        return referenced
+
+    @property
+    def referenced_entities(self) -> set[str]:
+        """Return a set of referenced entities."""
+        if self._referenced_entities is not None:
+            return self._referenced_entities
+
+        referenced = self.action_script.referenced_entities
+
+        if self._cond_func is not None:
+            for conf in self._cond_func.config:
+                referenced |= condition.async_extract_entities(conf)
+
+        for conf in self._trigger_config:
+            for entity_id in _trigger_extract_entities(conf):
+                referenced.add(entity_id)
+
+        self._referenced_entities = referenced
+        return referenced
+
+    async def async_added_to_hass(self) -> None:
+        """Startup with initial state or previous state."""
+        await super().async_added_to_hass()
+
+        self._logger = logging.getLogger(
+            f"{__name__}.{split_entity_id(self.entity_id)[1]}"
+        )
+        self.action_script.update_logger(self._logger)
+
+        if state := await self.async_get_last_state():
+            enable_automation = state.state == STATE_ON
+            last_triggered = state.attributes.get("last_triggered")
+            if last_triggered is not None:
+                self.action_script.last_triggered = parse_datetime(last_triggered)
+            self._logger.debug(
+                "Loaded automation %s with state %s from state storage last state %s",
+                self.entity_id,
+                enable_automation,
+                state,
+            )
+        else:
+            enable_automation = DEFAULT_INITIAL_STATE
+            self._logger.debug(
+                "Automation %s not in state storage, state %s from default is used",
+                self.entity_id,
+                enable_automation,
+            )
+
+        if self._initial_state is not None:
+            enable_automation = self._initial_state
+            self._logger.debug(
+                "Automation %s initial state %s overridden from config initial_state",
+                self.entity_id,
+                enable_automation,
+            )
+
+        if enable_automation:
+            await self.async_enable()
+
+    async def async_turn_on(self, **kwargs: Any) -> None:
+        """Turn the entity on and update the state."""
+        await self.async_enable()
+
+    async def async_turn_off(self, **kwargs: Any) -> None:
+        """Turn the entity off."""
+        if CONF_STOP_ACTIONS in kwargs:
+            await self.async_disable(kwargs[CONF_STOP_ACTIONS])
+        else:
+            await self.async_disable()
+
+    async def async_trigger(
+        self,
+        run_variables: dict[str, Any],
+        context: Context | None = None,
+        skip_condition: bool = False,
+    ) -> None:
+        """Trigger automation.
+
+        This method is a coroutine.
+        """
+        reason = ""
+        alias = ""
+        if "trigger" in run_variables:
+            if "description" in run_variables["trigger"]:
+                reason = f' by {run_variables["trigger"]["description"]}'
+            if "alias" in run_variables["trigger"]:
+                alias = f' trigger \'{run_variables["trigger"]["alias"]}\''
+        self._logger.debug("Automation%s triggered%s", alias, reason)
+
+        # Create a new context referring to the old context.
+        parent_id = None if context is None else context.id
+        trigger_context = Context(parent_id=parent_id)
+
+        # ========== 新增：调用 log_trigger 记录 Agent 事件 ==========
+        agent_event_id = None
+        try:
+            trigger_data = run_variables.get('trigger', {})
+            # 1. 提取触发源实体ID（支持实体触发和非实体触发）
+            entity_name = trigger_data.get('entity_id')
+            if not entity_name:
+                # 非实体触发（如时间、手动触发），用触发平台作为标识
+                entity_name = f"trigger.{trigger_data.get('platform', 'unknown')}"  # 如 "trigger.time"
+                from_state = "idle"
+                to_state = "triggered"
+            else:
+                # 实体触发，提取新旧状态
+                entity_from_state = trigger_data.get('from_state')
+                entity_to_state = trigger_data.get('to_state')
+                from_state = entity_from_state.state if entity_from_state else ""
+                to_state = entity_to_state.state if entity_to_state else ""
+
+            # 核心：判断是否是根因 (Root Cause)
+            # 如果 parent_id 是 None，或者 user_id 存在，通常是起点
+            is_start_point = (trigger_context.parent_id is None) or (trigger_context.user_id is not None)
+
+            
+            # 3. 修正 automation_id：使用实体公开的 unique_id（与状态机中一致）
+            automation_id = self.unique_id
+            # 4. 调用 log_trigger 记录 Agent 事件
+            agent_event_id = log_trigger(
+                action = "triggered",
+                entity_id=entity_name,
+                state=to_state,
+                automation_name = self.entity_id,
+                #automation_name=self.name or self.entity_id,
+                context=trigger_context,  # 传递当前自动化触发的上下文
+                automation_id=automation_id,
+                sequence=self.action_script.sequence,  # 传递动作序列，用于跟踪后续命令
+                is_start_point=if_start_point
+            )
+            _LOGGER.warning("Automation {automation_id} triggered by {entity_name} (state: {from_state}→{to_state})")
+            
+            self._logger.debug(
+                f"Automation {automation_id} triggered by {self.entity_id} (state: {from_state}→{to_state})"
+            )
+
+        except Exception as e:
+            self._logger.error(f"Provenance tracking error: {e}")
+        #——————————————————————————————————————————————
+        with trace_automation(
+            self.hass,
+            self.unique_id,
+            self.raw_config,
+            self._blueprint_inputs,
+            trigger_context,
+            self._trace_config,
+        ) as automation_trace:
+            this = None
+            if state := self.hass.states.get(self.entity_id):
+                this = state.as_dict()
+            #variables: dict[str, Any] = {"this": this, **(run_variables or {})}
+            #lqg tag
+            #注入 automation_id 和 context 到变量，供下游使用
+            variables: dict[str, Any] = {
+                "this": this,
+                **(run_variables or {}),
+                # 新增：传递自动化ID和触发上下文给条件/命令
+                "automation_id": self.unique_id,  # 供 condition.py/script.py 关联事件
+                "trigger_context": trigger_context,  # 供下游事件复用上下文
+                "agent_event_id": agent_event_id
+            }
+            if self._variables:
+                try:
+                    variables = self._variables.async_render(self.hass, variables)
+                except TemplateError as err:
+                    self._logger.error("Error rendering variables: %s", err)
+                    automation_trace.set_error(err)
+                    return
+
+            # Prepare tracing the automation
+            automation_trace.set_trace(trace_get())
+
+            # Set trigger reason
+            trigger_description = variables.get("trigger", {}).get("description")
+            automation_trace.set_trigger_description(trigger_description)
+
+            # Add initial variables as the trigger step
+            if "trigger" in variables and "idx" in variables["trigger"]:
+                trigger_path = f"trigger/{variables['trigger']['idx']}"
+            else:
+                trigger_path = "trigger"
+            trace_element = TraceElement(variables, trigger_path)
+            trace_append_element(trace_element)
+
+            if (
+                not skip_condition
+                and self._cond_func is not None
+                and not self._cond_func(variables)
+            ):
+                self._logger.debug(
+                    "Conditions not met, aborting automation. Condition summary: %s",
+                    trace_get(clear=False),
+                )
+                script_execution_set("failed_conditions")
+                return
+
+            self.async_set_context(trigger_context)
+            event_data = {
+                ATTR_NAME: self.name,
+                ATTR_ENTITY_ID: self.entity_id,
+            }
+            if "trigger" in variables and "description" in variables["trigger"]:
+                event_data[ATTR_SOURCE] = variables["trigger"]["description"]
+
+            @callback
+            def started_action() -> None:
+                self.hass.bus.async_fire(
+                    EVENT_AUTOMATION_TRIGGERED, event_data, context=trigger_context
+                )
+
+            # Make a new empty script stack; automations are allowed
+            # to recursively trigger themselves
+            script_stack_cv.set([])
+
+            try:
+                with trace_path("action"):
+                    # 执行动作序列（命令会在 script.py 中记录）
+                    await self.action_script.async_run(
+                        variables, trigger_context, started_action
+                    )
+            except ServiceNotFound as err:
+                async_create_issue(
+                    self.hass,
+                    DOMAIN,
+                    f"{self.entity_id}_service_not_found_{err.domain}.{err.service}",
+                    is_fixable=True,
+                    is_persistent=True,
+                    severity=IssueSeverity.ERROR,
+                    translation_key="service_not_found",
+                    translation_placeholders={
+                        "service": f"{err.domain}.{err.service}",
+                        "entity_id": self.entity_id,
+                        "name": self.name or self.entity_id,
+                        "edit": f"/config/automation/edit/{self.unique_id}",
+                    },
+                )
+                automation_trace.set_error(err)
+            except (vol.Invalid, HomeAssistantError) as err:
+                self._logger.error(
+                    "Error while executing automation %s: %s",
+                    self.entity_id,
+                    err,
+                )
+                automation_trace.set_error(err)
+            except Exception as err:  # pylint: disable=broad-except
+                self._logger.exception("While executing automation %s", self.entity_id)
+                automation_trace.set_error(err)
+
+    async def async_will_remove_from_hass(self) -> None:
+        """Remove listeners when removing automation from Home Assistant."""
+        await super().async_will_remove_from_hass()
+        await self.async_disable()
+
+    async def _async_enable_automation(self, event: Event) -> None:
+        """Start automation on startup."""
+        # Don't do anything if no longer enabled or already attached
+        if not self._is_enabled or self._async_detach_triggers is not None:
+            return
+
+        self._async_detach_triggers = await self._async_attach_triggers(True)
+
+    async def async_enable(self) -> None:
+        """Enable this automation entity.
+
+        This method is a coroutine.
+        """
+        if self._is_enabled:
+            return
+
+        self._is_enabled = True
+
+        # HomeAssistant is starting up
+        if self.hass.state != CoreState.not_running:
+            self._async_detach_triggers = await self._async_attach_triggers(False)
+            self.async_write_ha_state()
+            return
+
+        self.hass.bus.async_listen_once(
+            EVENT_HOMEASSISTANT_STARTED, self._async_enable_automation
+        )
+        self.async_write_ha_state()
+
+    async def async_disable(self, stop_actions: bool = DEFAULT_STOP_ACTIONS) -> None:
+        """Disable the automation entity."""
+        if not self._is_enabled and not self.action_script.runs:
+            return
+
+        self._is_enabled = False
+
+        if self._async_detach_triggers is not None:
+            self._async_detach_triggers()
+            self._async_detach_triggers = None
+
+        if stop_actions:
+            await self.action_script.async_stop()
+
+        self.async_write_ha_state()
+
+    def _log_callback(self, level: int, msg: str, **kwargs: Any) -> None:
+        """Log helper callback."""
+        self._logger.log(level, "%s %s", msg, self.name, **kwargs)
+
+    async def _async_attach_triggers(
+        self, home_assistant_start: bool
+    ) -> Callable[[], None] | None:
+        """Set up the triggers."""
+        this = None
+        self.async_write_ha_state()
+        if state := self.hass.states.get(self.entity_id):
+            this = state.as_dict()
+        variables = {"this": this}
+        if self._trigger_variables:
+            try:
+                variables = self._trigger_variables.async_render(
+                    self.hass,
+                    variables,
+                    limited=True,
+                )
+            except TemplateError as err:
+                self._logger.error("Error rendering trigger variables: %s", err)
+                return None
+
+        return await async_initialize_triggers(
+            self.hass,
+            self._trigger_config,
+            self.async_trigger,
+            DOMAIN,
+            str(self.name),
+            self._log_callback,
+            home_assistant_start,
+            variables,
+        )
+
+
+@dataclass(slots=True)
+class AutomationEntityConfig:
+    """Container for prepared automation entity configuration."""
+
+    config_block: ConfigType
+    list_no: int
+    raw_blueprint_inputs: ConfigType | None
+    raw_config: ConfigType | None
+    validation_failed: bool
+
+
+async def _prepare_automation_config(
+    hass: HomeAssistant,
+    config: ConfigType,
+) -> list[AutomationEntityConfig]:
+    """Parse configuration and prepare automation entity configuration."""
+    automation_configs: list[AutomationEntityConfig] = []
+
+    conf: list[ConfigType] = config[DOMAIN]
+
+    for list_no, config_block in enumerate(conf):
+        raw_config = cast(AutomationConfig, config_block).raw_config
+        raw_blueprint_inputs = cast(AutomationConfig, config_block).raw_blueprint_inputs
+        validation_failed = cast(AutomationConfig, config_block).validation_failed
+        automation_configs.append(
+            AutomationEntityConfig(
+                config_block,
+                list_no,
+                raw_blueprint_inputs,
+                raw_config,
+                validation_failed,
+            )
+        )
+
+    return automation_configs
+
+
+def _automation_name(automation_config: AutomationEntityConfig) -> str:
+    """Return the configured name of an automation."""
+    config_block = automation_config.config_block
+    list_no = automation_config.list_no
+    return config_block.get(CONF_ALIAS) or f"{DOMAIN} {list_no}"
+
+
+async def _create_automation_entities(
+    hass: HomeAssistant, automation_configs: list[AutomationEntityConfig]
+) -> list[BaseAutomationEntity]:
+    """Create automation entities from prepared configuration."""
+    entities: list[BaseAutomationEntity] = []
+
+    for automation_config in automation_configs:
+        config_block = automation_config.config_block
+
+        automation_id: str | None = config_block.get(CONF_ID)
+        name = _automation_name(automation_config)
+
+        if automation_config.validation_failed:
+            entities.append(
+                UnavailableAutomationEntity(
+                    automation_id,
+                    name,
+                    automation_config.raw_config,
+                )
+            )
+            continue
+
+        initial_state: bool | None = config_block.get(CONF_INITIAL_STATE)
+
+        action_script = Script(
+            hass,
+            config_block[CONF_ACTION],
+            name,
+            DOMAIN,
+            running_description="automation actions",
+            script_mode=config_block[CONF_MODE],
+            max_runs=config_block[CONF_MAX],
+            max_exceeded=config_block[CONF_MAX_EXCEEDED],
+            logger=LOGGER,
+            # We don't pass variables here
+            # Automation will already render them to use them in the condition
+            # and so will pass them on to the script.
+        )
+
+        if CONF_CONDITION in config_block:
+            cond_func = await _async_process_if(hass, name, config_block)
+
+            if cond_func is None:
+                continue
+        else:
+            cond_func = None
+
+        # Add trigger variables to variables
+        variables = None
+        if CONF_TRIGGER_VARIABLES in config_block:
+            variables = ScriptVariables(
+                dict(config_block[CONF_TRIGGER_VARIABLES].as_dict())
+            )
+        if CONF_VARIABLES in config_block:
+            if variables:
+                variables.variables.update(config_block[CONF_VARIABLES].as_dict())
+            else:
+                variables = config_block[CONF_VARIABLES]
+
+        entity = AutomationEntity(
+            automation_id,
+            name,
+            config_block[CONF_TRIGGER],
+            cond_func,
+            action_script,
+            initial_state,
+            variables,
+            config_block.get(CONF_TRIGGER_VARIABLES),
+            automation_config.raw_config,
+            automation_config.raw_blueprint_inputs,
+            config_block[CONF_TRACE],
+        )
+        entities.append(entity)
+
+    return entities
+
+
+async def _async_process_config(
+    hass: HomeAssistant,
+    config: dict[str, Any],
+    component: EntityComponent[BaseAutomationEntity],
+) -> None:
+    """Process config and add automations."""
+
+    def automation_matches_config(
+        automation: BaseAutomationEntity, config: AutomationEntityConfig
+    ) -> bool:
+        name = _automation_name(config)
+        return automation.name == name and automation.raw_config == config.raw_config
+
+    def find_matches(
+        automations: list[BaseAutomationEntity],
+        automation_configs: list[AutomationEntityConfig],
+    ) -> tuple[set[int], set[int]]:
+        """Find matches between a list of automation entities and a list of configurations.
+
+        An automation or configuration is only allowed to match at most once to handle
+        the case of multiple automations with identical configuration.
+
+        Returns a tuple of sets of indices: ({automation_matches}, {config_matches})
+        """
+        automation_matches: set[int] = set()
+        config_matches: set[int] = set()
+        automation_configs_with_id: dict[str, tuple[int, AutomationEntityConfig]] = {}
+        automation_configs_without_id: list[tuple[int, AutomationEntityConfig]] = []
+
+        for config_idx, config in enumerate(automation_configs):
+            if automation_id := config.config_block.get(CONF_ID):
+                automation_configs_with_id[automation_id] = (config_idx, config)
+                continue
+            automation_configs_without_id.append((config_idx, config))
+
+        for automation_idx, automation in enumerate(automations):
+            if automation.unique_id:
+                if automation.unique_id not in automation_configs_with_id:
+                    continue
+                config_idx, config = automation_configs_with_id.pop(
+                    automation.unique_id
+                )
+                if automation_matches_config(automation, config):
+                    automation_matches.add(automation_idx)
+                    config_matches.add(config_idx)
+                continue
+
+            for config_idx, config in automation_configs_without_id:
+                if config_idx in config_matches:
+                    # Only allow an automation config to match at most once
+                    continue
+                if automation_matches_config(automation, config):
+                    automation_matches.add(automation_idx)
+                    config_matches.add(config_idx)
+                    # Only allow an automation to match at most once
+                    break
+
+        return automation_matches, config_matches
+
+    automation_configs = await _prepare_automation_config(hass, config)
+    automations: list[BaseAutomationEntity] = list(component.entities)
+
+    # Find automations and configurations which have matches
+    automation_matches, config_matches = find_matches(automations, automation_configs)
+
+    # Remove automations which have changed config or no longer exist
+    tasks = [
+        automation.async_remove()
+        for idx, automation in enumerate(automations)
+        if idx not in automation_matches
+    ]
+    await asyncio.gather(*tasks)
+
+    # Create automations which have changed config or have been added
+    updated_automation_configs = [
+        config
+        for idx, config in enumerate(automation_configs)
+        if idx not in config_matches
+    ]
+    entities = await _create_automation_entities(hass, updated_automation_configs)
+    await component.async_add_entities(entities)
+
+
+async def _async_process_if(
+    hass: HomeAssistant, name: str, config: dict[str, Any]
+) -> IfAction | None:
+    """Process if checks."""
+    if_configs = config[CONF_CONDITION]
+
+    checks: list[condition.ConditionCheckerType] = []
+    for if_config in if_configs:
+        try:
+            #lqg add
+            # 解析条件时，绑定当前自动化的 ID 和上下文（从 config 中获取）
+            automation_id = config.get("unique_id")  # 从自动化配置中获取唯一ID
+            checks.append(await condition.async_from_config(
+                hass, 
+                if_config,
+                # 新增：传递自动化ID和上下文给 condition.py
+                automation_id=automation_id,
+                context=config.get("context")
+            ))
+            #checks.append(await condition.async_from_config(hass, if_config))
+        except HomeAssistantError as ex:
+            LOGGER.warning("Invalid condition: %s", ex)
+            return None
+
+    def if_action(variables: Mapping[str, Any] | None = None) -> bool:
+        """AND all conditions."""
+        errors: list[ConditionErrorIndex] = []
+        for index, check in enumerate(checks):
+            try:
+                with trace_path(["condition", str(index)]):
+                    if check(hass, variables) is False:
+                        return False
+            except ConditionError as ex:
+                errors.append(
+                    ConditionErrorIndex(
+                        "condition", index=index, total=len(checks), error=ex
+                    )
+                )
+
+        if errors:
+            LOGGER.warning(
+                "Error evaluating condition in '%s':\n%s",
+                name,
+                ConditionErrorContainer("condition", errors=errors),
+            )
+            return False
+
+        return True
+
+    result: IfAction = if_action  # type: ignore[assignment]
+    result.config = if_configs
+
+    return result
+
+
+@callback
+def _trigger_extract_devices(trigger_conf: dict) -> list[str]:
+    """Extract devices from a trigger config."""
+    if trigger_conf[CONF_PLATFORM] == "device":
+        return [trigger_conf[CONF_DEVICE_ID]]
+
+    if (
+        trigger_conf[CONF_PLATFORM] == "event"
+        and CONF_EVENT_DATA in trigger_conf
+        and CONF_DEVICE_ID in trigger_conf[CONF_EVENT_DATA]
+        and isinstance(trigger_conf[CONF_EVENT_DATA][CONF_DEVICE_ID], str)
+    ):
+        return [trigger_conf[CONF_EVENT_DATA][CONF_DEVICE_ID]]
+
+    if trigger_conf[CONF_PLATFORM] == "tag" and CONF_DEVICE_ID in trigger_conf:
+        return trigger_conf[CONF_DEVICE_ID]  # type: ignore[no-any-return]
+
+    return []
+
+
+@callback
+def _trigger_extract_entities(trigger_conf: dict) -> list[str]:
+    """Extract entities from a trigger config."""
+    if trigger_conf[CONF_PLATFORM] in ("state", "numeric_state"):
+        return trigger_conf[CONF_ENTITY_ID]  # type: ignore[no-any-return]
+
+    if trigger_conf[CONF_PLATFORM] == "calendar":
+        return [trigger_conf[CONF_ENTITY_ID]]
+
+    if trigger_conf[CONF_PLATFORM] == "zone":
+        return trigger_conf[CONF_ENTITY_ID] + [trigger_conf[CONF_ZONE]]  # type: ignore[no-any-return]
+
+    if trigger_conf[CONF_PLATFORM] == "geo_location":
+        return [trigger_conf[CONF_ZONE]]
+
+    if trigger_conf[CONF_PLATFORM] == "sun":
+        return ["sun.sun"]
+
+    if (
+        trigger_conf[CONF_PLATFORM] == "event"
+        and CONF_EVENT_DATA in trigger_conf
+        and CONF_ENTITY_ID in trigger_conf[CONF_EVENT_DATA]
+        and isinstance(trigger_conf[CONF_EVENT_DATA][CONF_ENTITY_ID], str)
+        and valid_entity_id(trigger_conf[CONF_EVENT_DATA][CONF_ENTITY_ID])
+    ):
+        return [trigger_conf[CONF_EVENT_DATA][CONF_ENTITY_ID]]
+
+    return []
+
+
+@websocket_api.websocket_command({"type": "automation/config", "entity_id": str})
+def websocket_config(
+    hass: HomeAssistant,
+    connection: websocket_api.ActiveConnection,
+    msg: dict[str, Any],
+) -> None:
+    """Get automation config."""
+    component: EntityComponent[BaseAutomationEntity] = hass.data[DOMAIN]
+
+    automation = component.get_entity(msg["entity_id"])
+
+    if automation is None:
+        connection.send_error(
+            msg["id"], websocket_api.const.ERR_NOT_FOUND, "Entity not found"
+        )
+        return
+
+    connection.send_result(
+        msg["id"],
+        {
+            "config": automation.raw_config,
+        },
+    )
+
+
+# These can be removed if no deprecated constant are in this module anymore
+__getattr__ = partial(check_if_deprecated_constant, module_globals=globals())
+__dir__ = partial(
+    dir_with_deprecated_constants, module_globals_keys=[*globals().keys()]
+)
+__all__ = all_with_deprecated_constants(globals())
diff -urN -x __pycache__ -x '*.pyc' /tmp/homeassistant-2024.1.5/homeassistant/components/automation/__init__.py /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/components/automation/__init__.py
--- /tmp/homeassistant-2024.1.5/homeassistant/components/automation/__init__.py	2024-01-21 04:41:25.000000000 +0800
+++ /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/components/automation/__init__.py	2026-02-12 18:01:08.543962415 +0800
@@ -1,5 +1,19 @@
 """Allow to set up simple automation rules via the config file."""
 from __future__ import annotations
+#from homeassistant.helpers.provenance
+from homeassistant.util.dt import parse_datetime
+
+#lqg tag
+from homeassistant.helpers.provenance import(
+    log_trigger
+)
+
+
+import logging
+_LOGGER = logging.getLogger(__name__)
+
+
+RELATION_TYPE_WAS_ASSOCIATED_WITH = "wasAssociateWith"  # 活动与代理关联
 
 from abc import ABC, abstractmethod
 import asyncio
@@ -455,6 +469,12 @@
         self._trace_config = trace_config
         self._attr_unique_id = automation_id
 
+    #lqg add
+    @property
+    def agent_id(self) -> str:
+        """生成自动化的唯一agent标识"""
+        return f"automation.{self.unique_id or self.entity_id}"  # 确保唯一性
+
     @property
     def name(self) -> str:
         """Return the name of the entity."""
@@ -599,6 +619,52 @@
         parent_id = None if context is None else context.id
         trigger_context = Context(parent_id=parent_id)
 
+        # ========== 新增：调用 log_trigger 记录 Agent 事件 ==========
+        agent_event_id = None
+        try:
+            trigger_data = run_variables.get('trigger', {})
+            # 1. 提取触发源实体ID（支持实体触发和非实体触发）
+            entity_name = trigger_data.get('entity_id')
+            if not entity_name:
+                # 非实体触发（如时间、手动触发），用触发平台作为标识
+                entity_name = f"trigger.{trigger_data.get('platform', 'unknown')}"  # 如 "trigger.time"
+                from_state = "idle"
+                to_state = "triggered"
+            else:
+                # 实体触发，提取新旧状态
+                entity_from_state = trigger_data.get('from_state')
+                entity_to_state = trigger_data.get('to_state')
+                from_state = entity_from_state.state if entity_from_state else ""
+                to_state = entity_to_state.state if entity_to_state else ""
+
+            # 核心：判断是否是根因 (Root Cause)
+            # 如果 parent_id 是 None，或者 user_id 存在，通常是起点
+            is_start_point = (trigger_context.parent_id is None) or (trigger_context.user_id is not None)
+
+            
+            # 3. 修正 automation_id：使用实体公开的 unique_id（与状态机中一致）
+            automation_id = self.unique_id
+            # 4. 调用 log_trigger 记录 Agent 事件
+            agent_event_id = log_trigger(
+                action = "triggered",
+                entity_id=entity_name,
+                state=to_state,
+                automation_name = self.entity_id,
+                #automation_name=self.name or self.entity_id,
+                context=trigger_context,  # 传递当前自动化触发的上下文
+                automation_id=automation_id,
+                sequence=self.action_script.sequence,  # 传递动作序列，用于跟踪后续命令
+                is_start_point=is_start_point
+            )
+            _LOGGER.warning("Automation {automation_id} triggered by {entity_name} (state: {from_state}→{to_state})")
+            
+            self._logger.debug(
+                f"Automation {automation_id} triggered by {self.entity_id} (state: {from_state}→{to_state})"
+            )
+
+        except Exception as e:
+            self._logger.error(f"Provenance tracking error: {e}")
+        #——————————————————————————————————————————————
         with trace_automation(
             self.hass,
             self.unique_id,
@@ -610,7 +676,17 @@
             this = None
             if state := self.hass.states.get(self.entity_id):
                 this = state.as_dict()
-            variables: dict[str, Any] = {"this": this, **(run_variables or {})}
+            #variables: dict[str, Any] = {"this": this, **(run_variables or {})}
+            #lqg tag
+            #注入 automation_id 和 context 到变量，供下游使用
+            variables: dict[str, Any] = {
+                "this": this,
+                **(run_variables or {}),
+                # 新增：传递自动化ID和触发上下文给条件/命令
+                "automation_id": self.unique_id,  # 供 condition.py/script.py 关联事件
+                "trigger_context": trigger_context,  # 供下游事件复用上下文
+                "agent_event_id": agent_event_id
+            }
             if self._variables:
                 try:
                     variables = self._variables.async_render(self.hass, variables)
@@ -633,7 +709,61 @@
                 trigger_path = "trigger"
             trace_element = TraceElement(variables, trigger_path)
             trace_append_element(trace_element)
-
+            ############################### zyd-before-condition ###############################
+            import time
+            from pathlib import Path
+            import os
+            from datetime import datetime
+            
+            time_format_iso = datetime.now().isoformat(sep=' ', timespec='seconds')
+            
+            automation_entity_id = self.entity_id
+            
+            trigger_data = variables.get("trigger", {})
+            platform = trigger_data.get("platform", "manual/unknown")
+            
+            # 尝试提取实体ID和状态变化
+            entity_id_triggered = trigger_data.get(ATTR_ENTITY_ID, "N/A")
+            
+            # 提取状态信息
+            from_state_obj = trigger_data.get("from_state")
+            to_state_obj = trigger_data.get("to_state")
+            
+            from_state_str = from_state_obj.state if from_state_obj and hasattr(from_state_obj, 'state') else "N/A"
+            to_state_str = to_state_obj.state if to_state_obj and hasattr(to_state_obj, 'state') else "N/A"
+            
+            # 2. 格式化日志行 (时间 \t 实体id \t Platform \t from_state \t to_state)
+            log_line = (
+                f"{time_format_iso}\t"
+                f"{entity_id_triggered}\t"
+                f"{platform}\t"
+                f"{from_state_str}\t"
+                f"{to_state_str}\n"
+            )
+            
+            # 3. 确定文件路径 (~/ZYD/YYYY-MM-DD.log)
+            today_date = datetime.now().strftime("%Y-%m-%d")
+            
+            # 使用 Pathlib 获取用户主目录并构建路径
+            home_dir = Path.home()
+            log_dir = home_dir / "ZYD"
+            log_file = log_dir / f"{today_date}.log"
+            
+            try:
+                # 4. 确保目录存在
+                log_dir.mkdir(parents=True, exist_ok=True)
+                
+                # 5. 写入文件 (a: append 增量补充)
+                with open(log_file, 'a', encoding='utf-8') as f:
+                    f.write(log_line)
+                    
+            except OSError as e:
+                # 异常处理：如果写入失败，记录到 Home Assistant 内部日志
+                _LOGGER.error("Failed to write ZYD automation log to %s: %s", log_file, e)
+            
+            print(f"zyd-before-condition-{time_format_iso}".center(75,"="))
+            print(f"variables:{self.entity_id} - Log Recorded: {'shadow_dataset_recorder' in automation_entity_id}")
+            ############################### zyd-before-condition ###############################
             if (
                 not skip_condition
                 and self._cond_func is not None
@@ -666,6 +796,7 @@
 
             try:
                 with trace_path("action"):
+                    # 执行动作序列（命令会在 script.py 中记录）
                     await self.action_script.async_run(
                         variables, trigger_context, started_action
                     )
@@ -996,7 +1127,17 @@
     checks: list[condition.ConditionCheckerType] = []
     for if_config in if_configs:
         try:
-            checks.append(await condition.async_from_config(hass, if_config))
+            #lqg add
+            # 解析条件时，绑定当前自动化的 ID 和上下文（从 config 中获取）
+            automation_id = config.get("unique_id")  # 从自动化配置中获取唯一ID
+            checks.append(await condition.async_from_config(
+                hass, 
+                if_config,
+                # 新增：传递自动化ID和上下文给 condition.py
+                automation_id=automation_id,
+                context=config.get("context")
+            ))
+            #checks.append(await condition.async_from_config(hass, if_config))
         except HomeAssistantError as ex:
             LOGGER.warning("Invalid condition: %s", ex)
             return None
diff -urN -x __pycache__ -x '*.pyc' "/tmp/homeassistant-2024.1.5/homeassistant/components/automation/__init__ zyd.py" "/home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/components/automation/__init__ zyd.py"
--- "/tmp/homeassistant-2024.1.5/homeassistant/components/automation/__init__ zyd.py"	1970-01-01 08:00:00.000000000 +0800
+++ "/home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/components/automation/__init__ zyd.py"	2026-01-10 21:53:58.069358740 +0800
@@ -0,0 +1,1260 @@
+"""Allow to set up simple automation rules via the config file."""
+from __future__ import annotations
+#from homeassistant.helpers.provenance
+from homeassistant.util.dt import parse_datetime
+
+#lqg tag
+from homeassistant.helpers.provenance import(
+    log_trigger
+)
+
+
+import logging
+_LOGGER = logging.getLogger(__name__)
+
+
+RELATION_TYPE_WAS_ASSOCIATED_WITH = "wasAssociateWith"  # 活动与代理关联
+
+from abc import ABC, abstractmethod
+import asyncio
+from collections.abc import Callable, Mapping
+from dataclasses import dataclass
+from functools import partial
+import logging
+from typing import Any, Protocol, cast
+
+import voluptuous as vol
+
+from homeassistant.components import websocket_api
+from homeassistant.components.blueprint import CONF_USE_BLUEPRINT
+from homeassistant.const import (
+    ATTR_ENTITY_ID,
+    ATTR_MODE,
+    ATTR_NAME,
+    CONF_ALIAS,
+    CONF_CONDITION,
+    CONF_DEVICE_ID,
+    CONF_ENTITY_ID,
+    CONF_EVENT_DATA,
+    CONF_ID,
+    CONF_MODE,
+    CONF_PATH,
+    CONF_PLATFORM,
+    CONF_VARIABLES,
+    CONF_ZONE,
+    EVENT_HOMEASSISTANT_STARTED,
+    SERVICE_RELOAD,
+    SERVICE_TOGGLE,
+    SERVICE_TURN_OFF,
+    SERVICE_TURN_ON,
+    STATE_ON,
+)
+from homeassistant.core import (
+    CALLBACK_TYPE,
+    Context,
+    CoreState,
+    Event,
+    HomeAssistant,
+    ServiceCall,
+    callback,
+    split_entity_id,
+    valid_entity_id,
+)
+from homeassistant.exceptions import (
+    ConditionError,
+    ConditionErrorContainer,
+    ConditionErrorIndex,
+    HomeAssistantError,
+    ServiceNotFound,
+    TemplateError,
+)
+from homeassistant.helpers import condition
+import homeassistant.helpers.config_validation as cv
+from homeassistant.helpers.deprecation import (
+    DeprecatedConstant,
+    all_with_deprecated_constants,
+    check_if_deprecated_constant,
+    dir_with_deprecated_constants,
+)
+from homeassistant.helpers.entity import ToggleEntity
+from homeassistant.helpers.entity_component import EntityComponent
+from homeassistant.helpers.issue_registry import IssueSeverity, async_create_issue
+from homeassistant.helpers.restore_state import RestoreEntity
+from homeassistant.helpers.script import (
+    ATTR_CUR,
+    ATTR_MAX,
+    CONF_MAX,
+    CONF_MAX_EXCEEDED,
+    Script,
+    script_stack_cv,
+)
+from homeassistant.helpers.script_variables import ScriptVariables
+from homeassistant.helpers.service import (
+    ReloadServiceHelper,
+    async_register_admin_service,
+)
+from homeassistant.helpers.trace import (
+    TraceElement,
+    script_execution_set,
+    trace_append_element,
+    trace_get,
+    trace_path,
+)
+from homeassistant.helpers.trigger import (
+    TriggerActionType,
+    TriggerData,
+    TriggerInfo,
+    async_initialize_triggers,
+)
+from homeassistant.helpers.typing import ConfigType
+from homeassistant.loader import bind_hass
+from homeassistant.util.dt import parse_datetime
+
+from .config import AutomationConfig
+from .const import (
+    CONF_ACTION,
+    CONF_INITIAL_STATE,
+    CONF_TRACE,
+    CONF_TRIGGER,
+    CONF_TRIGGER_VARIABLES,
+    DEFAULT_INITIAL_STATE,
+    DOMAIN,
+    LOGGER,
+)
+from .helpers import async_get_blueprints
+from .trace import trace_automation
+
+ENTITY_ID_FORMAT = DOMAIN + ".{}"
+
+
+CONF_SKIP_CONDITION = "skip_condition"
+CONF_STOP_ACTIONS = "stop_actions"
+DEFAULT_STOP_ACTIONS = True
+
+EVENT_AUTOMATION_RELOADED = "automation_reloaded"
+EVENT_AUTOMATION_TRIGGERED = "automation_triggered"
+
+ATTR_LAST_TRIGGERED = "last_triggered"
+ATTR_SOURCE = "source"
+ATTR_VARIABLES = "variables"
+SERVICE_TRIGGER = "trigger"
+
+
+class IfAction(Protocol):
+    """Define the format of if_action."""
+
+    config: list[ConfigType]
+
+    def __call__(self, variables: Mapping[str, Any] | None = None) -> bool:
+        """AND all conditions."""
+
+
+# AutomationActionType, AutomationTriggerData,
+# and AutomationTriggerInfo are deprecated as of 2022.9.
+# Can be removed in 2025.1
+_DEPRECATED_AutomationActionType = DeprecatedConstant(
+    TriggerActionType, "TriggerActionType", "2025.1"
+)
+_DEPRECATED_AutomationTriggerData = DeprecatedConstant(
+    TriggerData, "TriggerData", "2025.1"
+)
+_DEPRECATED_AutomationTriggerInfo = DeprecatedConstant(
+    TriggerInfo, "TriggerInfo", "2025.1"
+)
+
+
+@bind_hass
+def is_on(hass: HomeAssistant, entity_id: str) -> bool:
+    """Return true if specified automation entity_id is on.
+
+    Async friendly.
+    """
+    return hass.states.is_state(entity_id, STATE_ON)
+
+
+def _automations_with_x(
+    hass: HomeAssistant, referenced_id: str, property_name: str
+) -> list[str]:
+    """Return all automations that reference the x."""
+    if DOMAIN not in hass.data:
+        return []
+
+    component: EntityComponent[BaseAutomationEntity] = hass.data[DOMAIN]
+
+    return [
+        automation_entity.entity_id
+        for automation_entity in component.entities
+        if referenced_id in getattr(automation_entity, property_name)
+    ]
+
+
+def _x_in_automation(
+    hass: HomeAssistant, entity_id: str, property_name: str
+) -> list[str]:
+    """Return all x in an automation."""
+    if DOMAIN not in hass.data:
+        return []
+
+    component: EntityComponent[BaseAutomationEntity] = hass.data[DOMAIN]
+
+    if (automation_entity := component.get_entity(entity_id)) is None:
+        return []
+
+    return list(getattr(automation_entity, property_name))
+
+
+@callback
+def automations_with_entity(hass: HomeAssistant, entity_id: str) -> list[str]:
+    """Return all automations that reference the entity."""
+    return _automations_with_x(hass, entity_id, "referenced_entities")
+
+
+@callback
+def entities_in_automation(hass: HomeAssistant, entity_id: str) -> list[str]:
+    """Return all entities in an automation."""
+    return _x_in_automation(hass, entity_id, "referenced_entities")
+
+
+@callback
+def automations_with_device(hass: HomeAssistant, device_id: str) -> list[str]:
+    """Return all automations that reference the device."""
+    return _automations_with_x(hass, device_id, "referenced_devices")
+
+
+@callback
+def devices_in_automation(hass: HomeAssistant, entity_id: str) -> list[str]:
+    """Return all devices in an automation."""
+    return _x_in_automation(hass, entity_id, "referenced_devices")
+
+
+@callback
+def automations_with_area(hass: HomeAssistant, area_id: str) -> list[str]:
+    """Return all automations that reference the area."""
+    return _automations_with_x(hass, area_id, "referenced_areas")
+
+
+@callback
+def areas_in_automation(hass: HomeAssistant, entity_id: str) -> list[str]:
+    """Return all areas in an automation."""
+    return _x_in_automation(hass, entity_id, "referenced_areas")
+
+
+@callback
+def automations_with_blueprint(hass: HomeAssistant, blueprint_path: str) -> list[str]:
+    """Return all automations that reference the blueprint."""
+    if DOMAIN not in hass.data:
+        return []
+
+    component: EntityComponent[BaseAutomationEntity] = hass.data[DOMAIN]
+
+    return [
+        automation_entity.entity_id
+        for automation_entity in component.entities
+        if automation_entity.referenced_blueprint == blueprint_path
+    ]
+
+
+@callback
+def blueprint_in_automation(hass: HomeAssistant, entity_id: str) -> str | None:
+    """Return the blueprint the automation is based on or None."""
+    if DOMAIN not in hass.data:
+        return None
+
+    component: EntityComponent[BaseAutomationEntity] = hass.data[DOMAIN]
+
+    if (automation_entity := component.get_entity(entity_id)) is None:
+        return None
+
+    return automation_entity.referenced_blueprint
+
+
+async def async_setup(hass: HomeAssistant, config: ConfigType) -> bool:
+    """Set up all automations."""
+    hass.data[DOMAIN] = component = EntityComponent[BaseAutomationEntity](
+        LOGGER, DOMAIN, hass
+    )
+
+    # Register automation as valid domain for Blueprint
+    async_get_blueprints(hass)
+
+    await _async_process_config(hass, config, component)
+
+    # Add some default blueprints to blueprints/automation, does nothing
+    # if blueprints/automation already exists
+    await async_get_blueprints(hass).async_populate()
+
+    async def trigger_service_handler(
+        entity: BaseAutomationEntity, service_call: ServiceCall
+    ) -> None:
+        """Handle forced automation trigger, e.g. from frontend."""
+        await entity.async_trigger(
+            {**service_call.data[ATTR_VARIABLES], "trigger": {"platform": None}},
+            skip_condition=service_call.data[CONF_SKIP_CONDITION],
+            context=service_call.context,
+        )
+
+    component.async_register_entity_service(
+        SERVICE_TRIGGER,
+        {
+            vol.Optional(ATTR_VARIABLES, default={}): dict,
+            vol.Optional(CONF_SKIP_CONDITION, default=True): bool,
+        },
+        trigger_service_handler,
+    )
+    component.async_register_entity_service(SERVICE_TOGGLE, {}, "async_toggle")
+    component.async_register_entity_service(SERVICE_TURN_ON, {}, "async_turn_on")
+    component.async_register_entity_service(
+        SERVICE_TURN_OFF,
+        {vol.Optional(CONF_STOP_ACTIONS, default=DEFAULT_STOP_ACTIONS): cv.boolean},
+        "async_turn_off",
+    )
+
+    async def reload_service_handler(service_call: ServiceCall) -> None:
+        """Remove all automations and load new ones from config."""
+        await async_get_blueprints(hass).async_reset_cache()
+        if (conf := await component.async_prepare_reload(skip_reset=True)) is None:
+            return
+        await _async_process_config(hass, conf, component)
+        hass.bus.async_fire(EVENT_AUTOMATION_RELOADED, context=service_call.context)
+
+    reload_helper = ReloadServiceHelper(reload_service_handler)
+
+    async_register_admin_service(
+        hass,
+        DOMAIN,
+        SERVICE_RELOAD,
+        reload_helper.execute_service,
+        schema=vol.Schema({}),
+    )
+
+    websocket_api.async_register_command(hass, websocket_config)
+
+    return True
+
+
+class BaseAutomationEntity(ToggleEntity, ABC):
+    """Base class for automation entities."""
+
+    _entity_component_unrecorded_attributes = frozenset(
+        (ATTR_LAST_TRIGGERED, ATTR_MODE, ATTR_CUR, ATTR_MAX, CONF_ID)
+    )
+    raw_config: ConfigType | None
+
+    @property
+    def capability_attributes(self) -> dict[str, Any] | None:
+        """Return capability attributes."""
+        if self.unique_id is not None:
+            return {CONF_ID: self.unique_id}
+        return None
+
+    @property
+    @abstractmethod
+    def referenced_areas(self) -> set[str]:
+        """Return a set of referenced areas."""
+
+    @property
+    @abstractmethod
+    def referenced_blueprint(self) -> str | None:
+        """Return referenced blueprint or None."""
+
+    @property
+    @abstractmethod
+    def referenced_devices(self) -> set[str]:
+        """Return a set of referenced devices."""
+
+    @property
+    @abstractmethod
+    def referenced_entities(self) -> set[str]:
+        """Return a set of referenced entities."""
+
+    @abstractmethod
+    async def async_trigger(
+        self,
+        run_variables: dict[str, Any],
+        context: Context | None = None,
+        skip_condition: bool = False,
+    ) -> None:
+        """Trigger automation."""
+
+
+class UnavailableAutomationEntity(BaseAutomationEntity):
+    """A non-functional automation entity with its state set to unavailable.
+
+    This class is instatiated when an automation fails to validate.
+    """
+
+    _attr_should_poll = False
+    _attr_available = False
+
+    def __init__(
+        self,
+        automation_id: str | None,
+        name: str,
+        raw_config: ConfigType | None,
+    ) -> None:
+        """Initialize an automation entity."""
+        self._name = name
+        self._attr_unique_id = automation_id
+        self.raw_config = raw_config
+
+    @property
+    def name(self) -> str:
+        """Return the name of the entity."""
+        return self._name
+
+    @property
+    def referenced_areas(self) -> set[str]:
+        """Return a set of referenced areas."""
+        return set()
+
+    @property
+    def referenced_blueprint(self) -> str | None:
+        """Return referenced blueprint or None."""
+        return None
+
+    @property
+    def referenced_devices(self) -> set[str]:
+        """Return a set of referenced devices."""
+        return set()
+
+    @property
+    def referenced_entities(self) -> set[str]:
+        """Return a set of referenced entities."""
+        return set()
+
+    async def async_trigger(
+        self,
+        run_variables: dict[str, Any],
+        context: Context | None = None,
+        skip_condition: bool = False,
+    ) -> None:
+        """Trigger automation."""
+
+
+class AutomationEntity(BaseAutomationEntity, RestoreEntity):
+    """Entity to show status of entity."""
+
+    _attr_should_poll = False
+
+    def __init__(
+        self,
+        automation_id: str | None,
+        name: str,
+        trigger_config: list[ConfigType],
+        cond_func: IfAction | None,
+        action_script: Script,
+        initial_state: bool | None,
+        variables: ScriptVariables | None,
+        trigger_variables: ScriptVariables | None,
+        raw_config: ConfigType | None,
+        blueprint_inputs: ConfigType | None,
+        trace_config: ConfigType,
+    ) -> None:
+        """Initialize an automation entity."""
+        self._name = name
+        self._trigger_config = trigger_config
+        self._async_detach_triggers: CALLBACK_TYPE | None = None
+        self._cond_func = cond_func
+        self.action_script = action_script
+        self.action_script.change_listener = self.async_write_ha_state
+        self._initial_state = initial_state
+        self._is_enabled = False
+        self._referenced_entities: set[str] | None = None
+        self._referenced_devices: set[str] | None = None
+        self._logger = LOGGER
+        self._variables = variables
+        self._trigger_variables = trigger_variables
+        self.raw_config = raw_config
+        self._blueprint_inputs = blueprint_inputs
+        self._trace_config = trace_config
+        self._attr_unique_id = automation_id
+
+    #lqg add
+    @property
+    def agent_id(self) -> str:
+        """生成自动化的唯一agent标识"""
+        return f"automation.{self.unique_id or self.entity_id}"  # 确保唯一性
+
+    @property
+    def name(self) -> str:
+        """Return the name of the entity."""
+        return self._name
+
+    @property
+    def extra_state_attributes(self) -> dict[str, Any]:
+        """Return the entity state attributes."""
+        attrs = {
+            ATTR_LAST_TRIGGERED: self.action_script.last_triggered,
+            ATTR_MODE: self.action_script.script_mode,
+            ATTR_CUR: self.action_script.runs,
+        }
+        if self.action_script.supports_max:
+            attrs[ATTR_MAX] = self.action_script.max_runs
+        return attrs
+
+    @property
+    def is_on(self) -> bool:
+        """Return True if entity is on."""
+        return self._async_detach_triggers is not None or self._is_enabled
+
+    @property
+    def referenced_areas(self) -> set[str]:
+        """Return a set of referenced areas."""
+        return self.action_script.referenced_areas
+
+    @property
+    def referenced_blueprint(self) -> str | None:
+        """Return referenced blueprint or None."""
+        if self._blueprint_inputs is None:
+            return None
+        return cast(str, self._blueprint_inputs[CONF_USE_BLUEPRINT][CONF_PATH])
+
+    @property
+    def referenced_devices(self) -> set[str]:
+        """Return a set of referenced devices."""
+        if self._referenced_devices is not None:
+            return self._referenced_devices
+
+        referenced = self.action_script.referenced_devices
+
+        if self._cond_func is not None:
+            for conf in self._cond_func.config:
+                referenced |= condition.async_extract_devices(conf)
+
+        for conf in self._trigger_config:
+            referenced |= set(_trigger_extract_devices(conf))
+
+        self._referenced_devices = referenced
+        return referenced
+
+    @property
+    def referenced_entities(self) -> set[str]:
+        """Return a set of referenced entities."""
+        if self._referenced_entities is not None:
+            return self._referenced_entities
+
+        referenced = self.action_script.referenced_entities
+
+        if self._cond_func is not None:
+            for conf in self._cond_func.config:
+                referenced |= condition.async_extract_entities(conf)
+
+        for conf in self._trigger_config:
+            for entity_id in _trigger_extract_entities(conf):
+                referenced.add(entity_id)
+
+        self._referenced_entities = referenced
+        return referenced
+
+    async def async_added_to_hass(self) -> None:
+        """Startup with initial state or previous state."""
+        await super().async_added_to_hass()
+
+        self._logger = logging.getLogger(
+            f"{__name__}.{split_entity_id(self.entity_id)[1]}"
+        )
+        self.action_script.update_logger(self._logger)
+
+        if state := await self.async_get_last_state():
+            enable_automation = state.state == STATE_ON
+            last_triggered = state.attributes.get("last_triggered")
+            if last_triggered is not None:
+                self.action_script.last_triggered = parse_datetime(last_triggered)
+            self._logger.debug(
+                "Loaded automation %s with state %s from state storage last state %s",
+                self.entity_id,
+                enable_automation,
+                state,
+            )
+        else:
+            enable_automation = DEFAULT_INITIAL_STATE
+            self._logger.debug(
+                "Automation %s not in state storage, state %s from default is used",
+                self.entity_id,
+                enable_automation,
+            )
+
+        if self._initial_state is not None:
+            enable_automation = self._initial_state
+            self._logger.debug(
+                "Automation %s initial state %s overridden from config initial_state",
+                self.entity_id,
+                enable_automation,
+            )
+
+        if enable_automation:
+            await self.async_enable()
+
+    async def async_turn_on(self, **kwargs: Any) -> None:
+        """Turn the entity on and update the state."""
+        await self.async_enable()
+
+    async def async_turn_off(self, **kwargs: Any) -> None:
+        """Turn the entity off."""
+        if CONF_STOP_ACTIONS in kwargs:
+            await self.async_disable(kwargs[CONF_STOP_ACTIONS])
+        else:
+            await self.async_disable()
+
+    async def async_trigger(
+        self,
+        run_variables: dict[str, Any],
+        context: Context | None = None,
+        skip_condition: bool = False,
+    ) -> None:
+        """Trigger automation.
+
+        This method is a coroutine.
+        """
+        reason = ""
+        alias = ""
+        if "trigger" in run_variables:
+            if "description" in run_variables["trigger"]:
+                reason = f' by {run_variables["trigger"]["description"]}'
+            if "alias" in run_variables["trigger"]:
+                alias = f' trigger \'{run_variables["trigger"]["alias"]}\''
+        self._logger.debug("Automation%s triggered%s", alias, reason)
+
+        # Create a new context referring to the old context.
+        parent_id = None if context is None else context.id
+        trigger_context = Context(parent_id=parent_id)
+
+        # ========== 新增：调用 log_trigger 记录 Agent 事件 ==========
+        agent_event_id = None
+        try:
+            trigger_data = run_variables.get('trigger', {})
+            # 1. 提取触发源实体ID（支持实体触发和非实体触发）
+            entity_name = trigger_data.get('entity_id')
+            if not entity_name:
+                # 非实体触发（如时间、手动触发），用触发平台作为标识
+                entity_name = f"trigger.{trigger_data.get('platform', 'unknown')}"  # 如 "trigger.time"
+                from_state = "idle"
+                to_state = "triggered"
+            else:
+                # 实体触发，提取新旧状态
+                entity_from_state = trigger_data.get('from_state')
+                entity_to_state = trigger_data.get('to_state')
+                from_state = entity_from_state.state if entity_from_state else ""
+                to_state = entity_to_state.state if entity_to_state else ""
+
+            # 核心：判断是否是根因 (Root Cause)
+            # 如果 parent_id 是 None，或者 user_id 存在，通常是起点
+            is_start_point = (trigger_context.parent_id is None) or (trigger_context.user_id is not None)
+
+            
+            # 3. 修正 automation_id：使用实体公开的 unique_id（与状态机中一致）
+            automation_id = self.unique_id
+            # 4. 调用 log_trigger 记录 Agent 事件
+            agent_event_id = log_trigger(
+                action = "triggered",
+                entity_id=entity_name,
+                state=to_state,
+                automation_name = self.entity_id,
+                #automation_name=self.name or self.entity_id,
+                context=trigger_context,  # 传递当前自动化触发的上下文
+                automation_id=automation_id,
+                sequence=self.action_script.sequence,  # 传递动作序列，用于跟踪后续命令
+                is_start_point=if_start_point
+            )
+            _LOGGER.warning("Automation {automation_id} triggered by {entity_name} (state: {from_state}→{to_state})")
+            
+            self._logger.debug(
+                f"Automation {automation_id} triggered by {self.entity_id} (state: {from_state}→{to_state})"
+            )
+
+        except Exception as e:
+            self._logger.error(f"Provenance tracking error: {e}")
+        #——————————————————————————————————————————————
+        with trace_automation(
+            self.hass,
+            self.unique_id,
+            self.raw_config,
+            self._blueprint_inputs,
+            trigger_context,
+            self._trace_config,
+        ) as automation_trace:
+            this = None
+            if state := self.hass.states.get(self.entity_id):
+                this = state.as_dict()
+            #variables: dict[str, Any] = {"this": this, **(run_variables or {})}
+            #lqg tag
+            #注入 automation_id 和 context 到变量，供下游使用
+            variables: dict[str, Any] = {
+                "this": this,
+                **(run_variables or {}),
+                # 新增：传递自动化ID和触发上下文给条件/命令
+                "automation_id": self.unique_id,  # 供 condition.py/script.py 关联事件
+                "trigger_context": trigger_context,  # 供下游事件复用上下文
+                "agent_event_id": agent_event_id
+            }
+            if self._variables:
+                try:
+                    variables = self._variables.async_render(self.hass, variables)
+                except TemplateError as err:
+                    self._logger.error("Error rendering variables: %s", err)
+                    automation_trace.set_error(err)
+                    return
+
+            # Prepare tracing the automation
+            automation_trace.set_trace(trace_get())
+
+            # Set trigger reason
+            trigger_description = variables.get("trigger", {}).get("description")
+            automation_trace.set_trigger_description(trigger_description)
+
+            # Add initial variables as the trigger step
+            if "trigger" in variables and "idx" in variables["trigger"]:
+                trigger_path = f"trigger/{variables['trigger']['idx']}"
+            else:
+                trigger_path = "trigger"
+            trace_element = TraceElement(variables, trigger_path)
+            trace_append_element(trace_element)
+            ############################### zyd-before-condition ###############################
+            import time
+            from pathlib import Path
+            import os
+            from datetime import datetime
+            
+            time_format_iso = datetime.now().isoformat(sep=' ', timespec='seconds')
+            
+            # 1. 检查实体ID是否包含 'shadow_dataset_recorder'
+            automation_entity_id = self.entity_id
+            
+            if "shadow_dataset_recorder" in automation_entity_id:
+                
+                trigger_data = variables.get("trigger", {})
+                platform = trigger_data.get("platform", "manual/unknown")
+                
+                # 尝试提取实体ID和状态变化
+                entity_id_triggered = trigger_data.get(ATTR_ENTITY_ID, "N/A")
+                
+                # 提取状态信息
+                from_state_obj = trigger_data.get("from_state")
+                to_state_obj = trigger_data.get("to_state")
+                
+                from_state_str = from_state_obj.state if from_state_obj and hasattr(from_state_obj, 'state') else "N/A"
+                to_state_str = to_state_obj.state if to_state_obj and hasattr(to_state_obj, 'state') else "N/A"
+                
+                # 2. 格式化日志行 (时间 \t 实体id \t Platform \t from_state \t to_state)
+                log_line = (
+                    f"{time_format_iso}\t"
+                    f"{entity_id_triggered}\t"
+                    f"{platform}\t"
+                    f"{from_state_str}\t"
+                    f"{to_state_str}\n"
+                )
+                
+                # 3. 确定文件路径 (~/ZYD/YYYY-MM-DD.log)
+                today_date = datetime.now().strftime("%Y-%m-%d")
+                
+                # 使用 Pathlib 获取用户主目录并构建路径
+                home_dir = Path.home()
+                log_dir = home_dir / "ZYD"
+                log_file = log_dir / f"{today_date}.log"
+                
+                try:
+                    # 4. 确保目录存在
+                    log_dir.mkdir(parents=True, exist_ok=True)
+                    
+                    # 5. 写入文件 (a: append 增量补充)
+                    with open(log_file, 'a', encoding='utf-8') as f:
+                        f.write(log_line)
+                        
+                except OSError as e:
+                    # 异常处理：如果写入失败，记录到 Home Assistant 内部日志
+                    _LOGGER.error("Failed to write ZYD automation log to %s: %s", log_file, e)
+            # 保持原有的调试输出，如果需要的话，但不影响正式的日志文件
+            # 如果不需要原有的 print 调试信息，可以删除以下几行
+            print(f"zyd-before-condition-{time_format_iso}".center(75,"="))
+            print(f"variables:{self.entity_id} - Log Recorded: {'shadow_dataset_recorder' in automation_entity_id}")
+            ############################### zyd-before-condition ###############################
+            if (
+                not skip_condition
+                and self._cond_func is not None
+                and not self._cond_func(variables)
+            ):
+                self._logger.debug(
+                    "Conditions not met, aborting automation. Condition summary: %s",
+                    trace_get(clear=False),
+                )
+                script_execution_set("failed_conditions")
+                return
+
+            self.async_set_context(trigger_context)
+            event_data = {
+                ATTR_NAME: self.name,
+                ATTR_ENTITY_ID: self.entity_id,
+            }
+            if "trigger" in variables and "description" in variables["trigger"]:
+                event_data[ATTR_SOURCE] = variables["trigger"]["description"]
+
+            @callback
+            def started_action() -> None:
+                self.hass.bus.async_fire(
+                    EVENT_AUTOMATION_TRIGGERED, event_data, context=trigger_context
+                )
+
+            # Make a new empty script stack; automations are allowed
+            # to recursively trigger themselves
+            script_stack_cv.set([])
+
+            try:
+                with trace_path("action"):
+                    # 执行动作序列（命令会在 script.py 中记录）
+                    await self.action_script.async_run(
+                        variables, trigger_context, started_action
+                    )
+            except ServiceNotFound as err:
+                async_create_issue(
+                    self.hass,
+                    DOMAIN,
+                    f"{self.entity_id}_service_not_found_{err.domain}.{err.service}",
+                    is_fixable=True,
+                    is_persistent=True,
+                    severity=IssueSeverity.ERROR,
+                    translation_key="service_not_found",
+                    translation_placeholders={
+                        "service": f"{err.domain}.{err.service}",
+                        "entity_id": self.entity_id,
+                        "name": self.name or self.entity_id,
+                        "edit": f"/config/automation/edit/{self.unique_id}",
+                    },
+                )
+                automation_trace.set_error(err)
+            except (vol.Invalid, HomeAssistantError) as err:
+                self._logger.error(
+                    "Error while executing automation %s: %s",
+                    self.entity_id,
+                    err,
+                )
+                automation_trace.set_error(err)
+            except Exception as err:  # pylint: disable=broad-except
+                self._logger.exception("While executing automation %s", self.entity_id)
+                automation_trace.set_error(err)
+
+    async def async_will_remove_from_hass(self) -> None:
+        """Remove listeners when removing automation from Home Assistant."""
+        await super().async_will_remove_from_hass()
+        await self.async_disable()
+
+    async def _async_enable_automation(self, event: Event) -> None:
+        """Start automation on startup."""
+        # Don't do anything if no longer enabled or already attached
+        if not self._is_enabled or self._async_detach_triggers is not None:
+            return
+
+        self._async_detach_triggers = await self._async_attach_triggers(True)
+
+    async def async_enable(self) -> None:
+        """Enable this automation entity.
+
+        This method is a coroutine.
+        """
+        if self._is_enabled:
+            return
+
+        self._is_enabled = True
+
+        # HomeAssistant is starting up
+        if self.hass.state != CoreState.not_running:
+            self._async_detach_triggers = await self._async_attach_triggers(False)
+            self.async_write_ha_state()
+            return
+
+        self.hass.bus.async_listen_once(
+            EVENT_HOMEASSISTANT_STARTED, self._async_enable_automation
+        )
+        self.async_write_ha_state()
+
+    async def async_disable(self, stop_actions: bool = DEFAULT_STOP_ACTIONS) -> None:
+        """Disable the automation entity."""
+        if not self._is_enabled and not self.action_script.runs:
+            return
+
+        self._is_enabled = False
+
+        if self._async_detach_triggers is not None:
+            self._async_detach_triggers()
+            self._async_detach_triggers = None
+
+        if stop_actions:
+            await self.action_script.async_stop()
+
+        self.async_write_ha_state()
+
+    def _log_callback(self, level: int, msg: str, **kwargs: Any) -> None:
+        """Log helper callback."""
+        self._logger.log(level, "%s %s", msg, self.name, **kwargs)
+
+    async def _async_attach_triggers(
+        self, home_assistant_start: bool
+    ) -> Callable[[], None] | None:
+        """Set up the triggers."""
+        this = None
+        self.async_write_ha_state()
+        if state := self.hass.states.get(self.entity_id):
+            this = state.as_dict()
+        variables = {"this": this}
+        if self._trigger_variables:
+            try:
+                variables = self._trigger_variables.async_render(
+                    self.hass,
+                    variables,
+                    limited=True,
+                )
+            except TemplateError as err:
+                self._logger.error("Error rendering trigger variables: %s", err)
+                return None
+
+        return await async_initialize_triggers(
+            self.hass,
+            self._trigger_config,
+            self.async_trigger,
+            DOMAIN,
+            str(self.name),
+            self._log_callback,
+            home_assistant_start,
+            variables,
+        )
+
+
+@dataclass(slots=True)
+class AutomationEntityConfig:
+    """Container for prepared automation entity configuration."""
+
+    config_block: ConfigType
+    list_no: int
+    raw_blueprint_inputs: ConfigType | None
+    raw_config: ConfigType | None
+    validation_failed: bool
+
+
+async def _prepare_automation_config(
+    hass: HomeAssistant,
+    config: ConfigType,
+) -> list[AutomationEntityConfig]:
+    """Parse configuration and prepare automation entity configuration."""
+    automation_configs: list[AutomationEntityConfig] = []
+
+    conf: list[ConfigType] = config[DOMAIN]
+
+    for list_no, config_block in enumerate(conf):
+        raw_config = cast(AutomationConfig, config_block).raw_config
+        raw_blueprint_inputs = cast(AutomationConfig, config_block).raw_blueprint_inputs
+        validation_failed = cast(AutomationConfig, config_block).validation_failed
+        automation_configs.append(
+            AutomationEntityConfig(
+                config_block,
+                list_no,
+                raw_blueprint_inputs,
+                raw_config,
+                validation_failed,
+            )
+        )
+
+    return automation_configs
+
+
+def _automation_name(automation_config: AutomationEntityConfig) -> str:
+    """Return the configured name of an automation."""
+    config_block = automation_config.config_block
+    list_no = automation_config.list_no
+    return config_block.get(CONF_ALIAS) or f"{DOMAIN} {list_no}"
+
+
+async def _create_automation_entities(
+    hass: HomeAssistant, automation_configs: list[AutomationEntityConfig]
+) -> list[BaseAutomationEntity]:
+    """Create automation entities from prepared configuration."""
+    entities: list[BaseAutomationEntity] = []
+
+    for automation_config in automation_configs:
+        config_block = automation_config.config_block
+
+        automation_id: str | None = config_block.get(CONF_ID)
+        name = _automation_name(automation_config)
+
+        if automation_config.validation_failed:
+            entities.append(
+                UnavailableAutomationEntity(
+                    automation_id,
+                    name,
+                    automation_config.raw_config,
+                )
+            )
+            continue
+
+        initial_state: bool | None = config_block.get(CONF_INITIAL_STATE)
+
+        action_script = Script(
+            hass,
+            config_block[CONF_ACTION],
+            name,
+            DOMAIN,
+            running_description="automation actions",
+            script_mode=config_block[CONF_MODE],
+            max_runs=config_block[CONF_MAX],
+            max_exceeded=config_block[CONF_MAX_EXCEEDED],
+            logger=LOGGER,
+            # We don't pass variables here
+            # Automation will already render them to use them in the condition
+            # and so will pass them on to the script.
+        )
+
+        if CONF_CONDITION in config_block:
+            cond_func = await _async_process_if(hass, name, config_block)
+
+            if cond_func is None:
+                continue
+        else:
+            cond_func = None
+
+        # Add trigger variables to variables
+        variables = None
+        if CONF_TRIGGER_VARIABLES in config_block:
+            variables = ScriptVariables(
+                dict(config_block[CONF_TRIGGER_VARIABLES].as_dict())
+            )
+        if CONF_VARIABLES in config_block:
+            if variables:
+                variables.variables.update(config_block[CONF_VARIABLES].as_dict())
+            else:
+                variables = config_block[CONF_VARIABLES]
+
+        entity = AutomationEntity(
+            automation_id,
+            name,
+            config_block[CONF_TRIGGER],
+            cond_func,
+            action_script,
+            initial_state,
+            variables,
+            config_block.get(CONF_TRIGGER_VARIABLES),
+            automation_config.raw_config,
+            automation_config.raw_blueprint_inputs,
+            config_block[CONF_TRACE],
+        )
+        entities.append(entity)
+
+    return entities
+
+
+async def _async_process_config(
+    hass: HomeAssistant,
+    config: dict[str, Any],
+    component: EntityComponent[BaseAutomationEntity],
+) -> None:
+    """Process config and add automations."""
+
+    def automation_matches_config(
+        automation: BaseAutomationEntity, config: AutomationEntityConfig
+    ) -> bool:
+        name = _automation_name(config)
+        return automation.name == name and automation.raw_config == config.raw_config
+
+    def find_matches(
+        automations: list[BaseAutomationEntity],
+        automation_configs: list[AutomationEntityConfig],
+    ) -> tuple[set[int], set[int]]:
+        """Find matches between a list of automation entities and a list of configurations.
+
+        An automation or configuration is only allowed to match at most once to handle
+        the case of multiple automations with identical configuration.
+
+        Returns a tuple of sets of indices: ({automation_matches}, {config_matches})
+        """
+        automation_matches: set[int] = set()
+        config_matches: set[int] = set()
+        automation_configs_with_id: dict[str, tuple[int, AutomationEntityConfig]] = {}
+        automation_configs_without_id: list[tuple[int, AutomationEntityConfig]] = []
+
+        for config_idx, config in enumerate(automation_configs):
+            if automation_id := config.config_block.get(CONF_ID):
+                automation_configs_with_id[automation_id] = (config_idx, config)
+                continue
+            automation_configs_without_id.append((config_idx, config))
+
+        for automation_idx, automation in enumerate(automations):
+            if automation.unique_id:
+                if automation.unique_id not in automation_configs_with_id:
+                    continue
+                config_idx, config = automation_configs_with_id.pop(
+                    automation.unique_id
+                )
+                if automation_matches_config(automation, config):
+                    automation_matches.add(automation_idx)
+                    config_matches.add(config_idx)
+                continue
+
+            for config_idx, config in automation_configs_without_id:
+                if config_idx in config_matches:
+                    # Only allow an automation config to match at most once
+                    continue
+                if automation_matches_config(automation, config):
+                    automation_matches.add(automation_idx)
+                    config_matches.add(config_idx)
+                    # Only allow an automation to match at most once
+                    break
+
+        return automation_matches, config_matches
+
+    automation_configs = await _prepare_automation_config(hass, config)
+    automations: list[BaseAutomationEntity] = list(component.entities)
+
+    # Find automations and configurations which have matches
+    automation_matches, config_matches = find_matches(automations, automation_configs)
+
+    # Remove automations which have changed config or no longer exist
+    tasks = [
+        automation.async_remove()
+        for idx, automation in enumerate(automations)
+        if idx not in automation_matches
+    ]
+    await asyncio.gather(*tasks)
+
+    # Create automations which have changed config or have been added
+    updated_automation_configs = [
+        config
+        for idx, config in enumerate(automation_configs)
+        if idx not in config_matches
+    ]
+    entities = await _create_automation_entities(hass, updated_automation_configs)
+    await component.async_add_entities(entities)
+
+
+async def _async_process_if(
+    hass: HomeAssistant, name: str, config: dict[str, Any]
+) -> IfAction | None:
+    """Process if checks."""
+    if_configs = config[CONF_CONDITION]
+
+    checks: list[condition.ConditionCheckerType] = []
+    for if_config in if_configs:
+        try:
+            #lqg add
+            # 解析条件时，绑定当前自动化的 ID 和上下文（从 config 中获取）
+            automation_id = config.get("unique_id")  # 从自动化配置中获取唯一ID
+            checks.append(await condition.async_from_config(
+                hass, 
+                if_config,
+                # 新增：传递自动化ID和上下文给 condition.py
+                automation_id=automation_id,
+                context=config.get("context")
+            ))
+            #checks.append(await condition.async_from_config(hass, if_config))
+        except HomeAssistantError as ex:
+            LOGGER.warning("Invalid condition: %s", ex)
+            return None
+
+    def if_action(variables: Mapping[str, Any] | None = None) -> bool:
+        """AND all conditions."""
+        errors: list[ConditionErrorIndex] = []
+        for index, check in enumerate(checks):
+            try:
+                with trace_path(["condition", str(index)]):
+                    if check(hass, variables) is False:
+                        return False
+            except ConditionError as ex:
+                errors.append(
+                    ConditionErrorIndex(
+                        "condition", index=index, total=len(checks), error=ex
+                    )
+                )
+
+        if errors:
+            LOGGER.warning(
+                "Error evaluating condition in '%s':\n%s",
+                name,
+                ConditionErrorContainer("condition", errors=errors),
+            )
+            return False
+
+        return True
+
+    result: IfAction = if_action  # type: ignore[assignment]
+    result.config = if_configs
+
+    return result
+
+
+@callback
+def _trigger_extract_devices(trigger_conf: dict) -> list[str]:
+    """Extract devices from a trigger config."""
+    if trigger_conf[CONF_PLATFORM] == "device":
+        return [trigger_conf[CONF_DEVICE_ID]]
+
+    if (
+        trigger_conf[CONF_PLATFORM] == "event"
+        and CONF_EVENT_DATA in trigger_conf
+        and CONF_DEVICE_ID in trigger_conf[CONF_EVENT_DATA]
+        and isinstance(trigger_conf[CONF_EVENT_DATA][CONF_DEVICE_ID], str)
+    ):
+        return [trigger_conf[CONF_EVENT_DATA][CONF_DEVICE_ID]]
+
+    if trigger_conf[CONF_PLATFORM] == "tag" and CONF_DEVICE_ID in trigger_conf:
+        return trigger_conf[CONF_DEVICE_ID]  # type: ignore[no-any-return]
+
+    return []
+
+
+@callback
+def _trigger_extract_entities(trigger_conf: dict) -> list[str]:
+    """Extract entities from a trigger config."""
+    if trigger_conf[CONF_PLATFORM] in ("state", "numeric_state"):
+        return trigger_conf[CONF_ENTITY_ID]  # type: ignore[no-any-return]
+
+    if trigger_conf[CONF_PLATFORM] == "calendar":
+        return [trigger_conf[CONF_ENTITY_ID]]
+
+    if trigger_conf[CONF_PLATFORM] == "zone":
+        return trigger_conf[CONF_ENTITY_ID] + [trigger_conf[CONF_ZONE]]  # type: ignore[no-any-return]
+
+    if trigger_conf[CONF_PLATFORM] == "geo_location":
+        return [trigger_conf[CONF_ZONE]]
+
+    if trigger_conf[CONF_PLATFORM] == "sun":
+        return ["sun.sun"]
+
+    if (
+        trigger_conf[CONF_PLATFORM] == "event"
+        and CONF_EVENT_DATA in trigger_conf
+        and CONF_ENTITY_ID in trigger_conf[CONF_EVENT_DATA]
+        and isinstance(trigger_conf[CONF_EVENT_DATA][CONF_ENTITY_ID], str)
+        and valid_entity_id(trigger_conf[CONF_EVENT_DATA][CONF_ENTITY_ID])
+    ):
+        return [trigger_conf[CONF_EVENT_DATA][CONF_ENTITY_ID]]
+
+    return []
+
+
+@websocket_api.websocket_command({"type": "automation/config", "entity_id": str})
+def websocket_config(
+    hass: HomeAssistant,
+    connection: websocket_api.ActiveConnection,
+    msg: dict[str, Any],
+) -> None:
+    """Get automation config."""
+    component: EntityComponent[BaseAutomationEntity] = hass.data[DOMAIN]
+
+    automation = component.get_entity(msg["entity_id"])
+
+    if automation is None:
+        connection.send_error(
+            msg["id"], websocket_api.const.ERR_NOT_FOUND, "Entity not found"
+        )
+        return
+
+    connection.send_result(
+        msg["id"],
+        {
+            "config": automation.raw_config,
+        },
+    )
+
+
+# These can be removed if no deprecated constant are in this module anymore
+__getattr__ = partial(check_if_deprecated_constant, module_globals=globals())
+__dir__ = partial(
+    dir_with_deprecated_constants, module_globals_keys=[*globals().keys()]
+)
+__all__ = all_with_deprecated_constants(globals())
diff -urN -x __pycache__ -x '*.pyc' /tmp/homeassistant-2024.1.5/homeassistant/core-bk-20251223.py /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/core-bk-20251223.py
--- /tmp/homeassistant-2024.1.5/homeassistant/core-bk-20251223.py	1970-01-01 08:00:00.000000000 +0800
+++ /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/core-bk-20251223.py	2025-12-23 18:14:26.727143105 +0800
@@ -0,0 +1,2618 @@
+"""Core components of Home Assistant.
+
+Home Assistant is a Home Automation framework for observing the state
+of entities and react to changes.
+"""
+from __future__ import annotations
+
+
+"""
+from homeassistant.helpers.provenance import(
+    actionFilterModule,
+    #createTemporalRelation
+)"""
+from homeassistant.helpers.provenance import(
+    log_state_change, 
+    save_log,
+    record_event,
+    get_friendly_name
+)
+
+
+import asyncio
+from collections import UserDict, defaultdict
+from collections.abc import (
+    Callable,
+    Collection,
+    Coroutine,
+    Iterable,
+    KeysView,
+    Mapping,
+    ValuesView,
+)
+import concurrent.futures
+from contextlib import suppress
+from dataclasses import dataclass
+import datetime
+import enum
+import functools
+import logging
+import os
+import pathlib
+import re
+import threading
+import time
+from time import monotonic
+from typing import (
+    TYPE_CHECKING,
+    Any,
+    Generic,
+    Literal,
+    ParamSpec,
+    Self,
+    TypeVar,
+    cast,
+    overload,
+)
+from urllib.parse import urlparse
+
+import voluptuous as vol
+import yarl
+
+from . import block_async_io, util
+from .backports.functools import cached_property
+from .const import (
+    ATTR_DOMAIN,
+    ATTR_FRIENDLY_NAME,
+    ATTR_SERVICE,
+    ATTR_SERVICE_DATA,
+    COMPRESSED_STATE_ATTRIBUTES,
+    COMPRESSED_STATE_CONTEXT,
+    COMPRESSED_STATE_LAST_CHANGED,
+    COMPRESSED_STATE_LAST_UPDATED,
+    COMPRESSED_STATE_STATE,
+    EVENT_CALL_SERVICE,
+    EVENT_CORE_CONFIG_UPDATE,
+    EVENT_HOMEASSISTANT_CLOSE,
+    EVENT_HOMEASSISTANT_FINAL_WRITE,
+    EVENT_HOMEASSISTANT_START,
+    EVENT_HOMEASSISTANT_STARTED,
+    EVENT_HOMEASSISTANT_STOP,
+    EVENT_SERVICE_REGISTERED,
+    EVENT_SERVICE_REMOVED,
+    EVENT_STATE_CHANGED,
+    MATCH_ALL,
+    MAX_LENGTH_EVENT_EVENT_TYPE,
+    MAX_LENGTH_STATE_STATE,
+    UnitOfLength,
+    __version__,
+)
+from .exceptions import (
+    HomeAssistantError,
+    InvalidEntityFormatError,
+    InvalidStateError,
+    MaxLengthExceeded,
+    ServiceNotFound,
+    Unauthorized,
+)
+from .helpers.deprecation import (
+    DeprecatedConstantEnum,
+    all_with_deprecated_constants,
+    check_if_deprecated_constant,
+    dir_with_deprecated_constants,
+)
+from .helpers.json import json_dumps
+from .util import dt as dt_util, location
+from .util.async_ import (
+    cancelling,
+    run_callback_threadsafe,
+    shutdown_run_callback_threadsafe,
+)
+from .util.json import JsonObjectType
+from .util.read_only_dict import ReadOnlyDict
+from .util.timeout import TimeoutManager
+from .util.ulid import ulid_at_time, ulid_now
+from .util.unit_system import (
+    _CONF_UNIT_SYSTEM_IMPERIAL,
+    _CONF_UNIT_SYSTEM_US_CUSTOMARY,
+    METRIC_SYSTEM,
+    UnitSystem,
+    get_unit_system,
+)
+
+# Typing imports that create a circular dependency
+if TYPE_CHECKING:
+    from .auth import AuthManager
+    from .components.http import ApiConfig, HomeAssistantHTTP
+    from .config_entries import ConfigEntries
+    from .helpers.entity import StateInfo
+
+
+STOPPING_STAGE_SHUTDOWN_TIMEOUT = 20
+STOP_STAGE_SHUTDOWN_TIMEOUT = 100
+FINAL_WRITE_STAGE_SHUTDOWN_TIMEOUT = 60
+CLOSE_STAGE_SHUTDOWN_TIMEOUT = 30
+
+block_async_io.enable()
+
+_T = TypeVar("_T")
+_R = TypeVar("_R")
+_R_co = TypeVar("_R_co", covariant=True)
+_P = ParamSpec("_P")
+# Internal; not helpers.typing.UNDEFINED due to circular dependency
+_UNDEF: dict[Any, Any] = {}
+_CallableT = TypeVar("_CallableT", bound=Callable[..., Any])
+CALLBACK_TYPE = Callable[[], None]
+
+CORE_STORAGE_KEY = "core.config"
+CORE_STORAGE_VERSION = 1
+CORE_STORAGE_MINOR_VERSION = 3
+
+DOMAIN = "homeassistant"
+
+# How long to wait to log tasks that are blocking
+BLOCK_LOG_TIMEOUT = 60
+
+ServiceResponse = JsonObjectType | None
+EntityServiceResponse = dict[str, ServiceResponse]
+
+
+class ConfigSource(enum.StrEnum):
+    """Source of core configuration."""
+
+    DEFAULT = "default"
+    DISCOVERED = "discovered"
+    STORAGE = "storage"
+    YAML = "yaml"
+
+
+# SOURCE_* are deprecated as of Home Assistant 2022.2, use ConfigSource instead
+_DEPRECATED_SOURCE_DISCOVERED = DeprecatedConstantEnum(
+    ConfigSource.DISCOVERED, "2025.1"
+)
+_DEPRECATED_SOURCE_STORAGE = DeprecatedConstantEnum(ConfigSource.STORAGE, "2025.1")
+_DEPRECATED_SOURCE_YAML = DeprecatedConstantEnum(ConfigSource.YAML, "2025.1")
+
+
+# How long to wait until things that run on startup have to finish.
+TIMEOUT_EVENT_START = 15
+
+MAX_EXPECTED_ENTITY_IDS = 16384
+
+_LOGGER = logging.getLogger(__name__)
+
+
+@functools.lru_cache(MAX_EXPECTED_ENTITY_IDS)
+def split_entity_id(entity_id: str) -> tuple[str, str]:
+    """Split a state entity ID into domain and object ID."""
+    domain, _, object_id = entity_id.partition(".")
+    if not domain or not object_id:
+        raise ValueError(f"Invalid entity ID {entity_id}")
+    return domain, object_id
+
+
+_OBJECT_ID = r"(?!_)[\da-z_]+(?<!_)"
+_DOMAIN = r"(?!.+__)" + _OBJECT_ID
+VALID_DOMAIN = re.compile(r"^" + _DOMAIN + r"$")
+VALID_ENTITY_ID = re.compile(r"^" + _DOMAIN + r"\." + _OBJECT_ID + r"$")
+
+
+@functools.lru_cache(64)
+def valid_domain(domain: str) -> bool:
+    """Test if a domain a valid format."""
+    return VALID_DOMAIN.match(domain) is not None
+
+
+@functools.lru_cache(512)
+def valid_entity_id(entity_id: str) -> bool:
+    """Test if an entity ID is a valid format.
+
+    Format: <domain>.<entity> where both are slugs.
+    """
+    return VALID_ENTITY_ID.match(entity_id) is not None
+
+
+def validate_state(state: str) -> str:
+    """Validate a state, raise if it not valid."""
+    if len(state) > MAX_LENGTH_STATE_STATE:
+        raise InvalidStateError(
+            f"Invalid state with length {len(state)}. "
+            "State max length is 255 characters."
+        )
+    return state
+
+
+def callback(func: _CallableT) -> _CallableT:
+    """Annotation to mark method as safe to call from within the event loop."""
+    setattr(func, "_hass_callback", True)
+    return func
+
+
+def is_callback(func: Callable[..., Any]) -> bool:
+    """Check if function is safe to be called in the event loop."""
+    return getattr(func, "_hass_callback", False) is True
+
+
+def is_callback_check_partial(target: Callable[..., Any]) -> bool:
+    """Check if function is safe to be called in the event loop.
+
+    This version of is_callback will also check if the target is a partial
+    and walk the chain of partials to find the original function.
+    """
+    check_target = target
+    while isinstance(check_target, functools.partial):
+        check_target = check_target.func
+    return is_callback(check_target)
+
+
+class _Hass(threading.local):
+    """Container which makes a HomeAssistant instance available to the event loop."""
+
+    hass: HomeAssistant | None = None
+
+
+_hass = _Hass()
+
+
+@callback
+def async_get_hass() -> HomeAssistant:
+    """Return the HomeAssistant instance.
+
+    Raises HomeAssistantError when called from the wrong thread.
+
+    This should be used where it's very cumbersome or downright impossible to pass
+    hass to the code which needs it.
+    """
+    if not _hass.hass:
+        raise HomeAssistantError("async_get_hass called from the wrong thread")
+    return _hass.hass
+
+
+@callback
+def get_release_channel() -> Literal["beta", "dev", "nightly", "stable"]:
+    """Find release channel based on version number."""
+    version = __version__
+    if "dev0" in version:
+        return "dev"
+    if "dev" in version:
+        return "nightly"
+    if "b" in version:
+        return "beta"
+    return "stable"
+
+
+@enum.unique
+class HassJobType(enum.Enum):
+    """Represent a job type."""
+
+    Coroutinefunction = 1
+    Callback = 2
+    Executor = 3
+
+
+class HassJob(Generic[_P, _R_co]):
+    """Represent a job to be run later.
+
+    We check the callable type in advance
+    so we can avoid checking it every time
+    we run the job.
+    """
+
+    __slots__ = ("job_type", "target", "name", "_cancel_on_shutdown")
+
+    def __init__(
+        self,
+        target: Callable[_P, _R_co],
+        name: str | None = None,
+        *,
+        cancel_on_shutdown: bool | None = None,
+        job_type: HassJobType | None = None,
+    ) -> None:
+        """Create a job object."""
+        self.target = target
+        self.name = name
+        self.job_type = job_type or _get_hassjob_callable_job_type(target)
+        self._cancel_on_shutdown = cancel_on_shutdown
+
+    @property
+    def cancel_on_shutdown(self) -> bool | None:
+        """Return if the job should be cancelled on shutdown."""
+        return self._cancel_on_shutdown
+
+    def __repr__(self) -> str:
+        """Return the job."""
+        return f"<Job {self.name} {self.job_type} {self.target}>"
+
+
+@dataclass(frozen=True)
+class HassJobWithArgs:
+    """Container for a HassJob and arguments."""
+
+    job: HassJob[..., Coroutine[Any, Any, Any] | Any]
+    args: Iterable[Any]
+
+
+def _get_hassjob_callable_job_type(target: Callable[..., Any]) -> HassJobType:
+    """Determine the job type from the callable."""
+    # Check for partials to properly determine if coroutine function
+    check_target = target
+    while isinstance(check_target, functools.partial):
+        check_target = check_target.func
+
+    if asyncio.iscoroutinefunction(check_target):
+        return HassJobType.Coroutinefunction
+    if is_callback(check_target):
+        return HassJobType.Callback
+    if asyncio.iscoroutine(check_target):
+        raise ValueError("Coroutine not allowed to be passed to HassJob")
+    return HassJobType.Executor
+
+
+class CoreState(enum.Enum):
+    """Represent the current state of Home Assistant."""
+
+    not_running = "NOT_RUNNING"
+    starting = "STARTING"
+    running = "RUNNING"
+    stopping = "STOPPING"
+    final_write = "FINAL_WRITE"
+    stopped = "STOPPED"
+
+    def __str__(self) -> str:
+        """Return the event."""
+        return self.value
+
+
+class HomeAssistant:
+    """Root object of the Home Assistant home automation."""
+
+    auth: AuthManager
+    http: HomeAssistantHTTP = None  # type: ignore[assignment]
+    config_entries: ConfigEntries = None  # type: ignore[assignment]
+
+    def __new__(cls, config_dir: str) -> HomeAssistant:
+        """Set the _hass thread local data."""
+        hass = super().__new__(cls)
+        _hass.hass = hass
+        return hass
+
+    def __repr__(self) -> str:
+        """Return the representation."""
+        return f"<HomeAssistant {self.state}>"
+
+    def __init__(self, config_dir: str) -> None:
+        """Initialize new Home Assistant object."""
+        # pylint: disable-next=import-outside-toplevel
+        from . import loader
+
+        self.loop = asyncio.get_running_loop()
+        self._tasks: set[asyncio.Future[Any]] = set()
+        self._background_tasks: set[asyncio.Future[Any]] = set()
+        self.bus = EventBus(self)
+        self.services = ServiceRegistry(self)
+        self.states = StateMachine(self.bus, self.loop)
+        self.config = Config(self, config_dir)
+        self.components = loader.Components(self)
+        self.helpers = loader.Helpers(self)
+        # This is a dictionary that any component can store any data on.
+        self.data: dict[str, Any] = {}
+        self.state: CoreState = CoreState.not_running
+        self.exit_code: int = 0
+        # If not None, use to signal end-of-loop
+        self._stopped: asyncio.Event | None = None
+        # Timeout handler for Core/Helper namespace
+        self.timeout: TimeoutManager = TimeoutManager()
+        self._stop_future: concurrent.futures.Future[None] | None = None
+        self._shutdown_jobs: list[HassJobWithArgs] = []
+
+    @property
+    def is_running(self) -> bool:
+        """Return if Home Assistant is running."""
+        return self.state in (CoreState.starting, CoreState.running)
+
+    @property
+    def is_stopping(self) -> bool:
+        """Return if Home Assistant is stopping."""
+        return self.state in (CoreState.stopping, CoreState.final_write)
+
+    def start(self) -> int:
+        """Start Home Assistant.
+
+        Note: This function is only used for testing.
+        For regular use, use "await hass.run()".
+        """
+        # Register the async start
+        _future = asyncio.run_coroutine_threadsafe(self.async_start(), self.loop)
+        # Run forever
+        # Block until stopped
+        _LOGGER.info("Starting Home Assistant core loop")
+        self.loop.run_forever()
+        # The future is never retrieved but we still hold a reference to it
+        # to prevent the task from being garbage collected prematurely.
+        del _future
+        return self.exit_code
+
+    async def async_run(self, *, attach_signals: bool = True) -> int:
+        """Home Assistant main entry point.
+
+        Start Home Assistant and block until stopped.
+
+        This method is a coroutine.
+        """
+        if self.state != CoreState.not_running:
+            raise RuntimeError("Home Assistant is already running")
+
+        # _async_stop will set this instead of stopping the loop
+        self._stopped = asyncio.Event()
+
+        await self.async_start()
+        if attach_signals:
+            # pylint: disable-next=import-outside-toplevel
+            from .helpers.signal import async_register_signal_handling
+
+            async_register_signal_handling(self)
+
+        await self._stopped.wait()
+        return self.exit_code
+
+    async def async_start(self) -> None:
+        """Finalize startup from inside the event loop.
+
+        This method is a coroutine.
+        """
+        _LOGGER.info("Starting Home Assistant")
+        setattr(self.loop, "_thread_ident", threading.get_ident())
+
+        self.state = CoreState.starting
+        self.bus.async_fire(EVENT_CORE_CONFIG_UPDATE)
+        self.bus.async_fire(EVENT_HOMEASSISTANT_START)
+
+        if not self._tasks:
+            pending: set[asyncio.Future[Any]] | None = None
+        else:
+            _done, pending = await asyncio.wait(
+                self._tasks, timeout=TIMEOUT_EVENT_START
+            )
+
+        if pending:
+            _LOGGER.warning(
+                (
+                    "Something is blocking Home Assistant from wrapping up the start up"
+                    " phase. We're going to continue anyway. Please report the"
+                    " following info at"
+                    " https://github.com/home-assistant/core/issues: %s"
+                ),
+                ", ".join(self.config.components),
+            )
+
+        # Allow automations to set up the start triggers before changing state
+        await asyncio.sleep(0)
+
+        if self.state != CoreState.starting:
+            _LOGGER.warning(
+                "Home Assistant startup has been interrupted. "
+                "Its state may be inconsistent"
+            )
+            return
+
+        self.state = CoreState.running
+        self.bus.async_fire(EVENT_CORE_CONFIG_UPDATE)
+        self.bus.async_fire(EVENT_HOMEASSISTANT_STARTED)
+
+    def add_job(
+        self, target: Callable[..., Any] | Coroutine[Any, Any, Any], *args: Any
+    ) -> None:
+        """Add a job to be executed by the event loop or by an executor.
+
+        If the job is either a coroutine or decorated with @callback, it will be
+        run by the event loop, if not it will be run by an executor.
+
+        target: target to call.
+        args: parameters for method to call.
+        """
+        if target is None:
+            raise ValueError("Don't call add_job with None")
+        self.loop.call_soon_threadsafe(self.async_add_job, target, *args)
+
+    @overload
+    @callback
+    def async_add_job(
+        self, target: Callable[..., Coroutine[Any, Any, _R]], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @overload
+    @callback
+    def async_add_job(
+        self, target: Callable[..., Coroutine[Any, Any, _R] | _R], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @overload
+    @callback
+    def async_add_job(
+        self, target: Coroutine[Any, Any, _R], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @callback
+    def async_add_job(
+        self,
+        target: Callable[..., Coroutine[Any, Any, _R] | _R] | Coroutine[Any, Any, _R],
+        *args: Any,
+    ) -> asyncio.Future[_R] | None:
+        """Add a job to be executed by the event loop or by an executor.
+
+        If the job is either a coroutine or decorated with @callback, it will be
+        run by the event loop, if not it will be run by an executor.
+
+        This method must be run in the event loop.
+
+        target: target to call.
+        args: parameters for method to call.
+        """
+        if target is None:
+            raise ValueError("Don't call async_add_job with None")
+
+        if asyncio.iscoroutine(target):
+            return self.async_create_task(target)
+
+        # This code path is performance sensitive and uses
+        # if TYPE_CHECKING to avoid the overhead of constructing
+        # the type used for the cast. For history see:
+        # https://github.com/home-assistant/core/pull/71960
+        if TYPE_CHECKING:
+            target = cast(Callable[..., Coroutine[Any, Any, _R] | _R], target)
+        return self.async_add_hass_job(HassJob(target), *args)
+
+    @overload
+    @callback
+    def async_add_hass_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, _R]], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @overload
+    @callback
+    def async_add_hass_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, _R] | _R], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @callback
+    def async_add_hass_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, _R] | _R], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        """Add a HassJob from within the event loop.
+
+        This method must be run in the event loop.
+        hassjob: HassJob to call.
+        args: parameters for method to call.
+        """
+        task: asyncio.Future[_R]
+        # This code path is performance sensitive and uses
+        # if TYPE_CHECKING to avoid the overhead of constructing
+        # the type used for the cast. For history see:
+        # https://github.com/home-assistant/core/pull/71960
+        if hassjob.job_type == HassJobType.Coroutinefunction:
+            if TYPE_CHECKING:
+                hassjob.target = cast(
+                    Callable[..., Coroutine[Any, Any, _R]], hassjob.target
+                )
+            task = self.loop.create_task(hassjob.target(*args), name=hassjob.name)
+        elif hassjob.job_type == HassJobType.Callback:
+            if TYPE_CHECKING:
+                hassjob.target = cast(Callable[..., _R], hassjob.target)
+            self.loop.call_soon(hassjob.target, *args)
+            return None
+        else:
+            if TYPE_CHECKING:
+                hassjob.target = cast(Callable[..., _R], hassjob.target)
+            task = self.loop.run_in_executor(None, hassjob.target, *args)
+
+        self._tasks.add(task)
+        task.add_done_callback(self._tasks.remove)
+
+        return task
+
+    def create_task(
+        self, target: Coroutine[Any, Any, Any], name: str | None = None
+    ) -> None:
+        """Add task to the executor pool.
+
+        target: target to call.
+        """
+        self.loop.call_soon_threadsafe(self.async_create_task, target, name)
+
+    @callback
+    def async_create_task(
+        self, target: Coroutine[Any, Any, _R], name: str | None = None
+    ) -> asyncio.Task[_R]:
+        """Create a task from within the event loop.
+
+        This method must be run in the event loop. If you are using this in your
+        integration, use the create task methods on the config entry instead.
+
+        target: target to call.
+        """
+        task = self.loop.create_task(target, name=name)
+        self._tasks.add(task)
+        task.add_done_callback(self._tasks.remove)
+        return task
+
+    @callback
+    def async_create_background_task(
+        self,
+        target: Coroutine[Any, Any, _R],
+        name: str,
+    ) -> asyncio.Task[_R]:
+        """Create a task from within the event loop.
+
+        This is a background task which will not block startup and will be
+        automatically cancelled on shutdown. If you are using this in your
+        integration, use the create task methods on the config entry instead.
+
+        This method must be run in the event loop.
+        """
+        task = self.loop.create_task(target, name=name)
+        self._background_tasks.add(task)
+        task.add_done_callback(self._background_tasks.remove)
+        return task
+
+    @callback
+    def async_add_executor_job(
+        self, target: Callable[..., _T], *args: Any
+    ) -> asyncio.Future[_T]:
+        """Add an executor job from within the event loop."""
+        task = self.loop.run_in_executor(None, target, *args)
+        self._tasks.add(task)
+        task.add_done_callback(self._tasks.remove)
+
+        return task
+
+    @overload
+    @callback
+    def async_run_hass_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, _R]], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @overload
+    @callback
+    def async_run_hass_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, _R] | _R], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @callback
+    def async_run_hass_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, _R] | _R], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        """Run a HassJob from within the event loop.
+
+        This method must be run in the event loop.
+
+        hassjob: HassJob
+        args: parameters for method to call.
+        """
+        # This code path is performance sensitive and uses
+        # if TYPE_CHECKING to avoid the overhead of constructing
+        # the type used for the cast. For history see:
+        # https://github.com/home-assistant/core/pull/71960
+        if hassjob.job_type == HassJobType.Callback:
+            if TYPE_CHECKING:
+                hassjob.target = cast(Callable[..., _R], hassjob.target)
+            hassjob.target(*args)
+            return None
+
+        return self.async_add_hass_job(hassjob, *args)
+
+    @overload
+    @callback
+    def async_run_job(
+        self, target: Callable[..., Coroutine[Any, Any, _R]], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @overload
+    @callback
+    def async_run_job(
+        self, target: Callable[..., Coroutine[Any, Any, _R] | _R], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @overload
+    @callback
+    def async_run_job(
+        self, target: Coroutine[Any, Any, _R], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @callback
+    def async_run_job(
+        self,
+        target: Callable[..., Coroutine[Any, Any, _R] | _R] | Coroutine[Any, Any, _R],
+        *args: Any,
+    ) -> asyncio.Future[_R] | None:
+        """Run a job from within the event loop.
+
+        This method must be run in the event loop.
+
+        target: target to call.
+        args: parameters for method to call.
+        """
+        if asyncio.iscoroutine(target):
+            return self.async_create_task(target)
+
+        # This code path is performance sensitive and uses
+        # if TYPE_CHECKING to avoid the overhead of constructing
+        # the type used for the cast. For history see:
+        # https://github.com/home-assistant/core/pull/71960
+        if TYPE_CHECKING:
+            target = cast(Callable[..., Coroutine[Any, Any, _R] | _R], target)
+        return self.async_run_hass_job(HassJob(target), *args)
+
+    def block_till_done(self) -> None:
+        """Block until all pending work is done."""
+        asyncio.run_coroutine_threadsafe(
+            self.async_block_till_done(), self.loop
+        ).result()
+
+    async def async_block_till_done(self) -> None:
+        """Block until all pending work is done."""
+        # To flush out any call_soon_threadsafe
+        await asyncio.sleep(0)
+        start_time: float | None = None
+        current_task = asyncio.current_task()
+
+        while tasks := [
+            task
+            for task in self._tasks
+            if task is not current_task and not cancelling(task)
+        ]:
+            await self._await_and_log_pending(tasks)
+
+            if start_time is None:
+                # Avoid calling monotonic() until we know
+                # we may need to start logging blocked tasks.
+                start_time = 0
+            elif start_time == 0:
+                # If we have waited twice then we set the start
+                # time
+                start_time = monotonic()
+            elif monotonic() - start_time > BLOCK_LOG_TIMEOUT:
+                # We have waited at least three loops and new tasks
+                # continue to block. At this point we start
+                # logging all waiting tasks.
+                for task in tasks:
+                    _LOGGER.debug("Waiting for task: %s", task)
+
+    async def _await_and_log_pending(
+        self, pending: Collection[asyncio.Future[Any]]
+    ) -> None:
+        """Await and log tasks that take a long time."""
+        wait_time = 0
+        while pending:
+            _, pending = await asyncio.wait(pending, timeout=BLOCK_LOG_TIMEOUT)
+            if not pending:
+                return
+            wait_time += BLOCK_LOG_TIMEOUT
+            for task in pending:
+                _LOGGER.debug("Waited %s seconds for task: %s", wait_time, task)
+
+    @overload
+    @callback
+    def async_add_shutdown_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, Any]], *args: Any
+    ) -> CALLBACK_TYPE:
+        ...
+
+    @overload
+    @callback
+    def async_add_shutdown_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, Any] | Any], *args: Any
+    ) -> CALLBACK_TYPE:
+        ...
+
+    @callback
+    def async_add_shutdown_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, Any] | Any], *args: Any
+    ) -> CALLBACK_TYPE:
+        """Add a HassJob which will be executed on shutdown.
+
+        This method must be run in the event loop.
+
+        hassjob: HassJob
+        args: parameters for method to call.
+
+        Returns function to remove the job.
+        """
+        job_with_args = HassJobWithArgs(hassjob, args)
+        self._shutdown_jobs.append(job_with_args)
+
+        @callback
+        def remove_job() -> None:
+            self._shutdown_jobs.remove(job_with_args)
+
+        return remove_job
+
+    def stop(self) -> None:
+        """Stop Home Assistant and shuts down all threads."""
+        if self.state == CoreState.not_running:  # just ignore
+            return
+        # The future is never retrieved, and we only hold a reference
+        # to it to prevent it from being garbage collected.
+        self._stop_future = asyncio.run_coroutine_threadsafe(
+            self.async_stop(), self.loop
+        )
+
+    async def async_stop(self, exit_code: int = 0, *, force: bool = False) -> None:
+        """Stop Home Assistant and shuts down all threads.
+
+        The "force" flag commands async_stop to proceed regardless of
+        Home Assistant's current state. You should not set this flag
+        unless you're testing.
+
+        This method is a coroutine.
+        """
+        #lqg : save log
+        _LOGGER.warning("=======")
+        save_log('/home/homeassistant/.homeassistant/provenance_log.json')
+        if not force:
+            # Some tests require async_stop to run,
+            # regardless of the state of the loop.
+            if self.state == CoreState.not_running:  # just ignore
+                return
+            if self.state in [CoreState.stopping, CoreState.final_write]:
+                _LOGGER.info("Additional call to async_stop was ignored")
+                return
+            if self.state == CoreState.starting:
+                # This may not work
+                _LOGGER.warning(
+                    "Stopping Home Assistant before startup has completed may fail"
+                )
+
+        # Stage 1 - Run shutdown jobs
+        try:
+            async with self.timeout.async_timeout(STOPPING_STAGE_SHUTDOWN_TIMEOUT):
+                tasks: list[asyncio.Future[Any]] = []
+                for job in self._shutdown_jobs:
+                    task_or_none = self.async_run_hass_job(job.job, *job.args)
+                    if not task_or_none:
+                        continue
+                    tasks.append(task_or_none)
+                if tasks:
+                    await asyncio.gather(*tasks, return_exceptions=True)
+        except asyncio.TimeoutError:
+            _LOGGER.warning(
+                "Timed out waiting for shutdown jobs to complete, the shutdown will"
+                " continue"
+            )
+            self._async_log_running_tasks("run shutdown jobs")
+
+        # Stage 2 - Stop integrations
+
+        # Keep holding the reference to the tasks but do not allow them
+        # to block shutdown. Only tasks created after this point will
+        # be waited for.
+        running_tasks = self._tasks
+        # Avoid clearing here since we want the remove callbacks to fire
+        # and remove the tasks from the original set which is now running_tasks
+        self._tasks = set()
+
+        # Cancel all background tasks
+        for task in self._background_tasks:
+            self._tasks.add(task)
+            task.add_done_callback(self._tasks.remove)
+            task.cancel("Home Assistant is stopping")
+        self._cancel_cancellable_timers()
+
+        self.exit_code = exit_code
+
+        self.state = CoreState.stopping
+        self.bus.async_fire(EVENT_HOMEASSISTANT_STOP)
+        try:
+            async with self.timeout.async_timeout(STOP_STAGE_SHUTDOWN_TIMEOUT):
+                await self.async_block_till_done()
+        except asyncio.TimeoutError:
+            _LOGGER.warning(
+                "Timed out waiting for integrations to stop, the shutdown will"
+                " continue"
+            )
+            self._async_log_running_tasks("stop integrations")
+
+        # Stage 3 - Final write
+        self.state = CoreState.final_write
+        self.bus.async_fire(EVENT_HOMEASSISTANT_FINAL_WRITE)
+        try:
+            async with self.timeout.async_timeout(FINAL_WRITE_STAGE_SHUTDOWN_TIMEOUT):
+                await self.async_block_till_done()
+        except asyncio.TimeoutError:
+            _LOGGER.warning(
+                "Timed out waiting for final writes to complete, the shutdown will"
+                " continue"
+            )
+            self._async_log_running_tasks("final write")
+
+        # Stage 4 - Close
+        self.state = CoreState.not_running
+        self.bus.async_fire(EVENT_HOMEASSISTANT_CLOSE)
+
+        # Make a copy of running_tasks since a task can finish
+        # while we are awaiting canceled tasks to get their result
+        # which will result in the set size changing during iteration
+        for task in list(running_tasks):
+            if task.done() or cancelling(task):
+                # Since we made a copy we need to check
+                # to see if the task finished while we
+                # were awaiting another task
+                continue
+            _LOGGER.warning(
+                "Task %s was still running after final writes shutdown stage; "
+                "Integrations should cancel non-critical tasks when receiving "
+                "the stop event to prevent delaying shutdown",
+                task,
+            )
+            task.cancel("Home Assistant final writes shutdown stage")
+            try:
+                async with asyncio.timeout(0.1):
+                    await task
+            except asyncio.CancelledError:
+                pass
+            except asyncio.TimeoutError:
+                # Task may be shielded from cancellation.
+                _LOGGER.exception(
+                    "Task %s could not be canceled during final shutdown stage", task
+                )
+            except Exception as exc:  # pylint: disable=broad-except
+                _LOGGER.exception(
+                    "Task %s error during final shutdown stage: %s", task, exc
+                )
+
+        # Prevent run_callback_threadsafe from scheduling any additional
+        # callbacks in the event loop as callbacks created on the futures
+        # it returns will never run after the final `self.async_block_till_done`
+        # which will cause the futures to block forever when waiting for
+        # the `result()` which will cause a deadlock when shutting down the executor.
+        shutdown_run_callback_threadsafe(self.loop)
+
+        try:
+            async with self.timeout.async_timeout(CLOSE_STAGE_SHUTDOWN_TIMEOUT):
+                await self.async_block_till_done()
+        except asyncio.TimeoutError:
+            _LOGGER.warning(
+                "Timed out waiting for close event to be processed, the shutdown will"
+                " continue"
+            )
+            self._async_log_running_tasks("close")
+
+        self.state = CoreState.stopped
+
+        if self._stopped is not None:
+            self._stopped.set()
+
+    def _cancel_cancellable_timers(self) -> None:
+        """Cancel timer handles marked as cancellable."""
+        # pylint: disable-next=protected-access
+        handles: Iterable[asyncio.TimerHandle] = self.loop._scheduled  # type: ignore[attr-defined]
+        for handle in handles:
+            if (
+                not handle.cancelled()
+                and (args := handle._args)  # pylint: disable=protected-access
+                and type(job := args[0]) is HassJob  # noqa: E721
+                and job.cancel_on_shutdown
+            ):
+                handle.cancel()
+
+    def _async_log_running_tasks(self, stage: str) -> None:
+        """Log all running tasks."""
+        for task in self._tasks:
+            _LOGGER.warning("Shutdown stage '%s': still running: %s", stage, task)
+
+
+class Context:
+    """The context that triggered something."""
+
+    __slots__ = ("user_id", "parent_id", "id", "origin_event", "_as_dict")
+
+    def __init__(
+        self,
+        user_id: str | None = None,
+        parent_id: str | None = None,
+        id: str | None = None,  # pylint: disable=redefined-builtin
+    ) -> None:
+        """Init the context."""
+        self.id = id or ulid_now()
+        self.user_id = user_id
+        self.parent_id = parent_id
+        self.origin_event: Event | None = None
+        self._as_dict: ReadOnlyDict[str, str | None] | None = None
+
+    def __eq__(self, other: Any) -> bool:
+        """Compare contexts."""
+        return bool(self.__class__ == other.__class__ and self.id == other.id)
+
+    def as_dict(self) -> ReadOnlyDict[str, str | None]:
+        """Return a dictionary representation of the context."""
+        if not self._as_dict:
+            self._as_dict = ReadOnlyDict(
+                {
+                    "id": self.id,
+                    "parent_id": self.parent_id,
+                    "user_id": self.user_id,
+                }
+            )
+        return self._as_dict
+
+
+class EventOrigin(enum.Enum):
+    """Represent the origin of an event."""
+
+    local = "LOCAL"
+    remote = "REMOTE"
+
+    def __str__(self) -> str:
+        """Return the event."""
+        return self.value
+
+
+class Event:
+    """Representation of an event within the bus."""
+
+    __slots__ = ("event_type", "data", "origin", "time_fired", "context", "_as_dict")
+
+    def __init__(
+        self,
+        event_type: str,
+        data: dict[str, Any] | None = None,
+        origin: EventOrigin = EventOrigin.local,
+        time_fired: datetime.datetime | None = None,
+        context: Context | None = None,
+    ) -> None:
+        """Initialize a new event."""
+        self.event_type = event_type
+        self.data = data or {}
+        self.origin = origin
+        self.time_fired = time_fired or dt_util.utcnow()
+        if not context:
+            context = Context(
+                id=ulid_at_time(dt_util.utc_to_timestamp(self.time_fired))
+            )
+        self.context = context
+        self._as_dict: ReadOnlyDict[str, Any] | None = None
+        if not context.origin_event:
+            context.origin_event = self
+
+    def as_dict(self) -> ReadOnlyDict[str, Any]:
+        """Create a dict representation of this Event.
+
+        Async friendly.
+        """
+        if not self._as_dict:
+            self._as_dict = ReadOnlyDict(
+                {
+                    "event_type": self.event_type,
+                    "data": ReadOnlyDict(self.data),
+                    "origin": self.origin.value,
+                    "time_fired": self.time_fired.isoformat(),
+                    "context": self.context.as_dict(),
+                }
+            )
+        return self._as_dict
+
+    def __repr__(self) -> str:
+        """Return the representation."""
+        if self.data:
+            return (
+                f"<Event {self.event_type}[{str(self.origin)[0]}]:"
+                f" {util.repr_helper(self.data)}>"
+            )
+
+        return f"<Event {self.event_type}[{str(self.origin)[0]}]>"
+
+
+_FilterableJobType = tuple[
+    HassJob[[Event], Coroutine[Any, Any, None] | None],  # job
+    Callable[[Event], bool] | None,  # event_filter
+    bool,  # run_immediately
+]
+
+
+class EventBus:
+    """Allow the firing of and listening for events."""
+
+    __slots__ = ("_listeners", "_match_all_listeners", "_hass")
+
+    def __init__(self, hass: HomeAssistant) -> None:
+        """Initialize a new event bus."""
+        self._listeners: dict[str, list[_FilterableJobType]] = {}
+        self._match_all_listeners: list[_FilterableJobType] = []
+        self._listeners[MATCH_ALL] = self._match_all_listeners
+        self._hass = hass
+
+    @callback
+    def async_listeners(self) -> dict[str, int]:
+        """Return dictionary with events and the number of listeners.
+
+        This method must be run in the event loop.
+        """
+        return {key: len(listeners) for key, listeners in self._listeners.items()}
+
+    @property
+    def listeners(self) -> dict[str, int]:
+        """Return dictionary with events and the number of listeners."""
+        return run_callback_threadsafe(self._hass.loop, self.async_listeners).result()
+
+    def fire(
+        self,
+        event_type: str,
+        event_data: dict[str, Any] | None = None,
+        origin: EventOrigin = EventOrigin.local,
+        context: Context | None = None,
+    ) -> None:
+        """Fire an event."""
+        self._hass.loop.call_soon_threadsafe(
+            self.async_fire, event_type, event_data, origin, context
+        )
+
+    @callback
+    def async_fire(
+        self,
+        event_type: str,
+        event_data: dict[str, Any] | None = None,
+        origin: EventOrigin = EventOrigin.local,
+        context: Context | None = None,
+        time_fired: datetime.datetime | None = None,
+    ) -> None:
+        """Fire an event.
+
+        This method must be run in the event loop.
+        """
+        if len(event_type) > MAX_LENGTH_EVENT_EVENT_TYPE:
+            raise MaxLengthExceeded(
+                event_type, "event_type", MAX_LENGTH_EVENT_EVENT_TYPE
+            )
+
+        listeners = self._listeners.get(event_type, [])
+        match_all_listeners = self._match_all_listeners
+
+        event = Event(event_type, event_data, origin, time_fired, context)
+
+        if _LOGGER.isEnabledFor(logging.DEBUG):
+            _LOGGER.debug("Bus:Handling %s", event)
+
+        if not listeners and not match_all_listeners:
+            return
+
+        # EVENT_HOMEASSISTANT_CLOSE should not be sent to MATCH_ALL listeners
+        if event_type != EVENT_HOMEASSISTANT_CLOSE:
+            listeners = match_all_listeners + listeners
+
+        for job, event_filter, run_immediately in listeners:
+            if event_filter is not None:
+                try:
+                    if not event_filter(event):
+                        continue
+                except Exception:  # pylint: disable=broad-except
+                    _LOGGER.exception("Error in event filter")
+                    continue
+            if run_immediately:
+                try:
+                    job.target(event)
+                except Exception:  # pylint: disable=broad-except
+                    _LOGGER.exception("Error running job: %s", job)
+            else:
+                self._hass.async_add_hass_job(job, event)
+
+    def listen(
+        self,
+        event_type: str,
+        listener: Callable[[Event], Coroutine[Any, Any, None] | None],
+    ) -> CALLBACK_TYPE:
+        """Listen for all events or events of a specific type.
+
+        To listen to all events specify the constant ``MATCH_ALL``
+        as event_type.
+        """
+        async_remove_listener = run_callback_threadsafe(
+            self._hass.loop, self.async_listen, event_type, listener
+        ).result()
+
+        def remove_listener() -> None:
+            """Remove the listener."""
+            run_callback_threadsafe(self._hass.loop, async_remove_listener).result()
+
+        return remove_listener
+
+    @callback
+    def async_listen(
+        self,
+        event_type: str,
+        listener: Callable[[Event], Coroutine[Any, Any, None] | None],
+        event_filter: Callable[[Event], bool] | None = None,
+        run_immediately: bool = False,
+    ) -> CALLBACK_TYPE:
+        """Listen for all events or events of a specific type.
+
+        To listen to all events specify the constant ``MATCH_ALL``
+        as event_type.
+
+        An optional event_filter, which must be a callable decorated with
+        @callback that returns a boolean value, determines if the
+        listener callable should run.
+
+        If run_immediately is passed, the callback will be run
+        right away instead of using call_soon. Only use this if
+        the callback results in scheduling another task.
+
+        This method must be run in the event loop.
+        """
+        job_type: HassJobType | None = None
+        if event_filter is not None and not is_callback_check_partial(event_filter):
+            raise HomeAssistantError(f"Event filter {event_filter} is not a callback")
+        if run_immediately:
+            if not is_callback_check_partial(listener):
+                raise HomeAssistantError(f"Event listener {listener} is not a callback")
+            job_type = HassJobType.Callback
+        return self._async_listen_filterable_job(
+            event_type,
+            (
+                HassJob(listener, f"listen {event_type}", job_type=job_type),
+                event_filter,
+                run_immediately,
+            ),
+        )
+
+    @callback
+    def _async_listen_filterable_job(
+        self, event_type: str, filterable_job: _FilterableJobType
+    ) -> CALLBACK_TYPE:
+        self._listeners.setdefault(event_type, []).append(filterable_job)
+        return functools.partial(
+            self._async_remove_listener, event_type, filterable_job
+        )
+
+    def listen_once(
+        self,
+        event_type: str,
+        listener: Callable[[Event], Coroutine[Any, Any, None] | None],
+    ) -> CALLBACK_TYPE:
+        """Listen once for event of a specific type.
+
+        To listen to all events specify the constant ``MATCH_ALL``
+        as event_type.
+
+        Returns function to unsubscribe the listener.
+        """
+        async_remove_listener = run_callback_threadsafe(
+            self._hass.loop, self.async_listen_once, event_type, listener
+        ).result()
+
+        def remove_listener() -> None:
+            """Remove the listener."""
+            run_callback_threadsafe(self._hass.loop, async_remove_listener).result()
+
+        return remove_listener
+
+    @callback
+    def async_listen_once(
+        self,
+        event_type: str,
+        listener: Callable[[Event], Coroutine[Any, Any, None] | None],
+    ) -> CALLBACK_TYPE:
+        """Listen once for event of a specific type.
+
+        To listen to all events specify the constant ``MATCH_ALL``
+        as event_type.
+
+        Returns registered listener that can be used with remove_listener.
+
+        This method must be run in the event loop.
+        """
+        filterable_job: _FilterableJobType | None = None
+
+        @callback
+        def _onetime_listener(event: Event) -> None:
+            """Remove listener from event bus and then fire listener."""
+            nonlocal filterable_job
+            if hasattr(_onetime_listener, "run"):
+                return
+            # Set variable so that we will never run twice.
+            # Because the event bus loop might have async_fire queued multiple
+            # times, its possible this listener may already be lined up
+            # multiple times as well.
+            # This will make sure the second time it does nothing.
+            setattr(_onetime_listener, "run", True)
+            assert filterable_job is not None
+            self._async_remove_listener(event_type, filterable_job)
+            self._hass.async_run_job(listener, event)
+
+        functools.update_wrapper(
+            _onetime_listener, listener, ("__name__", "__qualname__", "__module__"), []
+        )
+
+        filterable_job = (
+            HassJob(
+                _onetime_listener,
+                f"onetime listen {event_type} {listener}",
+                job_type=HassJobType.Callback,
+            ),
+            None,
+            False,
+        )
+
+        return self._async_listen_filterable_job(event_type, filterable_job)
+
+    @callback
+    def _async_remove_listener(
+        self, event_type: str, filterable_job: _FilterableJobType
+    ) -> None:
+        """Remove a listener of a specific event_type.
+
+        This method must be run in the event loop.
+        """
+        try:
+            self._listeners[event_type].remove(filterable_job)
+
+            # delete event_type list if empty
+            if not self._listeners[event_type] and event_type != MATCH_ALL:
+                self._listeners.pop(event_type)
+        except (KeyError, ValueError):
+            # KeyError is key event_type listener did not exist
+            # ValueError if listener did not exist within event_type
+            _LOGGER.exception(
+                "Unable to remove unknown job listener %s", filterable_job
+            )
+
+
+class State:
+    """Object to represent a state within the state machine.
+
+    entity_id: the entity that is represented.
+    state: the state of the entity
+    attributes: extra information on entity and state
+    last_changed: last time the state was changed, not the attributes.
+    last_updated: last time this object was updated.
+    context: Context in which it was created
+    domain: Domain of this state.
+    object_id: Object id of this state.
+    """
+
+    def __init__(
+        self,
+        entity_id: str,
+        state: str,
+        attributes: Mapping[str, Any] | None = None,
+        last_changed: datetime.datetime | None = None,
+        last_updated: datetime.datetime | None = None,
+        context: Context | None = None,
+        validate_entity_id: bool | None = True,
+        state_info: StateInfo | None = None,
+    ) -> None:
+        """Initialize a new state."""
+        state = str(state)
+
+        if validate_entity_id and not valid_entity_id(entity_id):
+            raise InvalidEntityFormatError(
+                f"Invalid entity id encountered: {entity_id}. "
+                "Format should be <domain>.<object_id>"
+            )
+
+        validate_state(state)
+
+        self.entity_id = entity_id
+        self.state = state
+        self.attributes = ReadOnlyDict(attributes or {})
+        self.last_updated = last_updated or dt_util.utcnow()
+        self.last_changed = last_changed or self.last_updated
+        self.context = context or Context()
+        self.state_info = state_info
+        self.domain, self.object_id = split_entity_id(self.entity_id)
+        self._as_dict: ReadOnlyDict[str, Collection[Any]] | None = None
+
+    @property
+    def name(self) -> str:
+        """Name of this state."""
+        return self.attributes.get(ATTR_FRIENDLY_NAME) or self.object_id.replace(
+            "_", " "
+        )
+
+    def as_dict(self) -> ReadOnlyDict[str, Collection[Any]]:
+        """Return a dict representation of the State.
+
+        Async friendly.
+
+        To be used for JSON serialization.
+        Ensures: state == State.from_dict(state.as_dict())
+        """
+        if not self._as_dict:
+            last_changed_isoformat = self.last_changed.isoformat()
+            if self.last_changed == self.last_updated:
+                last_updated_isoformat = last_changed_isoformat
+            else:
+                last_updated_isoformat = self.last_updated.isoformat()
+            self._as_dict = ReadOnlyDict(
+                {
+                    "entity_id": self.entity_id,
+                    "state": self.state,
+                    "attributes": self.attributes,
+                    "last_changed": last_changed_isoformat,
+                    "last_updated": last_updated_isoformat,
+                    "context": self.context.as_dict(),
+                }
+            )
+        return self._as_dict
+
+    @cached_property
+    def as_dict_json(self) -> str:
+        """Return a JSON string of the State."""
+        return json_dumps(self.as_dict())
+
+    @cached_property
+    def as_compressed_state(self) -> dict[str, Any]:
+        """Build a compressed dict of a state for adds.
+
+        Omits the lu (last_updated) if it matches (lc) last_changed.
+
+        Sends c (context) as a string if it only contains an id.
+        """
+        state_context = self.context
+        if state_context.parent_id is None and state_context.user_id is None:
+            context: dict[str, Any] | str = state_context.id
+        else:
+            context = state_context.as_dict()
+        compressed_state = {
+            COMPRESSED_STATE_STATE: self.state,
+            COMPRESSED_STATE_ATTRIBUTES: self.attributes,
+            COMPRESSED_STATE_CONTEXT: context,
+            COMPRESSED_STATE_LAST_CHANGED: dt_util.utc_to_timestamp(self.last_changed),
+        }
+        if self.last_changed != self.last_updated:
+            compressed_state[COMPRESSED_STATE_LAST_UPDATED] = dt_util.utc_to_timestamp(
+                self.last_updated
+            )
+        return compressed_state
+
+    @cached_property
+    def as_compressed_state_json(self) -> str:
+        """Build a compressed JSON key value pair of a state for adds.
+
+        The JSON string is a key value pair of the entity_id and the compressed state.
+
+        It is used for sending multiple states in a single message.
+        """
+        return json_dumps({self.entity_id: self.as_compressed_state})[1:-1]
+
+    @classmethod
+    def from_dict(cls, json_dict: dict[str, Any]) -> Self | None:
+        """Initialize a state from a dict.
+
+        Async friendly.
+
+        Ensures: state == State.from_json_dict(state.to_json_dict())
+        """
+        if not (json_dict and "entity_id" in json_dict and "state" in json_dict):
+            return None
+
+        last_changed = json_dict.get("last_changed")
+
+        if isinstance(last_changed, str):
+            last_changed = dt_util.parse_datetime(last_changed)
+
+        last_updated = json_dict.get("last_updated")
+
+        if isinstance(last_updated, str):
+            last_updated = dt_util.parse_datetime(last_updated)
+
+        if context := json_dict.get("context"):
+            context = Context(id=context.get("id"), user_id=context.get("user_id"))
+
+        return cls(
+            json_dict["entity_id"],
+            json_dict["state"],
+            json_dict.get("attributes"),
+            last_changed,
+            last_updated,
+            context,
+        )
+
+    def expire(self) -> None:
+        """Mark the state as old.
+
+        We give up the original reference to the context to ensure
+        the context can be garbage collected by replacing it with
+        a new one with the same id to ensure the old state
+        can still be examined for comparison against the new state.
+
+        Since we are always going to fire a EVENT_STATE_CHANGED event
+        after we remove a state from the state machine we need to make
+        sure we don't end up holding a reference to the original context
+        since it can never be garbage collected as each event would
+        reference the previous one.
+        """
+        self.context = Context(
+            self.context.user_id, self.context.parent_id, self.context.id
+        )
+
+    def __repr__(self) -> str:
+        """Return the representation of the states."""
+        attrs = f"; {util.repr_helper(self.attributes)}" if self.attributes else ""
+
+        return (
+            f"<state {self.entity_id}={self.state}{attrs}"
+            f" @ {dt_util.as_local(self.last_changed).isoformat()}>"
+        )
+
+
+class States(UserDict[str, State]):
+    """Container for states, maps entity_id -> State.
+
+    Maintains an additional index:
+    - domain -> dict[str, State]
+    """
+
+    def __init__(self) -> None:
+        """Initialize the container."""
+        super().__init__()
+        self._domain_index: defaultdict[str, dict[str, State]] = defaultdict(dict)
+
+    def values(self) -> ValuesView[State]:
+        """Return the underlying values to avoid __iter__ overhead."""
+        return self.data.values()
+
+    def __setitem__(self, key: str, entry: State) -> None:
+        """Add an item."""
+        self.data[key] = entry
+        self._domain_index[entry.domain][entry.entity_id] = entry
+
+    def __delitem__(self, key: str) -> None:
+        """Remove an item."""
+        entry = self[key]
+        del self._domain_index[entry.domain][entry.entity_id]
+        super().__delitem__(key)
+
+    def domain_entity_ids(self, key: str) -> KeysView[str] | tuple[()]:
+        """Get all entity_ids for a domain."""
+        # Avoid polluting _domain_index with non-existing domains
+        if key not in self._domain_index:
+            return ()
+        return self._domain_index[key].keys()
+
+    def domain_states(self, key: str) -> ValuesView[State] | tuple[()]:
+        """Get all states for a domain."""
+        # Avoid polluting _domain_index with non-existing domains
+        if key not in self._domain_index:
+            return ()
+        return self._domain_index[key].values()
+
+
+class StateMachine:
+    """Helper class that tracks the state of different entities."""
+
+    __slots__ = ("_states", "_states_data", "_reservations", "_bus", "_loop")
+
+    def __init__(self, bus: EventBus, loop: asyncio.events.AbstractEventLoop) -> None:
+        """Initialize state machine."""
+        self._states = States()
+        # _states_data is used to access the States backing dict directly to speed
+        # up read operations
+        self._states_data = self._states.data
+        self._reservations: set[str] = set()
+        self._bus = bus
+        self._loop = loop
+
+    def entity_ids(self, domain_filter: str | None = None) -> list[str]:
+        """List of entity ids that are being tracked."""
+        future = run_callback_threadsafe(
+            self._loop, self.async_entity_ids, domain_filter
+        )
+        return future.result()
+
+    @callback
+    def async_entity_ids(
+        self, domain_filter: str | Iterable[str] | None = None
+    ) -> list[str]:
+        """List of entity ids that are being tracked.
+
+        This method must be run in the event loop.
+        """
+        if domain_filter is None:
+            return list(self._states_data)
+
+        if isinstance(domain_filter, str):
+            return list(self._states.domain_entity_ids(domain_filter.lower()))
+
+        entity_ids: list[str] = []
+        for domain in domain_filter:
+            entity_ids.extend(self._states.domain_entity_ids(domain))
+        return entity_ids
+
+    @callback
+    def async_entity_ids_count(
+        self, domain_filter: str | Iterable[str] | None = None
+    ) -> int:
+        """Count the entity ids that are being tracked.
+
+        This method must be run in the event loop.
+        """
+        if domain_filter is None:
+            return len(self._states_data)
+
+        if isinstance(domain_filter, str):
+            return len(self._states.domain_entity_ids(domain_filter.lower()))
+
+        return sum(
+            len(self._states.domain_entity_ids(domain)) for domain in domain_filter
+        )
+
+    def all(self, domain_filter: str | Iterable[str] | None = None) -> list[State]:
+        """Create a list of all states."""
+        return run_callback_threadsafe(
+            self._loop, self.async_all, domain_filter
+        ).result()
+
+    @callback
+    def async_all(
+        self, domain_filter: str | Iterable[str] | None = None
+    ) -> list[State]:
+        """Create a list of all states matching the filter.
+
+        This method must be run in the event loop.
+        """
+        if domain_filter is None:
+            return list(self._states_data.values())
+
+        if isinstance(domain_filter, str):
+            return list(self._states.domain_states(domain_filter.lower()))
+
+        states: list[State] = []
+        for domain in domain_filter:
+            states.extend(self._states.domain_states(domain))
+        return states
+
+    def get(self, entity_id: str) -> State | None:
+        """Retrieve state of entity_id or None if not found.
+
+        Async friendly.
+        """
+        return self._states_data.get(entity_id.lower())
+
+    def is_state(self, entity_id: str, state: str) -> bool:
+        """Test if entity exists and is in specified state.
+
+        Async friendly.
+        """
+        state_obj = self.get(entity_id)
+        return state_obj is not None and state_obj.state == state
+
+    def remove(self, entity_id: str) -> bool:
+        """Remove the state of an entity.
+
+        Returns boolean to indicate if an entity was removed.
+        """
+        return run_callback_threadsafe(
+            self._loop, self.async_remove, entity_id
+        ).result()
+
+    @callback
+    def async_remove(self, entity_id: str, context: Context | None = None) -> bool:
+        """Remove the state of an entity.
+
+        Returns boolean to indicate if an entity was removed.
+
+        This method must be run in the event loop.
+        """
+        entity_id = entity_id.lower()
+        old_state = self._states.pop(entity_id, None)
+        self._reservations.discard(entity_id)
+
+        if old_state is None:
+            return False
+
+        old_state.expire()
+        self._bus.async_fire(
+            EVENT_STATE_CHANGED,
+            {"entity_id": entity_id, "old_state": old_state, "new_state": None},
+            EventOrigin.local,
+            context=context,
+        )
+        return True
+
+    def set(
+        self,
+        entity_id: str,
+        new_state: str,
+        attributes: Mapping[str, Any] | None = None,
+        force_update: bool = False,
+        context: Context | None = None,
+    ) -> None:
+        """Set the state of an entity, add entity if it does not exist.
+
+        Attributes is an optional dict to specify attributes of this state.
+
+        If you just update the attributes and not the state, last changed will
+        not be affected.
+        """
+        run_callback_threadsafe(
+            self._loop,
+            self.async_set,
+            entity_id,
+            new_state,
+            attributes,
+            force_update,
+            context,
+        ).result()
+
+    @callback
+    def async_reserve(self, entity_id: str) -> None:
+        """Reserve a state in the state machine for an entity being added.
+
+        This must not fire an event when the state is reserved.
+
+        This avoids a race condition where multiple entities with the same
+        entity_id are added.
+        """
+        entity_id = entity_id.lower()
+        if entity_id in self._states_data or entity_id in self._reservations:
+            raise HomeAssistantError(
+                "async_reserve must not be called once the state is in the state"
+                " machine."
+            )
+
+        self._reservations.add(entity_id)
+
+    @callback
+    def async_available(self, entity_id: str) -> bool:
+        """Check to see if an entity_id is available to be used."""
+        entity_id = entity_id.lower()
+        return (
+            entity_id not in self._states_data and entity_id not in self._reservations
+        )
+
+    @callback
+    def async_set(
+        self,
+        entity_id: str,
+        new_state: str,
+        attributes: Mapping[str, Any] | None = None,
+        force_update: bool = False,
+        context: Context | None = None,
+        state_info: StateInfo | None = None,
+    ) -> None:
+        """Set the state of an entity, add entity if it does not exist.
+
+        Attributes is an optional dict to specify attributes of this state.
+
+        If you just update the attributes and not the state, last changed will
+        not be affected.
+
+        This method must be run in the event loop.
+        """
+        entity_id = entity_id.lower()
+        new_state = str(new_state)
+        attributes = attributes or {}
+        if (old_state := self._states_data.get(entity_id)) is None:
+            same_state = False
+            same_attr = False
+            last_changed = None
+        else:
+            same_state = old_state.state == new_state and not force_update
+            same_attr = old_state.attributes == attributes
+            last_changed = old_state.last_changed if same_state else None
+
+        if same_state and same_attr:
+            return
+
+        if context is None:
+            # It is much faster to convert a timestamp to a utc datetime object
+            # than converting a utc datetime object to a timestamp since cpython
+            # does not have a fast path for handling the UTC timezone and has to do
+            # multiple local timezone conversions.
+            #
+            # from_timestamp implementation:
+            # https://github.com/python/cpython/blob/c90a862cdcf55dc1753c6466e5fa4a467a13ae24/Modules/_datetimemodule.c#L2936
+            #
+            # timestamp implementation:
+            # https://github.com/python/cpython/blob/c90a862cdcf55dc1753c6466e5fa4a467a13ae24/Modules/_datetimemodule.c#L6387
+            # https://github.com/python/cpython/blob/c90a862cdcf55dc1753c6466e5fa4a467a13ae24/Modules/_datetimemodule.c#L6323
+            timestamp = time.time()
+            now = dt_util.utc_from_timestamp(timestamp)
+            context = Context(id=ulid_at_time(timestamp))
+        else:
+            now = dt_util.utcnow()
+
+        state = State(
+            entity_id,
+            new_state,
+            attributes,
+            last_changed,
+            now,
+            context,
+            old_state is None,
+            state_info,
+        )
+        if old_state is not None:
+            old_state.expire()
+
+        
+        #lqg lalala
+        # 正确比较状态值（处理old_state为None的情况）
+        old_state_val = old_state.state if old_state else None
+        if old_state_val != new_state:
+        #if old_state != new_state:
+            is_automation_triggered = (context.parent_id is not None and context.parent_id.startswith("automation_"))
+            if not is_automation_triggered:  # 仅记录非自动化触发的状态变化
+                log_state_change(
+                    entity_id=entity_id,
+                    new_state=new_state,
+                    old_state=old_state.state if old_state else "None",
+                    context=context
+                )
+
+        self._states[entity_id] = state
+        self._bus.async_fire(
+            EVENT_STATE_CHANGED,
+            {"entity_id": entity_id, "old_state": old_state, "new_state": state},
+            EventOrigin.local,
+            context,
+            time_fired=now,
+        )
+
+
+class SupportsResponse(enum.StrEnum):
+    """Service call response configuration."""
+
+    NONE = "none"
+    """The service does not support responses (the default)."""
+
+    OPTIONAL = "optional"
+    """The service optionally returns response data when asked by the caller."""
+
+    ONLY = "only"
+    """The service is read-only and the caller must always ask for response data."""
+
+
+class Service:
+    """Representation of a callable service."""
+
+    __slots__ = ["job", "schema", "domain", "service", "supports_response"]
+
+    def __init__(
+        self,
+        func: Callable[
+            [ServiceCall],
+            Coroutine[Any, Any, ServiceResponse | EntityServiceResponse]
+            | ServiceResponse
+            | EntityServiceResponse
+            | None,
+        ],
+        schema: vol.Schema | None,
+        domain: str,
+        service: str,
+        context: Context | None = None,
+        supports_response: SupportsResponse = SupportsResponse.NONE,
+    ) -> None:
+        """Initialize a service."""
+        self.job = HassJob(func, f"service {domain}.{service}")
+        self.schema = schema
+        self.supports_response = supports_response
+
+
+class ServiceCall:
+    """Representation of a call to a service."""
+
+    __slots__ = ("domain", "service", "data", "context", "return_response")
+
+    def __init__(
+        self,
+        domain: str,
+        service: str,
+        data: dict[str, Any] | None = None,
+        context: Context | None = None,
+        return_response: bool = False,
+    ) -> None:
+        """Initialize a service call."""
+        self.domain = domain
+        self.service = service
+        self.data = ReadOnlyDict(data or {})
+        self.context = context or Context()
+        self.return_response = return_response
+
+    def __repr__(self) -> str:
+        """Return the representation of the service."""
+        if self.data:
+            return (
+                f"<ServiceCall {self.domain}.{self.service} "
+                f"(c:{self.context.id}): {util.repr_helper(self.data)}>"
+            )
+
+        return f"<ServiceCall {self.domain}.{self.service} (c:{self.context.id})>"
+
+
+class ServiceRegistry:
+    """Offer the services over the eventbus."""
+
+    __slots__ = ("_services", "_hass")
+
+    def __init__(self, hass: HomeAssistant) -> None:
+        """Initialize a service registry."""
+        self._services: dict[str, dict[str, Service]] = {}
+        self._hass = hass
+
+    @property
+    def services(self) -> dict[str, dict[str, Service]]:
+        """Return dictionary with per domain a list of available services."""
+        return run_callback_threadsafe(self._hass.loop, self.async_services).result()
+
+    @callback
+    def async_services(self) -> dict[str, dict[str, Service]]:
+        """Return dictionary with per domain a list of available services.
+
+        This method must be run in the event loop.
+        """
+        return {domain: service.copy() for domain, service in self._services.items()}
+
+    def has_service(self, domain: str, service: str) -> bool:
+        """Test if specified service exists.
+
+        Async friendly.
+        """
+        return service.lower() in self._services.get(domain.lower(), [])
+
+    def supports_response(self, domain: str, service: str) -> SupportsResponse:
+        """Return whether or not the service supports response data.
+
+        This exists so that callers can return more helpful error messages given
+        the context. Will return NONE if the service does not exist as there is
+        other error handling when calling the service if it does not exist.
+        """
+        if not (handler := self._services[domain.lower()][service.lower()]):
+            return SupportsResponse.NONE
+        return handler.supports_response
+
+    def register(
+        self,
+        domain: str,
+        service: str,
+        service_func: Callable[
+            [ServiceCall],
+            Coroutine[Any, Any, ServiceResponse] | ServiceResponse | None,
+        ],
+        schema: vol.Schema | None = None,
+        supports_response: SupportsResponse = SupportsResponse.NONE,
+    ) -> None:
+        """Register a service.
+
+        Schema is called to coerce and validate the service data.
+        """
+        run_callback_threadsafe(
+            self._hass.loop,
+            self.async_register,
+            domain,
+            service,
+            service_func,
+            schema,
+            supports_response,
+        ).result()
+
+    @callback
+    def async_register(
+        self,
+        domain: str,
+        service: str,
+        service_func: Callable[
+            [ServiceCall],
+            Coroutine[Any, Any, ServiceResponse | EntityServiceResponse]
+            | ServiceResponse
+            | EntityServiceResponse
+            | None,
+        ],
+        schema: vol.Schema | None = None,
+        supports_response: SupportsResponse = SupportsResponse.NONE,
+    ) -> None:
+        """Register a service.
+
+        Schema is called to coerce and validate the service data.
+
+        This method must be run in the event loop.
+        """
+        domain = domain.lower()
+        service = service.lower()
+        service_obj = Service(
+            service_func, schema, domain, service, supports_response=supports_response
+        )
+
+        if domain in self._services:
+            self._services[domain][service] = service_obj
+        else:
+            self._services[domain] = {service: service_obj}
+
+        self._hass.bus.async_fire(
+            EVENT_SERVICE_REGISTERED, {ATTR_DOMAIN: domain, ATTR_SERVICE: service}
+        )
+
+    def remove(self, domain: str, service: str) -> None:
+        """Remove a registered service from service handler."""
+        run_callback_threadsafe(
+            self._hass.loop, self.async_remove, domain, service
+        ).result()
+
+    @callback
+    def async_remove(self, domain: str, service: str) -> None:
+        """Remove a registered service from service handler.
+
+        This method must be run in the event loop.
+        """
+        domain = domain.lower()
+        service = service.lower()
+
+        if service not in self._services.get(domain, {}):
+            _LOGGER.warning("Unable to remove unknown service %s/%s", domain, service)
+            return
+
+        self._services[domain].pop(service)
+
+        if not self._services[domain]:
+            self._services.pop(domain)
+
+        self._hass.bus.async_fire(
+            EVENT_SERVICE_REMOVED, {ATTR_DOMAIN: domain, ATTR_SERVICE: service}
+        )
+
+    def call(
+        self,
+        domain: str,
+        service: str,
+        service_data: dict[str, Any] | None = None,
+        blocking: bool = False,
+        context: Context | None = None,
+        target: dict[str, Any] | None = None,
+        return_response: bool = False,
+    ) -> ServiceResponse:
+        """Call a service.
+
+        See description of async_call for details.
+        """
+        return asyncio.run_coroutine_threadsafe(
+            self.async_call(
+                domain,
+                service,
+                service_data,
+                blocking,
+                context,
+                target,
+                return_response,
+            ),
+            self._hass.loop,
+        ).result()
+
+    async def async_call(
+        self,
+        domain: str,
+        service: str,
+        service_data: dict[str, Any] | None = None,
+        blocking: bool = False,
+        context: Context | None = None,
+        target: dict[str, Any] | None = None,
+        return_response: bool = False,
+    ) -> ServiceResponse:
+        """Call a service.
+
+        Specify blocking=True to wait until service is executed.
+
+        If return_response=True, indicates that the caller can consume return values
+        from the service, if any. Return values are a dict that can be returned by the
+        standard JSON serialization process. Return values can only be used with blocking=True.
+
+        This method will fire an event to indicate the service has been called.
+
+        Because the service is sent as an event you are not allowed to use
+        the keys ATTR_DOMAIN and ATTR_SERVICE in your service_data.
+
+        This method is a coroutine.
+        """
+        context = context or Context()
+        service_data = service_data or {}
+
+        try:
+            handler = self._services[domain][service]
+        except KeyError:
+            # Almost all calls are already lower case, so we avoid
+            # calling lower() on the arguments in the common case.
+            domain = domain.lower()
+            service = service.lower()
+            try:
+                handler = self._services[domain][service]
+            except KeyError:
+                raise ServiceNotFound(domain, service) from None
+
+        if return_response:
+            if not blocking:
+                raise ValueError(
+                    "Invalid argument return_response=True when blocking=False"
+                )
+            if handler.supports_response == SupportsResponse.NONE:
+                raise ValueError(
+                    "Invalid argument return_response=True when handler does not support responses"
+                )
+        elif handler.supports_response == SupportsResponse.ONLY:
+            raise ValueError(
+                "Service call requires responses but caller did not ask for responses"
+            )
+
+        if target:
+            service_data.update(target)
+
+        if handler.schema:
+            try:
+                processed_data: dict[str, Any] = handler.schema(service_data)
+            except vol.Invalid:
+                _LOGGER.debug(
+                    "Invalid data for service call %s.%s: %s",
+                    domain,
+                    service,
+                    service_data,
+                )
+                raise
+        else:
+            processed_data = service_data
+
+        service_call = ServiceCall(
+            domain, service, processed_data, context, return_response
+        )
+
+        #lqg tag
+        # 关键：获取服务调用的上下文和来源信息
+        target = target or {}
+        _LOGGER.warning("Logging Service Calling...")
+        # 核心逻辑：
+        # 1. 面板操作通常有user_id（用户触发）
+        # 2. 排除自动化相关的服务调用（如automation.*）
+        has_user = context.user_id is not None
+        is_automation_service = domain == "automation"  # 自动化服务直接排除
+        is_panel_source = has_user and not is_automation_service
+        #is_panel_source = not getattr(context, 'origin', None)
+        _LOGGER.warning("is panel source?")
+        _LOGGER.warning(is_panel_source)
+
+        if is_panel_source:
+            # 解析目标设备的 entity_id（从 target 或 service_data 中提取）
+            target_entities = target.get("entity_id") or service_data.get("entity_id")
+            # 处理单个设备或多个设备的情况
+            if isinstance(target_entities, list):
+                entity_ids = target_entities
+            else:
+                entity_ids = [target_entities] if target_entities else []
+
+            # 遍历所有目标设备，记录面板命令
+            for entity_id in entity_ids:
+                if not entity_id:
+                    continue  # 跳过无实体 ID 的情况（极少数）
+
+                device_name = get_friendly_name(entity_id)
+                command = f"{domain}.{service}"
+                description = f"{command.replace('_', ' ').title()}"
+
+                record_event(
+                    event_type="Command",
+                    device=device_name,
+                    description=description,
+                    context=context,
+                    extra_attributes={
+                        "command": command,
+                        "target_device": entity_id,
+                        "source": "panel",
+                        "user_id": context.user_id  #
+                    }
+                )
+
+        self._hass.bus.async_fire(
+            EVENT_CALL_SERVICE,
+            {
+                ATTR_DOMAIN: domain,
+                ATTR_SERVICE: service,
+                ATTR_SERVICE_DATA: service_data,
+            },
+            context=context,
+        )
+
+        coro = self._execute_service(handler, service_call)
+        if not blocking:
+            self._hass.async_create_task(
+                self._run_service_call_catch_exceptions(coro, service_call),
+                f"service call background {service_call.domain}.{service_call.service}",
+            )
+            return None
+
+        response_data = await coro
+        if not return_response:
+            return None
+        if not isinstance(response_data, dict):
+            raise HomeAssistantError(
+                f"Service response data expected a dictionary, was {type(response_data)}"
+            )
+        return response_data
+
+    async def _run_service_call_catch_exceptions(
+        self,
+        coro_or_task: Coroutine[Any, Any, Any] | asyncio.Task[Any],
+        service_call: ServiceCall,
+    ) -> None:
+        """Run service call in background, catching and logging any exceptions."""
+        try:
+            await coro_or_task
+        except Unauthorized:
+            _LOGGER.warning(
+                "Unauthorized service called %s/%s",
+                service_call.domain,
+                service_call.service,
+            )
+        except asyncio.CancelledError:
+            _LOGGER.debug("Service was cancelled: %s", service_call)
+        except Exception:  # pylint: disable=broad-except
+            _LOGGER.exception("Error executing service: %s", service_call)
+
+    async def _execute_service(
+        self, handler: Service, service_call: ServiceCall
+    ) -> ServiceResponse:
+        """Execute a service."""
+        job = handler.job
+        target = job.target
+        if job.job_type == HassJobType.Coroutinefunction:
+            if TYPE_CHECKING:
+                target = cast(Callable[..., Coroutine[Any, Any, _R]], target)
+            return await target(service_call)
+        if job.job_type == HassJobType.Callback:
+            if TYPE_CHECKING:
+                target = cast(Callable[..., _R], target)
+            return target(service_call)
+        if TYPE_CHECKING:
+            target = cast(Callable[..., _R], target)
+        return await self._hass.async_add_executor_job(target, service_call)
+
+
+class Config:
+    """Configuration settings for Home Assistant."""
+
+    def __init__(self, hass: HomeAssistant, config_dir: str) -> None:
+        """Initialize a new config object."""
+        self.hass = hass
+
+        self._store = self._ConfigStore(self.hass)
+
+        self.latitude: float = 0
+        self.longitude: float = 0
+
+        self.elevation: int = 0
+        """Elevation (always in meters regardless of the unit system)."""
+
+        self.location_name: str = "Home"
+        self.time_zone: str = "UTC"
+        self.units: UnitSystem = METRIC_SYSTEM
+        self.internal_url: str | None = None
+        self.external_url: str | None = None
+        self.currency: str = "EUR"
+        self.country: str | None = None
+        self.language: str = "en"
+
+        self.config_source: ConfigSource = ConfigSource.DEFAULT
+
+        # If True, pip install is skipped for requirements on startup
+        self.skip_pip: bool = False
+
+        # List of packages to skip when installing requirements on startup
+        self.skip_pip_packages: list[str] = []
+
+        # List of loaded components
+        self.components: set[str] = set()
+
+        # API (HTTP) server configuration
+        self.api: ApiConfig | None = None
+
+        # Directory that holds the configuration
+        self.config_dir: str = config_dir
+
+        # List of allowed external dirs to access
+        self.allowlist_external_dirs: set[str] = set()
+
+        # List of allowed external URLs that integrations may use
+        self.allowlist_external_urls: set[str] = set()
+
+        # Dictionary of Media folders that integrations may use
+        self.media_dirs: dict[str, str] = {}
+
+        # If Home Assistant is running in recovery mode
+        self.recovery_mode: bool = False
+
+        # Use legacy template behavior
+        self.legacy_templates: bool = False
+
+        # If Home Assistant is running in safe mode
+        self.safe_mode: bool = False
+
+    def distance(self, lat: float, lon: float) -> float | None:
+        """Calculate distance from Home Assistant.
+
+        Async friendly.
+        """
+        return self.units.length(
+            location.distance(self.latitude, self.longitude, lat, lon),
+            UnitOfLength.METERS,
+        )
+
+    def path(self, *path: str) -> str:
+        """Generate path to the file within the configuration directory.
+
+        Async friendly.
+        """
+        return os.path.join(self.config_dir, *path)
+
+    def is_allowed_external_url(self, url: str) -> bool:
+        """Check if an external URL is allowed."""
+        parsed_url = f"{str(yarl.URL(url))}/"
+
+        return any(
+            allowed
+            for allowed in self.allowlist_external_urls
+            if parsed_url.startswith(allowed)
+        )
+
+    def is_allowed_path(self, path: str) -> bool:
+        """Check if the path is valid for access from outside.
+
+        This function does blocking I/O and should not be called from the event loop.
+        Use hass.async_add_executor_job to schedule it on the executor.
+        """
+        assert path is not None
+
+        thepath = pathlib.Path(path)
+        try:
+            # The file path does not have to exist (it's parent should)
+            if thepath.exists():
+                thepath = thepath.resolve()
+            else:
+                thepath = thepath.parent.resolve()
+        except (FileNotFoundError, RuntimeError, PermissionError):
+            return False
+
+        for allowed_path in self.allowlist_external_dirs:
+            try:
+                thepath.relative_to(allowed_path)
+                return True
+            except ValueError:
+                pass
+
+        return False
+
+    def as_dict(self) -> dict[str, Any]:
+        """Create a dictionary representation of the configuration.
+
+        Async friendly.
+        """
+        return {
+            "latitude": self.latitude,
+            "longitude": self.longitude,
+            "elevation": self.elevation,
+            "unit_system": self.units.as_dict(),
+            "location_name": self.location_name,
+            "time_zone": self.time_zone,
+            "components": self.components,
+            "config_dir": self.config_dir,
+            # legacy, backwards compat
+            "whitelist_external_dirs": self.allowlist_external_dirs,
+            "allowlist_external_dirs": self.allowlist_external_dirs,
+            "allowlist_external_urls": self.allowlist_external_urls,
+            "version": __version__,
+            "config_source": self.config_source,
+            "recovery_mode": self.recovery_mode,
+            "state": self.hass.state.value,
+            "external_url": self.external_url,
+            "internal_url": self.internal_url,
+            "currency": self.currency,
+            "country": self.country,
+            "language": self.language,
+            "safe_mode": self.safe_mode,
+        }
+
+    def set_time_zone(self, time_zone_str: str) -> None:
+        """Help to set the time zone."""
+        if time_zone := dt_util.get_time_zone(time_zone_str):
+            self.time_zone = time_zone_str
+            dt_util.set_default_time_zone(time_zone)
+        else:
+            raise ValueError(f"Received invalid time zone {time_zone_str}")
+
+    @callback
+    def _update(
+        self,
+        *,
+        source: ConfigSource,
+        latitude: float | None = None,
+        longitude: float | None = None,
+        elevation: int | None = None,
+        unit_system: str | None = None,
+        location_name: str | None = None,
+        time_zone: str | None = None,
+        # pylint: disable=dangerous-default-value # _UNDEFs not modified
+        external_url: str | dict[Any, Any] | None = _UNDEF,
+        internal_url: str | dict[Any, Any] | None = _UNDEF,
+        currency: str | None = None,
+        country: str | dict[Any, Any] | None = _UNDEF,
+        language: str | None = None,
+    ) -> None:
+        """Update the configuration from a dictionary."""
+        self.config_source = source
+        if latitude is not None:
+            self.latitude = latitude
+        if longitude is not None:
+            self.longitude = longitude
+        if elevation is not None:
+            self.elevation = elevation
+        if unit_system is not None:
+            try:
+                self.units = get_unit_system(unit_system)
+            except ValueError:
+                self.units = METRIC_SYSTEM
+        if location_name is not None:
+            self.location_name = location_name
+        if time_zone is not None:
+            self.set_time_zone(time_zone)
+        if external_url is not _UNDEF:
+            self.external_url = cast(str | None, external_url)
+        if internal_url is not _UNDEF:
+            self.internal_url = cast(str | None, internal_url)
+        if currency is not None:
+            self.currency = currency
+        if country is not _UNDEF:
+            self.country = cast(str | None, country)
+        if language is not None:
+            self.language = language
+
+    async def async_update(self, **kwargs: Any) -> None:
+        """Update the configuration from a dictionary."""
+        # pylint: disable-next=import-outside-toplevel
+        from .config import (
+            _raise_issue_if_historic_currency,
+            _raise_issue_if_no_country,
+        )
+
+        self._update(source=ConfigSource.STORAGE, **kwargs)
+        await self._async_store()
+        self.hass.bus.async_fire(EVENT_CORE_CONFIG_UPDATE, kwargs)
+
+        _raise_issue_if_historic_currency(self.hass, self.currency)
+        _raise_issue_if_no_country(self.hass, self.country)
+
+    async def async_load(self) -> None:
+        """Load [homeassistant] core config."""
+        if not (data := await self._store.async_load()):
+            return
+
+        # In 2021.9 we fixed validation to disallow a path (because that's never
+        # correct) but this data still lives in storage, so we print a warning.
+        if data.get("external_url") and urlparse(data["external_url"]).path not in (
+            "",
+            "/",
+        ):
+            _LOGGER.warning("Invalid external_url set. It's not allowed to have a path")
+
+        if data.get("internal_url") and urlparse(data["internal_url"]).path not in (
+            "",
+            "/",
+        ):
+            _LOGGER.warning("Invalid internal_url set. It's not allowed to have a path")
+
+        self._update(
+            source=ConfigSource.STORAGE,
+            latitude=data.get("latitude"),
+            longitude=data.get("longitude"),
+            elevation=data.get("elevation"),
+            unit_system=data.get("unit_system_v2"),
+            location_name=data.get("location_name"),
+            time_zone=data.get("time_zone"),
+            external_url=data.get("external_url", _UNDEF),
+            internal_url=data.get("internal_url", _UNDEF),
+            currency=data.get("currency"),
+            country=data.get("country"),
+            language=data.get("language"),
+        )
+
+    async def _async_store(self) -> None:
+        """Store [homeassistant] core config."""
+        data = {
+            "latitude": self.latitude,
+            "longitude": self.longitude,
+            "elevation": self.elevation,
+            # We don't want any integrations to use the name of the unit system
+            # so we are using the private attribute here
+            "unit_system_v2": self.units._name,  # pylint: disable=protected-access
+            "location_name": self.location_name,
+            "time_zone": self.time_zone,
+            "external_url": self.external_url,
+            "internal_url": self.internal_url,
+            "currency": self.currency,
+            "country": self.country,
+            "language": self.language,
+        }
+
+        await self._store.async_save(data)
+
+    # Circular dependency prevents us from generating the class at top level
+    # pylint: disable-next=import-outside-toplevel
+    from .helpers.storage import Store
+
+    class _ConfigStore(Store[dict[str, Any]]):
+        """Class to help storing Config data."""
+
+        def __init__(self, hass: HomeAssistant) -> None:
+            """Initialize storage class."""
+            super().__init__(
+                hass,
+                CORE_STORAGE_VERSION,
+                CORE_STORAGE_KEY,
+                private=True,
+                atomic_writes=True,
+                minor_version=CORE_STORAGE_MINOR_VERSION,
+            )
+            self._original_unit_system: str | None = None  # from old store 1.1
+
+        async def _async_migrate_func(
+            self,
+            old_major_version: int,
+            old_minor_version: int,
+            old_data: dict[str, Any],
+        ) -> dict[str, Any]:
+            """Migrate to the new version."""
+            data = old_data
+            if old_major_version == 1 and old_minor_version < 2:
+                # In 1.2, we remove support for "imperial", replaced by "us_customary"
+                # Using a new key to allow rollback
+                self._original_unit_system = data.get("unit_system")
+                data["unit_system_v2"] = self._original_unit_system
+                if data["unit_system_v2"] == _CONF_UNIT_SYSTEM_IMPERIAL:
+                    data["unit_system_v2"] = _CONF_UNIT_SYSTEM_US_CUSTOMARY
+            if old_major_version == 1 and old_minor_version < 3:
+                # In 1.3, we add the key "language", initialize it from the
+                # owner account.
+                data["language"] = "en"
+                try:
+                    owner = await self.hass.auth.async_get_owner()
+                    if owner is not None:
+                        # pylint: disable-next=import-outside-toplevel
+                        from .components.frontend import storage as frontend_store
+
+                        # pylint: disable-next=import-outside-toplevel
+                        from .helpers import config_validation as cv
+
+                        _, owner_data = await frontend_store.async_user_store(
+                            self.hass, owner.id
+                        )
+
+                        if (
+                            "language" in owner_data
+                            and "language" in owner_data["language"]
+                        ):
+                            with suppress(vol.InInvalid):
+                                data["language"] = cv.language(
+                                    owner_data["language"]["language"]
+                                )
+                # pylint: disable-next=broad-except
+                except Exception:
+                    _LOGGER.exception("Unexpected error during core config migration")
+
+            if old_major_version > 1:
+                raise NotImplementedError
+            return data
+
+        async def async_save(self, data: dict[str, Any]) -> None:
+            if self._original_unit_system:
+                data["unit_system"] = self._original_unit_system
+            return await super().async_save(data)
+
+
+# These can be removed if no deprecated constant are in this module anymore
+__getattr__ = functools.partial(check_if_deprecated_constant, module_globals=globals())
+__dir__ = functools.partial(
+    dir_with_deprecated_constants, module_globals_keys=[*globals().keys()]
+)
+__all__ = all_with_deprecated_constants(globals())
diff -urN -x __pycache__ -x '*.pyc' /tmp/homeassistant-2024.1.5/homeassistant/core.py /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/core.py
--- /tmp/homeassistant-2024.1.5/homeassistant/core.py	2024-01-21 04:41:26.000000000 +0800
+++ /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/core.py	2026-02-12 19:36:01.639959022 +0800
@@ -5,6 +5,21 @@
 """
 from __future__ import annotations
 
+
+"""
+from homeassistant.helpers.provenance import(
+    actionFilterModule,
+    #createTemporalRelation
+)"""
+from homeassistant.helpers.provenance import(
+    log_state_change, 
+    save_log,
+    record_event,
+    get_friendly_name,
+    init_startup_log
+)
+
+
 import asyncio
 from collections import UserDict, defaultdict
 from collections.abc import (
@@ -446,6 +461,8 @@
 
         This method is a coroutine.
         """
+        _LOGGER.warning("===== Initializing New Provenance Session =====")
+        init_startup_log()
         _LOGGER.info("Starting Home Assistant")
         setattr(self.loop, "_thread_ident", threading.get_ident())
 
@@ -841,6 +858,10 @@
 
         This method is a coroutine.
         """
+        #lqg : save log
+        _LOGGER.warning("====== Saving Provenance Log on Shutdown ======")
+        # 建议创建一个专用的 logs 文件夹，避免根目录太乱
+        save_log('/home/homeassistant/.homeassistant/provenance_logs/')
         if not force:
             # Some tests require async_stop to run,
             # regardless of the state of the loop.
@@ -1816,6 +1837,22 @@
         )
         if old_state is not None:
             old_state.expire()
+
+        
+        #lqg lalala
+        # 正确比较状态值（处理old_state为None的情况）
+        old_state_val = old_state.state if old_state else None
+        if old_state_val != new_state:
+        #if old_state != new_state:
+            is_automation_triggered = (context.parent_id is not None and context.parent_id.startswith("automation_"))
+            if not is_automation_triggered:  # 仅记录非自动化触发的状态变化
+                log_state_change(
+                    entity_id=entity_id,
+                    new_state=new_state,
+                    old_state=old_state.state if old_state else "None",
+                    context=context
+                )
+
         self._states[entity_id] = state
         self._bus.async_fire(
             EVENT_STATE_CHANGED,
@@ -2128,6 +2165,51 @@
             domain, service, processed_data, context, return_response
         )
 
+        #lqg tag
+        # 关键：获取服务调用的上下文和来源信息
+        target = target or {}
+        _LOGGER.warning("Logging Service Calling...")
+        # 核心逻辑：
+        # 1. 面板操作通常有user_id（用户触发）
+        # 2. 排除自动化相关的服务调用（如automation.*）
+        has_user = context.user_id is not None
+        is_automation_service = domain == "automation"  # 自动化服务直接排除
+        is_panel_source = has_user and not is_automation_service
+        #is_panel_source = not getattr(context, 'origin', None)
+        _LOGGER.warning("is panel source?")
+        _LOGGER.warning(is_panel_source)
+
+        if is_panel_source:
+            # 解析目标设备的 entity_id（从 target 或 service_data 中提取）
+            target_entities = target.get("entity_id") or service_data.get("entity_id")
+            # 处理单个设备或多个设备的情况
+            if isinstance(target_entities, list):
+                entity_ids = target_entities
+            else:
+                entity_ids = [target_entities] if target_entities else []
+
+            # 遍历所有目标设备，记录面板命令
+            for entity_id in entity_ids:
+                if not entity_id:
+                    continue  # 跳过无实体 ID 的情况（极少数）
+
+                device_name = get_friendly_name(entity_id)
+                command = f"{domain}.{service}"
+                description = f"{command.replace('_', ' ').title()}"
+
+                record_event(
+                    event_type="Command",
+                    device=device_name,
+                    description=description,
+                    context=context,
+                    extra_attributes={
+                        "command": command,
+                        "target_device": entity_id,
+                        "source": "panel",
+                        "user_id": context.user_id  #
+                    }
+                )
+
         self._hass.bus.async_fire(
             EVENT_CALL_SERVICE,
             {
diff -urN -x __pycache__ -x '*.pyc' /tmp/homeassistant-2024.1.5/homeassistant/core-zyd.py /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/core-zyd.py
--- /tmp/homeassistant-2024.1.5/homeassistant/core-zyd.py	1970-01-01 08:00:00.000000000 +0800
+++ /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/core-zyd.py	2026-01-10 21:55:45.903757484 +0800
@@ -0,0 +1,2618 @@
+"""Core components of Home Assistant.
+
+Home Assistant is a Home Automation framework for observing the state
+of entities and react to changes.
+"""
+from __future__ import annotations
+
+
+# """
+# from homeassistant.helpers.provenance import(
+#     actionFilterModule,
+#     #createTemporalRelation
+# )"""
+# from homeassistant.helpers.provenance import(
+#     log_state_change, 
+#     save_log,
+#     record_event,
+#     get_friendly_name
+# )
+
+
+import asyncio
+from collections import UserDict, defaultdict
+from collections.abc import (
+    Callable,
+    Collection,
+    Coroutine,
+    Iterable,
+    KeysView,
+    Mapping,
+    ValuesView,
+)
+import concurrent.futures
+from contextlib import suppress
+from dataclasses import dataclass
+import datetime
+import enum
+import functools
+import logging
+import os
+import pathlib
+import re
+import threading
+import time
+from time import monotonic
+from typing import (
+    TYPE_CHECKING,
+    Any,
+    Generic,
+    Literal,
+    ParamSpec,
+    Self,
+    TypeVar,
+    cast,
+    overload,
+)
+from urllib.parse import urlparse
+
+import voluptuous as vol
+import yarl
+
+from . import block_async_io, util
+from .backports.functools import cached_property
+from .const import (
+    ATTR_DOMAIN,
+    ATTR_FRIENDLY_NAME,
+    ATTR_SERVICE,
+    ATTR_SERVICE_DATA,
+    COMPRESSED_STATE_ATTRIBUTES,
+    COMPRESSED_STATE_CONTEXT,
+    COMPRESSED_STATE_LAST_CHANGED,
+    COMPRESSED_STATE_LAST_UPDATED,
+    COMPRESSED_STATE_STATE,
+    EVENT_CALL_SERVICE,
+    EVENT_CORE_CONFIG_UPDATE,
+    EVENT_HOMEASSISTANT_CLOSE,
+    EVENT_HOMEASSISTANT_FINAL_WRITE,
+    EVENT_HOMEASSISTANT_START,
+    EVENT_HOMEASSISTANT_STARTED,
+    EVENT_HOMEASSISTANT_STOP,
+    EVENT_SERVICE_REGISTERED,
+    EVENT_SERVICE_REMOVED,
+    EVENT_STATE_CHANGED,
+    MATCH_ALL,
+    MAX_LENGTH_EVENT_EVENT_TYPE,
+    MAX_LENGTH_STATE_STATE,
+    UnitOfLength,
+    __version__,
+)
+from .exceptions import (
+    HomeAssistantError,
+    InvalidEntityFormatError,
+    InvalidStateError,
+    MaxLengthExceeded,
+    ServiceNotFound,
+    Unauthorized,
+)
+from .helpers.deprecation import (
+    DeprecatedConstantEnum,
+    all_with_deprecated_constants,
+    check_if_deprecated_constant,
+    dir_with_deprecated_constants,
+)
+from .helpers.json import json_dumps
+from .util import dt as dt_util, location
+from .util.async_ import (
+    cancelling,
+    run_callback_threadsafe,
+    shutdown_run_callback_threadsafe,
+)
+from .util.json import JsonObjectType
+from .util.read_only_dict import ReadOnlyDict
+from .util.timeout import TimeoutManager
+from .util.ulid import ulid_at_time, ulid_now
+from .util.unit_system import (
+    _CONF_UNIT_SYSTEM_IMPERIAL,
+    _CONF_UNIT_SYSTEM_US_CUSTOMARY,
+    METRIC_SYSTEM,
+    UnitSystem,
+    get_unit_system,
+)
+
+# Typing imports that create a circular dependency
+if TYPE_CHECKING:
+    from .auth import AuthManager
+    from .components.http import ApiConfig, HomeAssistantHTTP
+    from .config_entries import ConfigEntries
+    from .helpers.entity import StateInfo
+
+
+STOPPING_STAGE_SHUTDOWN_TIMEOUT = 20
+STOP_STAGE_SHUTDOWN_TIMEOUT = 100
+FINAL_WRITE_STAGE_SHUTDOWN_TIMEOUT = 60
+CLOSE_STAGE_SHUTDOWN_TIMEOUT = 30
+
+block_async_io.enable()
+
+_T = TypeVar("_T")
+_R = TypeVar("_R")
+_R_co = TypeVar("_R_co", covariant=True)
+_P = ParamSpec("_P")
+# Internal; not helpers.typing.UNDEFINED due to circular dependency
+_UNDEF: dict[Any, Any] = {}
+_CallableT = TypeVar("_CallableT", bound=Callable[..., Any])
+CALLBACK_TYPE = Callable[[], None]
+
+CORE_STORAGE_KEY = "core.config"
+CORE_STORAGE_VERSION = 1
+CORE_STORAGE_MINOR_VERSION = 3
+
+DOMAIN = "homeassistant"
+
+# How long to wait to log tasks that are blocking
+BLOCK_LOG_TIMEOUT = 60
+
+ServiceResponse = JsonObjectType | None
+EntityServiceResponse = dict[str, ServiceResponse]
+
+
+class ConfigSource(enum.StrEnum):
+    """Source of core configuration."""
+
+    DEFAULT = "default"
+    DISCOVERED = "discovered"
+    STORAGE = "storage"
+    YAML = "yaml"
+
+
+# SOURCE_* are deprecated as of Home Assistant 2022.2, use ConfigSource instead
+_DEPRECATED_SOURCE_DISCOVERED = DeprecatedConstantEnum(
+    ConfigSource.DISCOVERED, "2025.1"
+)
+_DEPRECATED_SOURCE_STORAGE = DeprecatedConstantEnum(ConfigSource.STORAGE, "2025.1")
+_DEPRECATED_SOURCE_YAML = DeprecatedConstantEnum(ConfigSource.YAML, "2025.1")
+
+
+# How long to wait until things that run on startup have to finish.
+TIMEOUT_EVENT_START = 15
+
+MAX_EXPECTED_ENTITY_IDS = 16384
+
+_LOGGER = logging.getLogger(__name__)
+
+
+@functools.lru_cache(MAX_EXPECTED_ENTITY_IDS)
+def split_entity_id(entity_id: str) -> tuple[str, str]:
+    """Split a state entity ID into domain and object ID."""
+    domain, _, object_id = entity_id.partition(".")
+    if not domain or not object_id:
+        raise ValueError(f"Invalid entity ID {entity_id}")
+    return domain, object_id
+
+
+_OBJECT_ID = r"(?!_)[\da-z_]+(?<!_)"
+_DOMAIN = r"(?!.+__)" + _OBJECT_ID
+VALID_DOMAIN = re.compile(r"^" + _DOMAIN + r"$")
+VALID_ENTITY_ID = re.compile(r"^" + _DOMAIN + r"\." + _OBJECT_ID + r"$")
+
+
+@functools.lru_cache(64)
+def valid_domain(domain: str) -> bool:
+    """Test if a domain a valid format."""
+    return VALID_DOMAIN.match(domain) is not None
+
+
+@functools.lru_cache(512)
+def valid_entity_id(entity_id: str) -> bool:
+    """Test if an entity ID is a valid format.
+
+    Format: <domain>.<entity> where both are slugs.
+    """
+    return VALID_ENTITY_ID.match(entity_id) is not None
+
+
+def validate_state(state: str) -> str:
+    """Validate a state, raise if it not valid."""
+    if len(state) > MAX_LENGTH_STATE_STATE:
+        raise InvalidStateError(
+            f"Invalid state with length {len(state)}. "
+            "State max length is 255 characters."
+        )
+    return state
+
+
+def callback(func: _CallableT) -> _CallableT:
+    """Annotation to mark method as safe to call from within the event loop."""
+    setattr(func, "_hass_callback", True)
+    return func
+
+
+def is_callback(func: Callable[..., Any]) -> bool:
+    """Check if function is safe to be called in the event loop."""
+    return getattr(func, "_hass_callback", False) is True
+
+
+def is_callback_check_partial(target: Callable[..., Any]) -> bool:
+    """Check if function is safe to be called in the event loop.
+
+    This version of is_callback will also check if the target is a partial
+    and walk the chain of partials to find the original function.
+    """
+    check_target = target
+    while isinstance(check_target, functools.partial):
+        check_target = check_target.func
+    return is_callback(check_target)
+
+
+class _Hass(threading.local):
+    """Container which makes a HomeAssistant instance available to the event loop."""
+
+    hass: HomeAssistant | None = None
+
+
+_hass = _Hass()
+
+
+@callback
+def async_get_hass() -> HomeAssistant:
+    """Return the HomeAssistant instance.
+
+    Raises HomeAssistantError when called from the wrong thread.
+
+    This should be used where it's very cumbersome or downright impossible to pass
+    hass to the code which needs it.
+    """
+    if not _hass.hass:
+        raise HomeAssistantError("async_get_hass called from the wrong thread")
+    return _hass.hass
+
+
+@callback
+def get_release_channel() -> Literal["beta", "dev", "nightly", "stable"]:
+    """Find release channel based on version number."""
+    version = __version__
+    if "dev0" in version:
+        return "dev"
+    if "dev" in version:
+        return "nightly"
+    if "b" in version:
+        return "beta"
+    return "stable"
+
+
+@enum.unique
+class HassJobType(enum.Enum):
+    """Represent a job type."""
+
+    Coroutinefunction = 1
+    Callback = 2
+    Executor = 3
+
+
+class HassJob(Generic[_P, _R_co]):
+    """Represent a job to be run later.
+
+    We check the callable type in advance
+    so we can avoid checking it every time
+    we run the job.
+    """
+
+    __slots__ = ("job_type", "target", "name", "_cancel_on_shutdown")
+
+    def __init__(
+        self,
+        target: Callable[_P, _R_co],
+        name: str | None = None,
+        *,
+        cancel_on_shutdown: bool | None = None,
+        job_type: HassJobType | None = None,
+    ) -> None:
+        """Create a job object."""
+        self.target = target
+        self.name = name
+        self.job_type = job_type or _get_hassjob_callable_job_type(target)
+        self._cancel_on_shutdown = cancel_on_shutdown
+
+    @property
+    def cancel_on_shutdown(self) -> bool | None:
+        """Return if the job should be cancelled on shutdown."""
+        return self._cancel_on_shutdown
+
+    def __repr__(self) -> str:
+        """Return the job."""
+        return f"<Job {self.name} {self.job_type} {self.target}>"
+
+
+@dataclass(frozen=True)
+class HassJobWithArgs:
+    """Container for a HassJob and arguments."""
+
+    job: HassJob[..., Coroutine[Any, Any, Any] | Any]
+    args: Iterable[Any]
+
+
+def _get_hassjob_callable_job_type(target: Callable[..., Any]) -> HassJobType:
+    """Determine the job type from the callable."""
+    # Check for partials to properly determine if coroutine function
+    check_target = target
+    while isinstance(check_target, functools.partial):
+        check_target = check_target.func
+
+    if asyncio.iscoroutinefunction(check_target):
+        return HassJobType.Coroutinefunction
+    if is_callback(check_target):
+        return HassJobType.Callback
+    if asyncio.iscoroutine(check_target):
+        raise ValueError("Coroutine not allowed to be passed to HassJob")
+    return HassJobType.Executor
+
+
+class CoreState(enum.Enum):
+    """Represent the current state of Home Assistant."""
+
+    not_running = "NOT_RUNNING"
+    starting = "STARTING"
+    running = "RUNNING"
+    stopping = "STOPPING"
+    final_write = "FINAL_WRITE"
+    stopped = "STOPPED"
+
+    def __str__(self) -> str:
+        """Return the event."""
+        return self.value
+
+
+class HomeAssistant:
+    """Root object of the Home Assistant home automation."""
+
+    auth: AuthManager
+    http: HomeAssistantHTTP = None  # type: ignore[assignment]
+    config_entries: ConfigEntries = None  # type: ignore[assignment]
+
+    def __new__(cls, config_dir: str) -> HomeAssistant:
+        """Set the _hass thread local data."""
+        hass = super().__new__(cls)
+        _hass.hass = hass
+        return hass
+
+    def __repr__(self) -> str:
+        """Return the representation."""
+        return f"<HomeAssistant {self.state}>"
+
+    def __init__(self, config_dir: str) -> None:
+        """Initialize new Home Assistant object."""
+        # pylint: disable-next=import-outside-toplevel
+        from . import loader
+
+        self.loop = asyncio.get_running_loop()
+        self._tasks: set[asyncio.Future[Any]] = set()
+        self._background_tasks: set[asyncio.Future[Any]] = set()
+        self.bus = EventBus(self)
+        self.services = ServiceRegistry(self)
+        self.states = StateMachine(self.bus, self.loop)
+        self.config = Config(self, config_dir)
+        self.components = loader.Components(self)
+        self.helpers = loader.Helpers(self)
+        # This is a dictionary that any component can store any data on.
+        self.data: dict[str, Any] = {}
+        self.state: CoreState = CoreState.not_running
+        self.exit_code: int = 0
+        # If not None, use to signal end-of-loop
+        self._stopped: asyncio.Event | None = None
+        # Timeout handler for Core/Helper namespace
+        self.timeout: TimeoutManager = TimeoutManager()
+        self._stop_future: concurrent.futures.Future[None] | None = None
+        self._shutdown_jobs: list[HassJobWithArgs] = []
+
+    @property
+    def is_running(self) -> bool:
+        """Return if Home Assistant is running."""
+        return self.state in (CoreState.starting, CoreState.running)
+
+    @property
+    def is_stopping(self) -> bool:
+        """Return if Home Assistant is stopping."""
+        return self.state in (CoreState.stopping, CoreState.final_write)
+
+    def start(self) -> int:
+        """Start Home Assistant.
+
+        Note: This function is only used for testing.
+        For regular use, use "await hass.run()".
+        """
+        # Register the async start
+        _future = asyncio.run_coroutine_threadsafe(self.async_start(), self.loop)
+        # Run forever
+        # Block until stopped
+        _LOGGER.info("Starting Home Assistant core loop")
+        self.loop.run_forever()
+        # The future is never retrieved but we still hold a reference to it
+        # to prevent the task from being garbage collected prematurely.
+        del _future
+        return self.exit_code
+
+    async def async_run(self, *, attach_signals: bool = True) -> int:
+        """Home Assistant main entry point.
+
+        Start Home Assistant and block until stopped.
+
+        This method is a coroutine.
+        """
+        if self.state != CoreState.not_running:
+            raise RuntimeError("Home Assistant is already running")
+
+        # _async_stop will set this instead of stopping the loop
+        self._stopped = asyncio.Event()
+
+        await self.async_start()
+        if attach_signals:
+            # pylint: disable-next=import-outside-toplevel
+            from .helpers.signal import async_register_signal_handling
+
+            async_register_signal_handling(self)
+
+        await self._stopped.wait()
+        return self.exit_code
+
+    async def async_start(self) -> None:
+        """Finalize startup from inside the event loop.
+
+        This method is a coroutine.
+        """
+        _LOGGER.info("Starting Home Assistant")
+        setattr(self.loop, "_thread_ident", threading.get_ident())
+
+        self.state = CoreState.starting
+        self.bus.async_fire(EVENT_CORE_CONFIG_UPDATE)
+        self.bus.async_fire(EVENT_HOMEASSISTANT_START)
+
+        if not self._tasks:
+            pending: set[asyncio.Future[Any]] | None = None
+        else:
+            _done, pending = await asyncio.wait(
+                self._tasks, timeout=TIMEOUT_EVENT_START
+            )
+
+        if pending:
+            _LOGGER.warning(
+                (
+                    "Something is blocking Home Assistant from wrapping up the start up"
+                    " phase. We're going to continue anyway. Please report the"
+                    " following info at"
+                    " https://github.com/home-assistant/core/issues: %s"
+                ),
+                ", ".join(self.config.components),
+            )
+
+        # Allow automations to set up the start triggers before changing state
+        await asyncio.sleep(0)
+
+        if self.state != CoreState.starting:
+            _LOGGER.warning(
+                "Home Assistant startup has been interrupted. "
+                "Its state may be inconsistent"
+            )
+            return
+
+        self.state = CoreState.running
+        self.bus.async_fire(EVENT_CORE_CONFIG_UPDATE)
+        self.bus.async_fire(EVENT_HOMEASSISTANT_STARTED)
+
+    def add_job(
+        self, target: Callable[..., Any] | Coroutine[Any, Any, Any], *args: Any
+    ) -> None:
+        """Add a job to be executed by the event loop or by an executor.
+
+        If the job is either a coroutine or decorated with @callback, it will be
+        run by the event loop, if not it will be run by an executor.
+
+        target: target to call.
+        args: parameters for method to call.
+        """
+        if target is None:
+            raise ValueError("Don't call add_job with None")
+        self.loop.call_soon_threadsafe(self.async_add_job, target, *args)
+
+    @overload
+    @callback
+    def async_add_job(
+        self, target: Callable[..., Coroutine[Any, Any, _R]], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @overload
+    @callback
+    def async_add_job(
+        self, target: Callable[..., Coroutine[Any, Any, _R] | _R], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @overload
+    @callback
+    def async_add_job(
+        self, target: Coroutine[Any, Any, _R], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @callback
+    def async_add_job(
+        self,
+        target: Callable[..., Coroutine[Any, Any, _R] | _R] | Coroutine[Any, Any, _R],
+        *args: Any,
+    ) -> asyncio.Future[_R] | None:
+        """Add a job to be executed by the event loop or by an executor.
+
+        If the job is either a coroutine or decorated with @callback, it will be
+        run by the event loop, if not it will be run by an executor.
+
+        This method must be run in the event loop.
+
+        target: target to call.
+        args: parameters for method to call.
+        """
+        if target is None:
+            raise ValueError("Don't call async_add_job with None")
+
+        if asyncio.iscoroutine(target):
+            return self.async_create_task(target)
+
+        # This code path is performance sensitive and uses
+        # if TYPE_CHECKING to avoid the overhead of constructing
+        # the type used for the cast. For history see:
+        # https://github.com/home-assistant/core/pull/71960
+        if TYPE_CHECKING:
+            target = cast(Callable[..., Coroutine[Any, Any, _R] | _R], target)
+        return self.async_add_hass_job(HassJob(target), *args)
+
+    @overload
+    @callback
+    def async_add_hass_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, _R]], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @overload
+    @callback
+    def async_add_hass_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, _R] | _R], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @callback
+    def async_add_hass_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, _R] | _R], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        """Add a HassJob from within the event loop.
+
+        This method must be run in the event loop.
+        hassjob: HassJob to call.
+        args: parameters for method to call.
+        """
+        task: asyncio.Future[_R]
+        # This code path is performance sensitive and uses
+        # if TYPE_CHECKING to avoid the overhead of constructing
+        # the type used for the cast. For history see:
+        # https://github.com/home-assistant/core/pull/71960
+        if hassjob.job_type == HassJobType.Coroutinefunction:
+            if TYPE_CHECKING:
+                hassjob.target = cast(
+                    Callable[..., Coroutine[Any, Any, _R]], hassjob.target
+                )
+            task = self.loop.create_task(hassjob.target(*args), name=hassjob.name)
+        elif hassjob.job_type == HassJobType.Callback:
+            if TYPE_CHECKING:
+                hassjob.target = cast(Callable[..., _R], hassjob.target)
+            self.loop.call_soon(hassjob.target, *args)
+            return None
+        else:
+            if TYPE_CHECKING:
+                hassjob.target = cast(Callable[..., _R], hassjob.target)
+            task = self.loop.run_in_executor(None, hassjob.target, *args)
+
+        self._tasks.add(task)
+        task.add_done_callback(self._tasks.remove)
+
+        return task
+
+    def create_task(
+        self, target: Coroutine[Any, Any, Any], name: str | None = None
+    ) -> None:
+        """Add task to the executor pool.
+
+        target: target to call.
+        """
+        self.loop.call_soon_threadsafe(self.async_create_task, target, name)
+
+    @callback
+    def async_create_task(
+        self, target: Coroutine[Any, Any, _R], name: str | None = None
+    ) -> asyncio.Task[_R]:
+        """Create a task from within the event loop.
+
+        This method must be run in the event loop. If you are using this in your
+        integration, use the create task methods on the config entry instead.
+
+        target: target to call.
+        """
+        task = self.loop.create_task(target, name=name)
+        self._tasks.add(task)
+        task.add_done_callback(self._tasks.remove)
+        return task
+
+    @callback
+    def async_create_background_task(
+        self,
+        target: Coroutine[Any, Any, _R],
+        name: str,
+    ) -> asyncio.Task[_R]:
+        """Create a task from within the event loop.
+
+        This is a background task which will not block startup and will be
+        automatically cancelled on shutdown. If you are using this in your
+        integration, use the create task methods on the config entry instead.
+
+        This method must be run in the event loop.
+        """
+        task = self.loop.create_task(target, name=name)
+        self._background_tasks.add(task)
+        task.add_done_callback(self._background_tasks.remove)
+        return task
+
+    @callback
+    def async_add_executor_job(
+        self, target: Callable[..., _T], *args: Any
+    ) -> asyncio.Future[_T]:
+        """Add an executor job from within the event loop."""
+        task = self.loop.run_in_executor(None, target, *args)
+        self._tasks.add(task)
+        task.add_done_callback(self._tasks.remove)
+
+        return task
+
+    @overload
+    @callback
+    def async_run_hass_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, _R]], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @overload
+    @callback
+    def async_run_hass_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, _R] | _R], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @callback
+    def async_run_hass_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, _R] | _R], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        """Run a HassJob from within the event loop.
+
+        This method must be run in the event loop.
+
+        hassjob: HassJob
+        args: parameters for method to call.
+        """
+        # This code path is performance sensitive and uses
+        # if TYPE_CHECKING to avoid the overhead of constructing
+        # the type used for the cast. For history see:
+        # https://github.com/home-assistant/core/pull/71960
+        if hassjob.job_type == HassJobType.Callback:
+            if TYPE_CHECKING:
+                hassjob.target = cast(Callable[..., _R], hassjob.target)
+            hassjob.target(*args)
+            return None
+
+        return self.async_add_hass_job(hassjob, *args)
+
+    @overload
+    @callback
+    def async_run_job(
+        self, target: Callable[..., Coroutine[Any, Any, _R]], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @overload
+    @callback
+    def async_run_job(
+        self, target: Callable[..., Coroutine[Any, Any, _R] | _R], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @overload
+    @callback
+    def async_run_job(
+        self, target: Coroutine[Any, Any, _R], *args: Any
+    ) -> asyncio.Future[_R] | None:
+        ...
+
+    @callback
+    def async_run_job(
+        self,
+        target: Callable[..., Coroutine[Any, Any, _R] | _R] | Coroutine[Any, Any, _R],
+        *args: Any,
+    ) -> asyncio.Future[_R] | None:
+        """Run a job from within the event loop.
+
+        This method must be run in the event loop.
+
+        target: target to call.
+        args: parameters for method to call.
+        """
+        if asyncio.iscoroutine(target):
+            return self.async_create_task(target)
+
+        # This code path is performance sensitive and uses
+        # if TYPE_CHECKING to avoid the overhead of constructing
+        # the type used for the cast. For history see:
+        # https://github.com/home-assistant/core/pull/71960
+        if TYPE_CHECKING:
+            target = cast(Callable[..., Coroutine[Any, Any, _R] | _R], target)
+        return self.async_run_hass_job(HassJob(target), *args)
+
+    def block_till_done(self) -> None:
+        """Block until all pending work is done."""
+        asyncio.run_coroutine_threadsafe(
+            self.async_block_till_done(), self.loop
+        ).result()
+
+    async def async_block_till_done(self) -> None:
+        """Block until all pending work is done."""
+        # To flush out any call_soon_threadsafe
+        await asyncio.sleep(0)
+        start_time: float | None = None
+        current_task = asyncio.current_task()
+
+        while tasks := [
+            task
+            for task in self._tasks
+            if task is not current_task and not cancelling(task)
+        ]:
+            await self._await_and_log_pending(tasks)
+
+            if start_time is None:
+                # Avoid calling monotonic() until we know
+                # we may need to start logging blocked tasks.
+                start_time = 0
+            elif start_time == 0:
+                # If we have waited twice then we set the start
+                # time
+                start_time = monotonic()
+            elif monotonic() - start_time > BLOCK_LOG_TIMEOUT:
+                # We have waited at least three loops and new tasks
+                # continue to block. At this point we start
+                # logging all waiting tasks.
+                for task in tasks:
+                    _LOGGER.debug("Waiting for task: %s", task)
+
+    async def _await_and_log_pending(
+        self, pending: Collection[asyncio.Future[Any]]
+    ) -> None:
+        """Await and log tasks that take a long time."""
+        wait_time = 0
+        while pending:
+            _, pending = await asyncio.wait(pending, timeout=BLOCK_LOG_TIMEOUT)
+            if not pending:
+                return
+            wait_time += BLOCK_LOG_TIMEOUT
+            for task in pending:
+                _LOGGER.debug("Waited %s seconds for task: %s", wait_time, task)
+
+    @overload
+    @callback
+    def async_add_shutdown_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, Any]], *args: Any
+    ) -> CALLBACK_TYPE:
+        ...
+
+    @overload
+    @callback
+    def async_add_shutdown_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, Any] | Any], *args: Any
+    ) -> CALLBACK_TYPE:
+        ...
+
+    @callback
+    def async_add_shutdown_job(
+        self, hassjob: HassJob[..., Coroutine[Any, Any, Any] | Any], *args: Any
+    ) -> CALLBACK_TYPE:
+        """Add a HassJob which will be executed on shutdown.
+
+        This method must be run in the event loop.
+
+        hassjob: HassJob
+        args: parameters for method to call.
+
+        Returns function to remove the job.
+        """
+        job_with_args = HassJobWithArgs(hassjob, args)
+        self._shutdown_jobs.append(job_with_args)
+
+        @callback
+        def remove_job() -> None:
+            self._shutdown_jobs.remove(job_with_args)
+
+        return remove_job
+
+    def stop(self) -> None:
+        """Stop Home Assistant and shuts down all threads."""
+        if self.state == CoreState.not_running:  # just ignore
+            return
+        # The future is never retrieved, and we only hold a reference
+        # to it to prevent it from being garbage collected.
+        self._stop_future = asyncio.run_coroutine_threadsafe(
+            self.async_stop(), self.loop
+        )
+
+    async def async_stop(self, exit_code: int = 0, *, force: bool = False) -> None:
+        """Stop Home Assistant and shuts down all threads.
+
+        The "force" flag commands async_stop to proceed regardless of
+        Home Assistant's current state. You should not set this flag
+        unless you're testing.
+
+        This method is a coroutine.
+        """
+        #lqg : save log
+        _LOGGER.warning("=======")
+        # save_log('/home/homeassistant/.homeassistant/provenance_log.json')
+        if not force:
+            # Some tests require async_stop to run,
+            # regardless of the state of the loop.
+            if self.state == CoreState.not_running:  # just ignore
+                return
+            if self.state in [CoreState.stopping, CoreState.final_write]:
+                _LOGGER.info("Additional call to async_stop was ignored")
+                return
+            if self.state == CoreState.starting:
+                # This may not work
+                _LOGGER.warning(
+                    "Stopping Home Assistant before startup has completed may fail"
+                )
+
+        # Stage 1 - Run shutdown jobs
+        try:
+            async with self.timeout.async_timeout(STOPPING_STAGE_SHUTDOWN_TIMEOUT):
+                tasks: list[asyncio.Future[Any]] = []
+                for job in self._shutdown_jobs:
+                    task_or_none = self.async_run_hass_job(job.job, *job.args)
+                    if not task_or_none:
+                        continue
+                    tasks.append(task_or_none)
+                if tasks:
+                    await asyncio.gather(*tasks, return_exceptions=True)
+        except asyncio.TimeoutError:
+            _LOGGER.warning(
+                "Timed out waiting for shutdown jobs to complete, the shutdown will"
+                " continue"
+            )
+            self._async_log_running_tasks("run shutdown jobs")
+
+        # Stage 2 - Stop integrations
+
+        # Keep holding the reference to the tasks but do not allow them
+        # to block shutdown. Only tasks created after this point will
+        # be waited for.
+        running_tasks = self._tasks
+        # Avoid clearing here since we want the remove callbacks to fire
+        # and remove the tasks from the original set which is now running_tasks
+        self._tasks = set()
+
+        # Cancel all background tasks
+        for task in self._background_tasks:
+            self._tasks.add(task)
+            task.add_done_callback(self._tasks.remove)
+            task.cancel("Home Assistant is stopping")
+        self._cancel_cancellable_timers()
+
+        self.exit_code = exit_code
+
+        self.state = CoreState.stopping
+        self.bus.async_fire(EVENT_HOMEASSISTANT_STOP)
+        try:
+            async with self.timeout.async_timeout(STOP_STAGE_SHUTDOWN_TIMEOUT):
+                await self.async_block_till_done()
+        except asyncio.TimeoutError:
+            _LOGGER.warning(
+                "Timed out waiting for integrations to stop, the shutdown will"
+                " continue"
+            )
+            self._async_log_running_tasks("stop integrations")
+
+        # Stage 3 - Final write
+        self.state = CoreState.final_write
+        self.bus.async_fire(EVENT_HOMEASSISTANT_FINAL_WRITE)
+        try:
+            async with self.timeout.async_timeout(FINAL_WRITE_STAGE_SHUTDOWN_TIMEOUT):
+                await self.async_block_till_done()
+        except asyncio.TimeoutError:
+            _LOGGER.warning(
+                "Timed out waiting for final writes to complete, the shutdown will"
+                " continue"
+            )
+            self._async_log_running_tasks("final write")
+
+        # Stage 4 - Close
+        self.state = CoreState.not_running
+        self.bus.async_fire(EVENT_HOMEASSISTANT_CLOSE)
+
+        # Make a copy of running_tasks since a task can finish
+        # while we are awaiting canceled tasks to get their result
+        # which will result in the set size changing during iteration
+        for task in list(running_tasks):
+            if task.done() or cancelling(task):
+                # Since we made a copy we need to check
+                # to see if the task finished while we
+                # were awaiting another task
+                continue
+            _LOGGER.warning(
+                "Task %s was still running after final writes shutdown stage; "
+                "Integrations should cancel non-critical tasks when receiving "
+                "the stop event to prevent delaying shutdown",
+                task,
+            )
+            task.cancel("Home Assistant final writes shutdown stage")
+            try:
+                async with asyncio.timeout(0.1):
+                    await task
+            except asyncio.CancelledError:
+                pass
+            except asyncio.TimeoutError:
+                # Task may be shielded from cancellation.
+                _LOGGER.exception(
+                    "Task %s could not be canceled during final shutdown stage", task
+                )
+            except Exception as exc:  # pylint: disable=broad-except
+                _LOGGER.exception(
+                    "Task %s error during final shutdown stage: %s", task, exc
+                )
+
+        # Prevent run_callback_threadsafe from scheduling any additional
+        # callbacks in the event loop as callbacks created on the futures
+        # it returns will never run after the final `self.async_block_till_done`
+        # which will cause the futures to block forever when waiting for
+        # the `result()` which will cause a deadlock when shutting down the executor.
+        shutdown_run_callback_threadsafe(self.loop)
+
+        try:
+            async with self.timeout.async_timeout(CLOSE_STAGE_SHUTDOWN_TIMEOUT):
+                await self.async_block_till_done()
+        except asyncio.TimeoutError:
+            _LOGGER.warning(
+                "Timed out waiting for close event to be processed, the shutdown will"
+                " continue"
+            )
+            self._async_log_running_tasks("close")
+
+        self.state = CoreState.stopped
+
+        if self._stopped is not None:
+            self._stopped.set()
+
+    def _cancel_cancellable_timers(self) -> None:
+        """Cancel timer handles marked as cancellable."""
+        # pylint: disable-next=protected-access
+        handles: Iterable[asyncio.TimerHandle] = self.loop._scheduled  # type: ignore[attr-defined]
+        for handle in handles:
+            if (
+                not handle.cancelled()
+                and (args := handle._args)  # pylint: disable=protected-access
+                and type(job := args[0]) is HassJob  # noqa: E721
+                and job.cancel_on_shutdown
+            ):
+                handle.cancel()
+
+    def _async_log_running_tasks(self, stage: str) -> None:
+        """Log all running tasks."""
+        for task in self._tasks:
+            _LOGGER.warning("Shutdown stage '%s': still running: %s", stage, task)
+
+
+class Context:
+    """The context that triggered something."""
+
+    __slots__ = ("user_id", "parent_id", "id", "origin_event", "_as_dict")
+
+    def __init__(
+        self,
+        user_id: str | None = None,
+        parent_id: str | None = None,
+        id: str | None = None,  # pylint: disable=redefined-builtin
+    ) -> None:
+        """Init the context."""
+        self.id = id or ulid_now()
+        self.user_id = user_id
+        self.parent_id = parent_id
+        self.origin_event: Event | None = None
+        self._as_dict: ReadOnlyDict[str, str | None] | None = None
+
+    def __eq__(self, other: Any) -> bool:
+        """Compare contexts."""
+        return bool(self.__class__ == other.__class__ and self.id == other.id)
+
+    def as_dict(self) -> ReadOnlyDict[str, str | None]:
+        """Return a dictionary representation of the context."""
+        if not self._as_dict:
+            self._as_dict = ReadOnlyDict(
+                {
+                    "id": self.id,
+                    "parent_id": self.parent_id,
+                    "user_id": self.user_id,
+                }
+            )
+        return self._as_dict
+
+
+class EventOrigin(enum.Enum):
+    """Represent the origin of an event."""
+
+    local = "LOCAL"
+    remote = "REMOTE"
+
+    def __str__(self) -> str:
+        """Return the event."""
+        return self.value
+
+
+class Event:
+    """Representation of an event within the bus."""
+
+    __slots__ = ("event_type", "data", "origin", "time_fired", "context", "_as_dict")
+
+    def __init__(
+        self,
+        event_type: str,
+        data: dict[str, Any] | None = None,
+        origin: EventOrigin = EventOrigin.local,
+        time_fired: datetime.datetime | None = None,
+        context: Context | None = None,
+    ) -> None:
+        """Initialize a new event."""
+        self.event_type = event_type
+        self.data = data or {}
+        self.origin = origin
+        self.time_fired = time_fired or dt_util.utcnow()
+        if not context:
+            context = Context(
+                id=ulid_at_time(dt_util.utc_to_timestamp(self.time_fired))
+            )
+        self.context = context
+        self._as_dict: ReadOnlyDict[str, Any] | None = None
+        if not context.origin_event:
+            context.origin_event = self
+
+    def as_dict(self) -> ReadOnlyDict[str, Any]:
+        """Create a dict representation of this Event.
+
+        Async friendly.
+        """
+        if not self._as_dict:
+            self._as_dict = ReadOnlyDict(
+                {
+                    "event_type": self.event_type,
+                    "data": ReadOnlyDict(self.data),
+                    "origin": self.origin.value,
+                    "time_fired": self.time_fired.isoformat(),
+                    "context": self.context.as_dict(),
+                }
+            )
+        return self._as_dict
+
+    def __repr__(self) -> str:
+        """Return the representation."""
+        if self.data:
+            return (
+                f"<Event {self.event_type}[{str(self.origin)[0]}]:"
+                f" {util.repr_helper(self.data)}>"
+            )
+
+        return f"<Event {self.event_type}[{str(self.origin)[0]}]>"
+
+
+_FilterableJobType = tuple[
+    HassJob[[Event], Coroutine[Any, Any, None] | None],  # job
+    Callable[[Event], bool] | None,  # event_filter
+    bool,  # run_immediately
+]
+
+
+class EventBus:
+    """Allow the firing of and listening for events."""
+
+    __slots__ = ("_listeners", "_match_all_listeners", "_hass")
+
+    def __init__(self, hass: HomeAssistant) -> None:
+        """Initialize a new event bus."""
+        self._listeners: dict[str, list[_FilterableJobType]] = {}
+        self._match_all_listeners: list[_FilterableJobType] = []
+        self._listeners[MATCH_ALL] = self._match_all_listeners
+        self._hass = hass
+
+    @callback
+    def async_listeners(self) -> dict[str, int]:
+        """Return dictionary with events and the number of listeners.
+
+        This method must be run in the event loop.
+        """
+        return {key: len(listeners) for key, listeners in self._listeners.items()}
+
+    @property
+    def listeners(self) -> dict[str, int]:
+        """Return dictionary with events and the number of listeners."""
+        return run_callback_threadsafe(self._hass.loop, self.async_listeners).result()
+
+    def fire(
+        self,
+        event_type: str,
+        event_data: dict[str, Any] | None = None,
+        origin: EventOrigin = EventOrigin.local,
+        context: Context | None = None,
+    ) -> None:
+        """Fire an event."""
+        self._hass.loop.call_soon_threadsafe(
+            self.async_fire, event_type, event_data, origin, context
+        )
+
+    @callback
+    def async_fire(
+        self,
+        event_type: str,
+        event_data: dict[str, Any] | None = None,
+        origin: EventOrigin = EventOrigin.local,
+        context: Context | None = None,
+        time_fired: datetime.datetime | None = None,
+    ) -> None:
+        """Fire an event.
+
+        This method must be run in the event loop.
+        """
+        if len(event_type) > MAX_LENGTH_EVENT_EVENT_TYPE:
+            raise MaxLengthExceeded(
+                event_type, "event_type", MAX_LENGTH_EVENT_EVENT_TYPE
+            )
+
+        listeners = self._listeners.get(event_type, [])
+        match_all_listeners = self._match_all_listeners
+
+        event = Event(event_type, event_data, origin, time_fired, context)
+
+        if _LOGGER.isEnabledFor(logging.DEBUG):
+            _LOGGER.debug("Bus:Handling %s", event)
+
+        if not listeners and not match_all_listeners:
+            return
+
+        # EVENT_HOMEASSISTANT_CLOSE should not be sent to MATCH_ALL listeners
+        if event_type != EVENT_HOMEASSISTANT_CLOSE:
+            listeners = match_all_listeners + listeners
+
+        for job, event_filter, run_immediately in listeners:
+            if event_filter is not None:
+                try:
+                    if not event_filter(event):
+                        continue
+                except Exception:  # pylint: disable=broad-except
+                    _LOGGER.exception("Error in event filter")
+                    continue
+            if run_immediately:
+                try:
+                    job.target(event)
+                except Exception:  # pylint: disable=broad-except
+                    _LOGGER.exception("Error running job: %s", job)
+            else:
+                self._hass.async_add_hass_job(job, event)
+
+    def listen(
+        self,
+        event_type: str,
+        listener: Callable[[Event], Coroutine[Any, Any, None] | None],
+    ) -> CALLBACK_TYPE:
+        """Listen for all events or events of a specific type.
+
+        To listen to all events specify the constant ``MATCH_ALL``
+        as event_type.
+        """
+        async_remove_listener = run_callback_threadsafe(
+            self._hass.loop, self.async_listen, event_type, listener
+        ).result()
+
+        def remove_listener() -> None:
+            """Remove the listener."""
+            run_callback_threadsafe(self._hass.loop, async_remove_listener).result()
+
+        return remove_listener
+
+    @callback
+    def async_listen(
+        self,
+        event_type: str,
+        listener: Callable[[Event], Coroutine[Any, Any, None] | None],
+        event_filter: Callable[[Event], bool] | None = None,
+        run_immediately: bool = False,
+    ) -> CALLBACK_TYPE:
+        """Listen for all events or events of a specific type.
+
+        To listen to all events specify the constant ``MATCH_ALL``
+        as event_type.
+
+        An optional event_filter, which must be a callable decorated with
+        @callback that returns a boolean value, determines if the
+        listener callable should run.
+
+        If run_immediately is passed, the callback will be run
+        right away instead of using call_soon. Only use this if
+        the callback results in scheduling another task.
+
+        This method must be run in the event loop.
+        """
+        job_type: HassJobType | None = None
+        if event_filter is not None and not is_callback_check_partial(event_filter):
+            raise HomeAssistantError(f"Event filter {event_filter} is not a callback")
+        if run_immediately:
+            if not is_callback_check_partial(listener):
+                raise HomeAssistantError(f"Event listener {listener} is not a callback")
+            job_type = HassJobType.Callback
+        return self._async_listen_filterable_job(
+            event_type,
+            (
+                HassJob(listener, f"listen {event_type}", job_type=job_type),
+                event_filter,
+                run_immediately,
+            ),
+        )
+
+    @callback
+    def _async_listen_filterable_job(
+        self, event_type: str, filterable_job: _FilterableJobType
+    ) -> CALLBACK_TYPE:
+        self._listeners.setdefault(event_type, []).append(filterable_job)
+        return functools.partial(
+            self._async_remove_listener, event_type, filterable_job
+        )
+
+    def listen_once(
+        self,
+        event_type: str,
+        listener: Callable[[Event], Coroutine[Any, Any, None] | None],
+    ) -> CALLBACK_TYPE:
+        """Listen once for event of a specific type.
+
+        To listen to all events specify the constant ``MATCH_ALL``
+        as event_type.
+
+        Returns function to unsubscribe the listener.
+        """
+        async_remove_listener = run_callback_threadsafe(
+            self._hass.loop, self.async_listen_once, event_type, listener
+        ).result()
+
+        def remove_listener() -> None:
+            """Remove the listener."""
+            run_callback_threadsafe(self._hass.loop, async_remove_listener).result()
+
+        return remove_listener
+
+    @callback
+    def async_listen_once(
+        self,
+        event_type: str,
+        listener: Callable[[Event], Coroutine[Any, Any, None] | None],
+    ) -> CALLBACK_TYPE:
+        """Listen once for event of a specific type.
+
+        To listen to all events specify the constant ``MATCH_ALL``
+        as event_type.
+
+        Returns registered listener that can be used with remove_listener.
+
+        This method must be run in the event loop.
+        """
+        filterable_job: _FilterableJobType | None = None
+
+        @callback
+        def _onetime_listener(event: Event) -> None:
+            """Remove listener from event bus and then fire listener."""
+            nonlocal filterable_job
+            if hasattr(_onetime_listener, "run"):
+                return
+            # Set variable so that we will never run twice.
+            # Because the event bus loop might have async_fire queued multiple
+            # times, its possible this listener may already be lined up
+            # multiple times as well.
+            # This will make sure the second time it does nothing.
+            setattr(_onetime_listener, "run", True)
+            assert filterable_job is not None
+            self._async_remove_listener(event_type, filterable_job)
+            self._hass.async_run_job(listener, event)
+
+        functools.update_wrapper(
+            _onetime_listener, listener, ("__name__", "__qualname__", "__module__"), []
+        )
+
+        filterable_job = (
+            HassJob(
+                _onetime_listener,
+                f"onetime listen {event_type} {listener}",
+                job_type=HassJobType.Callback,
+            ),
+            None,
+            False,
+        )
+
+        return self._async_listen_filterable_job(event_type, filterable_job)
+
+    @callback
+    def _async_remove_listener(
+        self, event_type: str, filterable_job: _FilterableJobType
+    ) -> None:
+        """Remove a listener of a specific event_type.
+
+        This method must be run in the event loop.
+        """
+        try:
+            self._listeners[event_type].remove(filterable_job)
+
+            # delete event_type list if empty
+            if not self._listeners[event_type] and event_type != MATCH_ALL:
+                self._listeners.pop(event_type)
+        except (KeyError, ValueError):
+            # KeyError is key event_type listener did not exist
+            # ValueError if listener did not exist within event_type
+            _LOGGER.exception(
+                "Unable to remove unknown job listener %s", filterable_job
+            )
+
+
+class State:
+    """Object to represent a state within the state machine.
+
+    entity_id: the entity that is represented.
+    state: the state of the entity
+    attributes: extra information on entity and state
+    last_changed: last time the state was changed, not the attributes.
+    last_updated: last time this object was updated.
+    context: Context in which it was created
+    domain: Domain of this state.
+    object_id: Object id of this state.
+    """
+
+    def __init__(
+        self,
+        entity_id: str,
+        state: str,
+        attributes: Mapping[str, Any] | None = None,
+        last_changed: datetime.datetime | None = None,
+        last_updated: datetime.datetime | None = None,
+        context: Context | None = None,
+        validate_entity_id: bool | None = True,
+        state_info: StateInfo | None = None,
+    ) -> None:
+        """Initialize a new state."""
+        state = str(state)
+
+        if validate_entity_id and not valid_entity_id(entity_id):
+            raise InvalidEntityFormatError(
+                f"Invalid entity id encountered: {entity_id}. "
+                "Format should be <domain>.<object_id>"
+            )
+
+        validate_state(state)
+
+        self.entity_id = entity_id
+        self.state = state
+        self.attributes = ReadOnlyDict(attributes or {})
+        self.last_updated = last_updated or dt_util.utcnow()
+        self.last_changed = last_changed or self.last_updated
+        self.context = context or Context()
+        self.state_info = state_info
+        self.domain, self.object_id = split_entity_id(self.entity_id)
+        self._as_dict: ReadOnlyDict[str, Collection[Any]] | None = None
+
+    @property
+    def name(self) -> str:
+        """Name of this state."""
+        return self.attributes.get(ATTR_FRIENDLY_NAME) or self.object_id.replace(
+            "_", " "
+        )
+
+    def as_dict(self) -> ReadOnlyDict[str, Collection[Any]]:
+        """Return a dict representation of the State.
+
+        Async friendly.
+
+        To be used for JSON serialization.
+        Ensures: state == State.from_dict(state.as_dict())
+        """
+        if not self._as_dict:
+            last_changed_isoformat = self.last_changed.isoformat()
+            if self.last_changed == self.last_updated:
+                last_updated_isoformat = last_changed_isoformat
+            else:
+                last_updated_isoformat = self.last_updated.isoformat()
+            self._as_dict = ReadOnlyDict(
+                {
+                    "entity_id": self.entity_id,
+                    "state": self.state,
+                    "attributes": self.attributes,
+                    "last_changed": last_changed_isoformat,
+                    "last_updated": last_updated_isoformat,
+                    "context": self.context.as_dict(),
+                }
+            )
+        return self._as_dict
+
+    @cached_property
+    def as_dict_json(self) -> str:
+        """Return a JSON string of the State."""
+        return json_dumps(self.as_dict())
+
+    @cached_property
+    def as_compressed_state(self) -> dict[str, Any]:
+        """Build a compressed dict of a state for adds.
+
+        Omits the lu (last_updated) if it matches (lc) last_changed.
+
+        Sends c (context) as a string if it only contains an id.
+        """
+        state_context = self.context
+        if state_context.parent_id is None and state_context.user_id is None:
+            context: dict[str, Any] | str = state_context.id
+        else:
+            context = state_context.as_dict()
+        compressed_state = {
+            COMPRESSED_STATE_STATE: self.state,
+            COMPRESSED_STATE_ATTRIBUTES: self.attributes,
+            COMPRESSED_STATE_CONTEXT: context,
+            COMPRESSED_STATE_LAST_CHANGED: dt_util.utc_to_timestamp(self.last_changed),
+        }
+        if self.last_changed != self.last_updated:
+            compressed_state[COMPRESSED_STATE_LAST_UPDATED] = dt_util.utc_to_timestamp(
+                self.last_updated
+            )
+        return compressed_state
+
+    @cached_property
+    def as_compressed_state_json(self) -> str:
+        """Build a compressed JSON key value pair of a state for adds.
+
+        The JSON string is a key value pair of the entity_id and the compressed state.
+
+        It is used for sending multiple states in a single message.
+        """
+        return json_dumps({self.entity_id: self.as_compressed_state})[1:-1]
+
+    @classmethod
+    def from_dict(cls, json_dict: dict[str, Any]) -> Self | None:
+        """Initialize a state from a dict.
+
+        Async friendly.
+
+        Ensures: state == State.from_json_dict(state.to_json_dict())
+        """
+        if not (json_dict and "entity_id" in json_dict and "state" in json_dict):
+            return None
+
+        last_changed = json_dict.get("last_changed")
+
+        if isinstance(last_changed, str):
+            last_changed = dt_util.parse_datetime(last_changed)
+
+        last_updated = json_dict.get("last_updated")
+
+        if isinstance(last_updated, str):
+            last_updated = dt_util.parse_datetime(last_updated)
+
+        if context := json_dict.get("context"):
+            context = Context(id=context.get("id"), user_id=context.get("user_id"))
+
+        return cls(
+            json_dict["entity_id"],
+            json_dict["state"],
+            json_dict.get("attributes"),
+            last_changed,
+            last_updated,
+            context,
+        )
+
+    def expire(self) -> None:
+        """Mark the state as old.
+
+        We give up the original reference to the context to ensure
+        the context can be garbage collected by replacing it with
+        a new one with the same id to ensure the old state
+        can still be examined for comparison against the new state.
+
+        Since we are always going to fire a EVENT_STATE_CHANGED event
+        after we remove a state from the state machine we need to make
+        sure we don't end up holding a reference to the original context
+        since it can never be garbage collected as each event would
+        reference the previous one.
+        """
+        self.context = Context(
+            self.context.user_id, self.context.parent_id, self.context.id
+        )
+
+    def __repr__(self) -> str:
+        """Return the representation of the states."""
+        attrs = f"; {util.repr_helper(self.attributes)}" if self.attributes else ""
+
+        return (
+            f"<state {self.entity_id}={self.state}{attrs}"
+            f" @ {dt_util.as_local(self.last_changed).isoformat()}>"
+        )
+
+
+class States(UserDict[str, State]):
+    """Container for states, maps entity_id -> State.
+
+    Maintains an additional index:
+    - domain -> dict[str, State]
+    """
+
+    def __init__(self) -> None:
+        """Initialize the container."""
+        super().__init__()
+        self._domain_index: defaultdict[str, dict[str, State]] = defaultdict(dict)
+
+    def values(self) -> ValuesView[State]:
+        """Return the underlying values to avoid __iter__ overhead."""
+        return self.data.values()
+
+    def __setitem__(self, key: str, entry: State) -> None:
+        """Add an item."""
+        self.data[key] = entry
+        self._domain_index[entry.domain][entry.entity_id] = entry
+
+    def __delitem__(self, key: str) -> None:
+        """Remove an item."""
+        entry = self[key]
+        del self._domain_index[entry.domain][entry.entity_id]
+        super().__delitem__(key)
+
+    def domain_entity_ids(self, key: str) -> KeysView[str] | tuple[()]:
+        """Get all entity_ids for a domain."""
+        # Avoid polluting _domain_index with non-existing domains
+        if key not in self._domain_index:
+            return ()
+        return self._domain_index[key].keys()
+
+    def domain_states(self, key: str) -> ValuesView[State] | tuple[()]:
+        """Get all states for a domain."""
+        # Avoid polluting _domain_index with non-existing domains
+        if key not in self._domain_index:
+            return ()
+        return self._domain_index[key].values()
+
+
+class StateMachine:
+    """Helper class that tracks the state of different entities."""
+
+    __slots__ = ("_states", "_states_data", "_reservations", "_bus", "_loop")
+
+    def __init__(self, bus: EventBus, loop: asyncio.events.AbstractEventLoop) -> None:
+        """Initialize state machine."""
+        self._states = States()
+        # _states_data is used to access the States backing dict directly to speed
+        # up read operations
+        self._states_data = self._states.data
+        self._reservations: set[str] = set()
+        self._bus = bus
+        self._loop = loop
+
+    def entity_ids(self, domain_filter: str | None = None) -> list[str]:
+        """List of entity ids that are being tracked."""
+        future = run_callback_threadsafe(
+            self._loop, self.async_entity_ids, domain_filter
+        )
+        return future.result()
+
+    @callback
+    def async_entity_ids(
+        self, domain_filter: str | Iterable[str] | None = None
+    ) -> list[str]:
+        """List of entity ids that are being tracked.
+
+        This method must be run in the event loop.
+        """
+        if domain_filter is None:
+            return list(self._states_data)
+
+        if isinstance(domain_filter, str):
+            return list(self._states.domain_entity_ids(domain_filter.lower()))
+
+        entity_ids: list[str] = []
+        for domain in domain_filter:
+            entity_ids.extend(self._states.domain_entity_ids(domain))
+        return entity_ids
+
+    @callback
+    def async_entity_ids_count(
+        self, domain_filter: str | Iterable[str] | None = None
+    ) -> int:
+        """Count the entity ids that are being tracked.
+
+        This method must be run in the event loop.
+        """
+        if domain_filter is None:
+            return len(self._states_data)
+
+        if isinstance(domain_filter, str):
+            return len(self._states.domain_entity_ids(domain_filter.lower()))
+
+        return sum(
+            len(self._states.domain_entity_ids(domain)) for domain in domain_filter
+        )
+
+    def all(self, domain_filter: str | Iterable[str] | None = None) -> list[State]:
+        """Create a list of all states."""
+        return run_callback_threadsafe(
+            self._loop, self.async_all, domain_filter
+        ).result()
+
+    @callback
+    def async_all(
+        self, domain_filter: str | Iterable[str] | None = None
+    ) -> list[State]:
+        """Create a list of all states matching the filter.
+
+        This method must be run in the event loop.
+        """
+        if domain_filter is None:
+            return list(self._states_data.values())
+
+        if isinstance(domain_filter, str):
+            return list(self._states.domain_states(domain_filter.lower()))
+
+        states: list[State] = []
+        for domain in domain_filter:
+            states.extend(self._states.domain_states(domain))
+        return states
+
+    def get(self, entity_id: str) -> State | None:
+        """Retrieve state of entity_id or None if not found.
+
+        Async friendly.
+        """
+        return self._states_data.get(entity_id.lower())
+
+    def is_state(self, entity_id: str, state: str) -> bool:
+        """Test if entity exists and is in specified state.
+
+        Async friendly.
+        """
+        state_obj = self.get(entity_id)
+        return state_obj is not None and state_obj.state == state
+
+    def remove(self, entity_id: str) -> bool:
+        """Remove the state of an entity.
+
+        Returns boolean to indicate if an entity was removed.
+        """
+        return run_callback_threadsafe(
+            self._loop, self.async_remove, entity_id
+        ).result()
+
+    @callback
+    def async_remove(self, entity_id: str, context: Context | None = None) -> bool:
+        """Remove the state of an entity.
+
+        Returns boolean to indicate if an entity was removed.
+
+        This method must be run in the event loop.
+        """
+        entity_id = entity_id.lower()
+        old_state = self._states.pop(entity_id, None)
+        self._reservations.discard(entity_id)
+
+        if old_state is None:
+            return False
+
+        old_state.expire()
+        self._bus.async_fire(
+            EVENT_STATE_CHANGED,
+            {"entity_id": entity_id, "old_state": old_state, "new_state": None},
+            EventOrigin.local,
+            context=context,
+        )
+        return True
+
+    def set(
+        self,
+        entity_id: str,
+        new_state: str,
+        attributes: Mapping[str, Any] | None = None,
+        force_update: bool = False,
+        context: Context | None = None,
+    ) -> None:
+        """Set the state of an entity, add entity if it does not exist.
+
+        Attributes is an optional dict to specify attributes of this state.
+
+        If you just update the attributes and not the state, last changed will
+        not be affected.
+        """
+        run_callback_threadsafe(
+            self._loop,
+            self.async_set,
+            entity_id,
+            new_state,
+            attributes,
+            force_update,
+            context,
+        ).result()
+
+    @callback
+    def async_reserve(self, entity_id: str) -> None:
+        """Reserve a state in the state machine for an entity being added.
+
+        This must not fire an event when the state is reserved.
+
+        This avoids a race condition where multiple entities with the same
+        entity_id are added.
+        """
+        entity_id = entity_id.lower()
+        if entity_id in self._states_data or entity_id in self._reservations:
+            raise HomeAssistantError(
+                "async_reserve must not be called once the state is in the state"
+                " machine."
+            )
+
+        self._reservations.add(entity_id)
+
+    @callback
+    def async_available(self, entity_id: str) -> bool:
+        """Check to see if an entity_id is available to be used."""
+        entity_id = entity_id.lower()
+        return (
+            entity_id not in self._states_data and entity_id not in self._reservations
+        )
+
+    @callback
+    def async_set(
+        self,
+        entity_id: str,
+        new_state: str,
+        attributes: Mapping[str, Any] | None = None,
+        force_update: bool = False,
+        context: Context | None = None,
+        state_info: StateInfo | None = None,
+    ) -> None:
+        """Set the state of an entity, add entity if it does not exist.
+
+        Attributes is an optional dict to specify attributes of this state.
+
+        If you just update the attributes and not the state, last changed will
+        not be affected.
+
+        This method must be run in the event loop.
+        """
+        entity_id = entity_id.lower()
+        new_state = str(new_state)
+        attributes = attributes or {}
+        if (old_state := self._states_data.get(entity_id)) is None:
+            same_state = False
+            same_attr = False
+            last_changed = None
+        else:
+            same_state = old_state.state == new_state and not force_update
+            same_attr = old_state.attributes == attributes
+            last_changed = old_state.last_changed if same_state else None
+
+        if same_state and same_attr:
+            return
+
+        if context is None:
+            # It is much faster to convert a timestamp to a utc datetime object
+            # than converting a utc datetime object to a timestamp since cpython
+            # does not have a fast path for handling the UTC timezone and has to do
+            # multiple local timezone conversions.
+            #
+            # from_timestamp implementation:
+            # https://github.com/python/cpython/blob/c90a862cdcf55dc1753c6466e5fa4a467a13ae24/Modules/_datetimemodule.c#L2936
+            #
+            # timestamp implementation:
+            # https://github.com/python/cpython/blob/c90a862cdcf55dc1753c6466e5fa4a467a13ae24/Modules/_datetimemodule.c#L6387
+            # https://github.com/python/cpython/blob/c90a862cdcf55dc1753c6466e5fa4a467a13ae24/Modules/_datetimemodule.c#L6323
+            timestamp = time.time()
+            now = dt_util.utc_from_timestamp(timestamp)
+            context = Context(id=ulid_at_time(timestamp))
+        else:
+            now = dt_util.utcnow()
+
+        state = State(
+            entity_id,
+            new_state,
+            attributes,
+            last_changed,
+            now,
+            context,
+            old_state is None,
+            state_info,
+        )
+        if old_state is not None:
+            old_state.expire()
+
+        
+        # #lqg lalala
+        # # 正确比较状态值（处理old_state为None的情况）
+        # old_state_val = old_state.state if old_state else None
+        # if old_state_val != new_state:
+        # #if old_state != new_state:
+        #     is_automation_triggered = (context.parent_id is not None and context.parent_id.startswith("automation_"))
+        #     if not is_automation_triggered:  # 仅记录非自动化触发的状态变化
+        #         log_state_change(
+        #             entity_id=entity_id,
+        #             new_state=new_state,
+        #             old_state=old_state.state if old_state else "None",
+        #             context=context
+        #         )
+
+        self._states[entity_id] = state
+        self._bus.async_fire(
+            EVENT_STATE_CHANGED,
+            {"entity_id": entity_id, "old_state": old_state, "new_state": state},
+            EventOrigin.local,
+            context,
+            time_fired=now,
+        )
+
+
+class SupportsResponse(enum.StrEnum):
+    """Service call response configuration."""
+
+    NONE = "none"
+    """The service does not support responses (the default)."""
+
+    OPTIONAL = "optional"
+    """The service optionally returns response data when asked by the caller."""
+
+    ONLY = "only"
+    """The service is read-only and the caller must always ask for response data."""
+
+
+class Service:
+    """Representation of a callable service."""
+
+    __slots__ = ["job", "schema", "domain", "service", "supports_response"]
+
+    def __init__(
+        self,
+        func: Callable[
+            [ServiceCall],
+            Coroutine[Any, Any, ServiceResponse | EntityServiceResponse]
+            | ServiceResponse
+            | EntityServiceResponse
+            | None,
+        ],
+        schema: vol.Schema | None,
+        domain: str,
+        service: str,
+        context: Context | None = None,
+        supports_response: SupportsResponse = SupportsResponse.NONE,
+    ) -> None:
+        """Initialize a service."""
+        self.job = HassJob(func, f"service {domain}.{service}")
+        self.schema = schema
+        self.supports_response = supports_response
+
+
+class ServiceCall:
+    """Representation of a call to a service."""
+
+    __slots__ = ("domain", "service", "data", "context", "return_response")
+
+    def __init__(
+        self,
+        domain: str,
+        service: str,
+        data: dict[str, Any] | None = None,
+        context: Context | None = None,
+        return_response: bool = False,
+    ) -> None:
+        """Initialize a service call."""
+        self.domain = domain
+        self.service = service
+        self.data = ReadOnlyDict(data or {})
+        self.context = context or Context()
+        self.return_response = return_response
+
+    def __repr__(self) -> str:
+        """Return the representation of the service."""
+        if self.data:
+            return (
+                f"<ServiceCall {self.domain}.{self.service} "
+                f"(c:{self.context.id}): {util.repr_helper(self.data)}>"
+            )
+
+        return f"<ServiceCall {self.domain}.{self.service} (c:{self.context.id})>"
+
+
+class ServiceRegistry:
+    """Offer the services over the eventbus."""
+
+    __slots__ = ("_services", "_hass")
+
+    def __init__(self, hass: HomeAssistant) -> None:
+        """Initialize a service registry."""
+        self._services: dict[str, dict[str, Service]] = {}
+        self._hass = hass
+
+    @property
+    def services(self) -> dict[str, dict[str, Service]]:
+        """Return dictionary with per domain a list of available services."""
+        return run_callback_threadsafe(self._hass.loop, self.async_services).result()
+
+    @callback
+    def async_services(self) -> dict[str, dict[str, Service]]:
+        """Return dictionary with per domain a list of available services.
+
+        This method must be run in the event loop.
+        """
+        return {domain: service.copy() for domain, service in self._services.items()}
+
+    def has_service(self, domain: str, service: str) -> bool:
+        """Test if specified service exists.
+
+        Async friendly.
+        """
+        return service.lower() in self._services.get(domain.lower(), [])
+
+    def supports_response(self, domain: str, service: str) -> SupportsResponse:
+        """Return whether or not the service supports response data.
+
+        This exists so that callers can return more helpful error messages given
+        the context. Will return NONE if the service does not exist as there is
+        other error handling when calling the service if it does not exist.
+        """
+        if not (handler := self._services[domain.lower()][service.lower()]):
+            return SupportsResponse.NONE
+        return handler.supports_response
+
+    def register(
+        self,
+        domain: str,
+        service: str,
+        service_func: Callable[
+            [ServiceCall],
+            Coroutine[Any, Any, ServiceResponse] | ServiceResponse | None,
+        ],
+        schema: vol.Schema | None = None,
+        supports_response: SupportsResponse = SupportsResponse.NONE,
+    ) -> None:
+        """Register a service.
+
+        Schema is called to coerce and validate the service data.
+        """
+        run_callback_threadsafe(
+            self._hass.loop,
+            self.async_register,
+            domain,
+            service,
+            service_func,
+            schema,
+            supports_response,
+        ).result()
+
+    @callback
+    def async_register(
+        self,
+        domain: str,
+        service: str,
+        service_func: Callable[
+            [ServiceCall],
+            Coroutine[Any, Any, ServiceResponse | EntityServiceResponse]
+            | ServiceResponse
+            | EntityServiceResponse
+            | None,
+        ],
+        schema: vol.Schema | None = None,
+        supports_response: SupportsResponse = SupportsResponse.NONE,
+    ) -> None:
+        """Register a service.
+
+        Schema is called to coerce and validate the service data.
+
+        This method must be run in the event loop.
+        """
+        domain = domain.lower()
+        service = service.lower()
+        service_obj = Service(
+            service_func, schema, domain, service, supports_response=supports_response
+        )
+
+        if domain in self._services:
+            self._services[domain][service] = service_obj
+        else:
+            self._services[domain] = {service: service_obj}
+
+        self._hass.bus.async_fire(
+            EVENT_SERVICE_REGISTERED, {ATTR_DOMAIN: domain, ATTR_SERVICE: service}
+        )
+
+    def remove(self, domain: str, service: str) -> None:
+        """Remove a registered service from service handler."""
+        run_callback_threadsafe(
+            self._hass.loop, self.async_remove, domain, service
+        ).result()
+
+    @callback
+    def async_remove(self, domain: str, service: str) -> None:
+        """Remove a registered service from service handler.
+
+        This method must be run in the event loop.
+        """
+        domain = domain.lower()
+        service = service.lower()
+
+        if service not in self._services.get(domain, {}):
+            _LOGGER.warning("Unable to remove unknown service %s/%s", domain, service)
+            return
+
+        self._services[domain].pop(service)
+
+        if not self._services[domain]:
+            self._services.pop(domain)
+
+        self._hass.bus.async_fire(
+            EVENT_SERVICE_REMOVED, {ATTR_DOMAIN: domain, ATTR_SERVICE: service}
+        )
+
+    def call(
+        self,
+        domain: str,
+        service: str,
+        service_data: dict[str, Any] | None = None,
+        blocking: bool = False,
+        context: Context | None = None,
+        target: dict[str, Any] | None = None,
+        return_response: bool = False,
+    ) -> ServiceResponse:
+        """Call a service.
+
+        See description of async_call for details.
+        """
+        return asyncio.run_coroutine_threadsafe(
+            self.async_call(
+                domain,
+                service,
+                service_data,
+                blocking,
+                context,
+                target,
+                return_response,
+            ),
+            self._hass.loop,
+        ).result()
+
+    async def async_call(
+        self,
+        domain: str,
+        service: str,
+        service_data: dict[str, Any] | None = None,
+        blocking: bool = False,
+        context: Context | None = None,
+        target: dict[str, Any] | None = None,
+        return_response: bool = False,
+    ) -> ServiceResponse:
+        """Call a service.
+
+        Specify blocking=True to wait until service is executed.
+
+        If return_response=True, indicates that the caller can consume return values
+        from the service, if any. Return values are a dict that can be returned by the
+        standard JSON serialization process. Return values can only be used with blocking=True.
+
+        This method will fire an event to indicate the service has been called.
+
+        Because the service is sent as an event you are not allowed to use
+        the keys ATTR_DOMAIN and ATTR_SERVICE in your service_data.
+
+        This method is a coroutine.
+        """
+        context = context or Context()
+        service_data = service_data or {}
+
+        try:
+            handler = self._services[domain][service]
+        except KeyError:
+            # Almost all calls are already lower case, so we avoid
+            # calling lower() on the arguments in the common case.
+            domain = domain.lower()
+            service = service.lower()
+            try:
+                handler = self._services[domain][service]
+            except KeyError:
+                raise ServiceNotFound(domain, service) from None
+
+        if return_response:
+            if not blocking:
+                raise ValueError(
+                    "Invalid argument return_response=True when blocking=False"
+                )
+            if handler.supports_response == SupportsResponse.NONE:
+                raise ValueError(
+                    "Invalid argument return_response=True when handler does not support responses"
+                )
+        elif handler.supports_response == SupportsResponse.ONLY:
+            raise ValueError(
+                "Service call requires responses but caller did not ask for responses"
+            )
+
+        if target:
+            service_data.update(target)
+
+        if handler.schema:
+            try:
+                processed_data: dict[str, Any] = handler.schema(service_data)
+            except vol.Invalid:
+                _LOGGER.debug(
+                    "Invalid data for service call %s.%s: %s",
+                    domain,
+                    service,
+                    service_data,
+                )
+                raise
+        else:
+            processed_data = service_data
+
+        service_call = ServiceCall(
+            domain, service, processed_data, context, return_response
+        )
+
+        #lqg tag
+        # 关键：获取服务调用的上下文和来源信息
+        target = target or {}
+        _LOGGER.warning("Logging Service Calling...")
+        # 核心逻辑：
+        # 1. 面板操作通常有user_id（用户触发）
+        # 2. 排除自动化相关的服务调用（如automation.*）
+        has_user = context.user_id is not None
+        is_automation_service = domain == "automation"  # 自动化服务直接排除
+        is_panel_source = has_user and not is_automation_service
+        #is_panel_source = not getattr(context, 'origin', None)
+        _LOGGER.warning("is panel source?")
+        _LOGGER.warning(is_panel_source)
+
+        if is_panel_source:
+            # 解析目标设备的 entity_id（从 target 或 service_data 中提取）
+            target_entities = target.get("entity_id") or service_data.get("entity_id")
+            # 处理单个设备或多个设备的情况
+            if isinstance(target_entities, list):
+                entity_ids = target_entities
+            else:
+                entity_ids = [target_entities] if target_entities else []
+
+            # 遍历所有目标设备，记录面板命令
+            for entity_id in entity_ids:
+                if not entity_id:
+                    continue  # 跳过无实体 ID 的情况（极少数）
+
+                # device_name = get_friendly_name(entity_id)
+                # command = f"{domain}.{service}"
+                # description = f"{command.replace('_', ' ').title()}"
+
+                # record_event(
+                #     event_type="Command",
+                #     device=device_name,
+                #     description=description,
+                #     context=context,
+                #     extra_attributes={
+                #         "command": command,
+                #         "target_device": entity_id,
+                #         "source": "panel",
+                #         "user_id": context.user_id  #
+                #     }
+                # )
+
+        self._hass.bus.async_fire(
+            EVENT_CALL_SERVICE,
+            {
+                ATTR_DOMAIN: domain,
+                ATTR_SERVICE: service,
+                ATTR_SERVICE_DATA: service_data,
+            },
+            context=context,
+        )
+
+        coro = self._execute_service(handler, service_call)
+        if not blocking:
+            self._hass.async_create_task(
+                self._run_service_call_catch_exceptions(coro, service_call),
+                f"service call background {service_call.domain}.{service_call.service}",
+            )
+            return None
+
+        response_data = await coro
+        if not return_response:
+            return None
+        if not isinstance(response_data, dict):
+            raise HomeAssistantError(
+                f"Service response data expected a dictionary, was {type(response_data)}"
+            )
+        return response_data
+
+    async def _run_service_call_catch_exceptions(
+        self,
+        coro_or_task: Coroutine[Any, Any, Any] | asyncio.Task[Any],
+        service_call: ServiceCall,
+    ) -> None:
+        """Run service call in background, catching and logging any exceptions."""
+        try:
+            await coro_or_task
+        except Unauthorized:
+            _LOGGER.warning(
+                "Unauthorized service called %s/%s",
+                service_call.domain,
+                service_call.service,
+            )
+        except asyncio.CancelledError:
+            _LOGGER.debug("Service was cancelled: %s", service_call)
+        except Exception:  # pylint: disable=broad-except
+            _LOGGER.exception("Error executing service: %s", service_call)
+
+    async def _execute_service(
+        self, handler: Service, service_call: ServiceCall
+    ) -> ServiceResponse:
+        """Execute a service."""
+        job = handler.job
+        target = job.target
+        if job.job_type == HassJobType.Coroutinefunction:
+            if TYPE_CHECKING:
+                target = cast(Callable[..., Coroutine[Any, Any, _R]], target)
+            return await target(service_call)
+        if job.job_type == HassJobType.Callback:
+            if TYPE_CHECKING:
+                target = cast(Callable[..., _R], target)
+            return target(service_call)
+        if TYPE_CHECKING:
+            target = cast(Callable[..., _R], target)
+        return await self._hass.async_add_executor_job(target, service_call)
+
+
+class Config:
+    """Configuration settings for Home Assistant."""
+
+    def __init__(self, hass: HomeAssistant, config_dir: str) -> None:
+        """Initialize a new config object."""
+        self.hass = hass
+
+        self._store = self._ConfigStore(self.hass)
+
+        self.latitude: float = 0
+        self.longitude: float = 0
+
+        self.elevation: int = 0
+        """Elevation (always in meters regardless of the unit system)."""
+
+        self.location_name: str = "Home"
+        self.time_zone: str = "UTC"
+        self.units: UnitSystem = METRIC_SYSTEM
+        self.internal_url: str | None = None
+        self.external_url: str | None = None
+        self.currency: str = "EUR"
+        self.country: str | None = None
+        self.language: str = "en"
+
+        self.config_source: ConfigSource = ConfigSource.DEFAULT
+
+        # If True, pip install is skipped for requirements on startup
+        self.skip_pip: bool = False
+
+        # List of packages to skip when installing requirements on startup
+        self.skip_pip_packages: list[str] = []
+
+        # List of loaded components
+        self.components: set[str] = set()
+
+        # API (HTTP) server configuration
+        self.api: ApiConfig | None = None
+
+        # Directory that holds the configuration
+        self.config_dir: str = config_dir
+
+        # List of allowed external dirs to access
+        self.allowlist_external_dirs: set[str] = set()
+
+        # List of allowed external URLs that integrations may use
+        self.allowlist_external_urls: set[str] = set()
+
+        # Dictionary of Media folders that integrations may use
+        self.media_dirs: dict[str, str] = {}
+
+        # If Home Assistant is running in recovery mode
+        self.recovery_mode: bool = False
+
+        # Use legacy template behavior
+        self.legacy_templates: bool = False
+
+        # If Home Assistant is running in safe mode
+        self.safe_mode: bool = False
+
+    def distance(self, lat: float, lon: float) -> float | None:
+        """Calculate distance from Home Assistant.
+
+        Async friendly.
+        """
+        return self.units.length(
+            location.distance(self.latitude, self.longitude, lat, lon),
+            UnitOfLength.METERS,
+        )
+
+    def path(self, *path: str) -> str:
+        """Generate path to the file within the configuration directory.
+
+        Async friendly.
+        """
+        return os.path.join(self.config_dir, *path)
+
+    def is_allowed_external_url(self, url: str) -> bool:
+        """Check if an external URL is allowed."""
+        parsed_url = f"{str(yarl.URL(url))}/"
+
+        return any(
+            allowed
+            for allowed in self.allowlist_external_urls
+            if parsed_url.startswith(allowed)
+        )
+
+    def is_allowed_path(self, path: str) -> bool:
+        """Check if the path is valid for access from outside.
+
+        This function does blocking I/O and should not be called from the event loop.
+        Use hass.async_add_executor_job to schedule it on the executor.
+        """
+        assert path is not None
+
+        thepath = pathlib.Path(path)
+        try:
+            # The file path does not have to exist (it's parent should)
+            if thepath.exists():
+                thepath = thepath.resolve()
+            else:
+                thepath = thepath.parent.resolve()
+        except (FileNotFoundError, RuntimeError, PermissionError):
+            return False
+
+        for allowed_path in self.allowlist_external_dirs:
+            try:
+                thepath.relative_to(allowed_path)
+                return True
+            except ValueError:
+                pass
+
+        return False
+
+    def as_dict(self) -> dict[str, Any]:
+        """Create a dictionary representation of the configuration.
+
+        Async friendly.
+        """
+        return {
+            "latitude": self.latitude,
+            "longitude": self.longitude,
+            "elevation": self.elevation,
+            "unit_system": self.units.as_dict(),
+            "location_name": self.location_name,
+            "time_zone": self.time_zone,
+            "components": self.components,
+            "config_dir": self.config_dir,
+            # legacy, backwards compat
+            "whitelist_external_dirs": self.allowlist_external_dirs,
+            "allowlist_external_dirs": self.allowlist_external_dirs,
+            "allowlist_external_urls": self.allowlist_external_urls,
+            "version": __version__,
+            "config_source": self.config_source,
+            "recovery_mode": self.recovery_mode,
+            "state": self.hass.state.value,
+            "external_url": self.external_url,
+            "internal_url": self.internal_url,
+            "currency": self.currency,
+            "country": self.country,
+            "language": self.language,
+            "safe_mode": self.safe_mode,
+        }
+
+    def set_time_zone(self, time_zone_str: str) -> None:
+        """Help to set the time zone."""
+        if time_zone := dt_util.get_time_zone(time_zone_str):
+            self.time_zone = time_zone_str
+            dt_util.set_default_time_zone(time_zone)
+        else:
+            raise ValueError(f"Received invalid time zone {time_zone_str}")
+
+    @callback
+    def _update(
+        self,
+        *,
+        source: ConfigSource,
+        latitude: float | None = None,
+        longitude: float | None = None,
+        elevation: int | None = None,
+        unit_system: str | None = None,
+        location_name: str | None = None,
+        time_zone: str | None = None,
+        # pylint: disable=dangerous-default-value # _UNDEFs not modified
+        external_url: str | dict[Any, Any] | None = _UNDEF,
+        internal_url: str | dict[Any, Any] | None = _UNDEF,
+        currency: str | None = None,
+        country: str | dict[Any, Any] | None = _UNDEF,
+        language: str | None = None,
+    ) -> None:
+        """Update the configuration from a dictionary."""
+        self.config_source = source
+        if latitude is not None:
+            self.latitude = latitude
+        if longitude is not None:
+            self.longitude = longitude
+        if elevation is not None:
+            self.elevation = elevation
+        if unit_system is not None:
+            try:
+                self.units = get_unit_system(unit_system)
+            except ValueError:
+                self.units = METRIC_SYSTEM
+        if location_name is not None:
+            self.location_name = location_name
+        if time_zone is not None:
+            self.set_time_zone(time_zone)
+        if external_url is not _UNDEF:
+            self.external_url = cast(str | None, external_url)
+        if internal_url is not _UNDEF:
+            self.internal_url = cast(str | None, internal_url)
+        if currency is not None:
+            self.currency = currency
+        if country is not _UNDEF:
+            self.country = cast(str | None, country)
+        if language is not None:
+            self.language = language
+
+    async def async_update(self, **kwargs: Any) -> None:
+        """Update the configuration from a dictionary."""
+        # pylint: disable-next=import-outside-toplevel
+        from .config import (
+            _raise_issue_if_historic_currency,
+            _raise_issue_if_no_country,
+        )
+
+        self._update(source=ConfigSource.STORAGE, **kwargs)
+        await self._async_store()
+        self.hass.bus.async_fire(EVENT_CORE_CONFIG_UPDATE, kwargs)
+
+        _raise_issue_if_historic_currency(self.hass, self.currency)
+        _raise_issue_if_no_country(self.hass, self.country)
+
+    async def async_load(self) -> None:
+        """Load [homeassistant] core config."""
+        if not (data := await self._store.async_load()):
+            return
+
+        # In 2021.9 we fixed validation to disallow a path (because that's never
+        # correct) but this data still lives in storage, so we print a warning.
+        if data.get("external_url") and urlparse(data["external_url"]).path not in (
+            "",
+            "/",
+        ):
+            _LOGGER.warning("Invalid external_url set. It's not allowed to have a path")
+
+        if data.get("internal_url") and urlparse(data["internal_url"]).path not in (
+            "",
+            "/",
+        ):
+            _LOGGER.warning("Invalid internal_url set. It's not allowed to have a path")
+
+        self._update(
+            source=ConfigSource.STORAGE,
+            latitude=data.get("latitude"),
+            longitude=data.get("longitude"),
+            elevation=data.get("elevation"),
+            unit_system=data.get("unit_system_v2"),
+            location_name=data.get("location_name"),
+            time_zone=data.get("time_zone"),
+            external_url=data.get("external_url", _UNDEF),
+            internal_url=data.get("internal_url", _UNDEF),
+            currency=data.get("currency"),
+            country=data.get("country"),
+            language=data.get("language"),
+        )
+
+    async def _async_store(self) -> None:
+        """Store [homeassistant] core config."""
+        data = {
+            "latitude": self.latitude,
+            "longitude": self.longitude,
+            "elevation": self.elevation,
+            # We don't want any integrations to use the name of the unit system
+            # so we are using the private attribute here
+            "unit_system_v2": self.units._name,  # pylint: disable=protected-access
+            "location_name": self.location_name,
+            "time_zone": self.time_zone,
+            "external_url": self.external_url,
+            "internal_url": self.internal_url,
+            "currency": self.currency,
+            "country": self.country,
+            "language": self.language,
+        }
+
+        await self._store.async_save(data)
+
+    # Circular dependency prevents us from generating the class at top level
+    # pylint: disable-next=import-outside-toplevel
+    from .helpers.storage import Store
+
+    class _ConfigStore(Store[dict[str, Any]]):
+        """Class to help storing Config data."""
+
+        def __init__(self, hass: HomeAssistant) -> None:
+            """Initialize storage class."""
+            super().__init__(
+                hass,
+                CORE_STORAGE_VERSION,
+                CORE_STORAGE_KEY,
+                private=True,
+                atomic_writes=True,
+                minor_version=CORE_STORAGE_MINOR_VERSION,
+            )
+            self._original_unit_system: str | None = None  # from old store 1.1
+
+        async def _async_migrate_func(
+            self,
+            old_major_version: int,
+            old_minor_version: int,
+            old_data: dict[str, Any],
+        ) -> dict[str, Any]:
+            """Migrate to the new version."""
+            data = old_data
+            if old_major_version == 1 and old_minor_version < 2:
+                # In 1.2, we remove support for "imperial", replaced by "us_customary"
+                # Using a new key to allow rollback
+                self._original_unit_system = data.get("unit_system")
+                data["unit_system_v2"] = self._original_unit_system
+                if data["unit_system_v2"] == _CONF_UNIT_SYSTEM_IMPERIAL:
+                    data["unit_system_v2"] = _CONF_UNIT_SYSTEM_US_CUSTOMARY
+            if old_major_version == 1 and old_minor_version < 3:
+                # In 1.3, we add the key "language", initialize it from the
+                # owner account.
+                data["language"] = "en"
+                try:
+                    owner = await self.hass.auth.async_get_owner()
+                    if owner is not None:
+                        # pylint: disable-next=import-outside-toplevel
+                        from .components.frontend import storage as frontend_store
+
+                        # pylint: disable-next=import-outside-toplevel
+                        from .helpers import config_validation as cv
+
+                        _, owner_data = await frontend_store.async_user_store(
+                            self.hass, owner.id
+                        )
+
+                        if (
+                            "language" in owner_data
+                            and "language" in owner_data["language"]
+                        ):
+                            with suppress(vol.InInvalid):
+                                data["language"] = cv.language(
+                                    owner_data["language"]["language"]
+                                )
+                # pylint: disable-next=broad-except
+                except Exception:
+                    _LOGGER.exception("Unexpected error during core config migration")
+
+            if old_major_version > 1:
+                raise NotImplementedError
+            return data
+
+        async def async_save(self, data: dict[str, Any]) -> None:
+            if self._original_unit_system:
+                data["unit_system"] = self._original_unit_system
+            return await super().async_save(data)
+
+
+# These can be removed if no deprecated constant are in this module anymore
+__getattr__ = functools.partial(check_if_deprecated_constant, module_globals=globals())
+__dir__ = functools.partial(
+    dir_with_deprecated_constants, module_globals_keys=[*globals().keys()]
+)
+__all__ = all_with_deprecated_constants(globals())
diff -urN -x __pycache__ -x '*.pyc' /tmp/homeassistant-2024.1.5/homeassistant/helpers/condition.py /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/helpers/condition.py
--- /tmp/homeassistant-2024.1.5/homeassistant/helpers/condition.py	2024-01-21 04:41:26.000000000 +0800
+++ /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/helpers/condition.py	2026-02-12 18:23:52.359961602 +0800
@@ -1,6 +1,19 @@
 """Offer reusable conditions."""
 from __future__ import annotations
 
+#lqg tag
+"""
+from homeassistant.helpers.provenance import(
+    conditionTrack,
+    createEntity,
+    createActivity
+)"""
+from homeassistant.helpers.provenance import log_condition
+from homeassistant.util.dt import parse_datetime
+
+import logging
+_LOGGER = logging.getLogger(__name__)
+
 import asyncio
 from collections import deque
 from collections.abc import Callable, Container, Generator
@@ -207,6 +220,8 @@
 async def async_from_config(
     hass: HomeAssistant,
     config: ConfigType,
+    automation_id: str | None = None,  # 新增参数
+    context: Context | None = None     # 新增参数
 ) -> ConditionCheckerType:
     """Turn a condition configuration into a method.
 
@@ -373,120 +388,203 @@
     """Test a numeric state condition."""
     if entity is None:
         raise ConditionErrorMessage("numeric_state", "no entity specified")
+    #lqg tag
+    # ===== 调试信息：开始数值条件检查 =====
+    _LOGGER.warning("[数值状态条件] 开始检查...")
+    automation_name = "unknown_automation"
+    entity_id = ""
+    context = None
+    check_result = False  # 默认为False，后续会更新
+    condition_desc = "check numeric State"
+    fvalue = None  # 初始化数值变量
 
-    if isinstance(entity, str):
-        entity_id = entity
-
-        if (entity := hass.states.get(entity)) is None:
-            raise ConditionErrorMessage("numeric_state", f"unknown entity {entity_id}")
-    else:
-        entity_id = entity.entity_id
+    try:
+        # 获取自动化名称（增强容错）
+        if variables and "this" in variables:
+            automation_name = variables["this"].get("entity_id", "unknown_automation")
+        _LOGGER.warning(f"[数值状态条件] 自动化名称: {automation_name}")
+
+        # 统一赋值 entity_state
+        if isinstance(entity, str):
+            entity_id = entity
+            entity_state = hass.states.get(entity_id)
+            if entity_state is None:
+                raise ConditionErrorMessage(
+                    "numeric_state", f"unknown entity {entity_id}")
+        else:
+            entity_id = entity.entity_id
+            entity_state = entity
 
-    if attribute is not None and attribute not in entity.attributes:
-        condition_trace_set_result(
-            False,
-            message=f"attribute '{attribute}' of entity {entity_id} does not exist",
-        )
-        return False
+        context = entity_state.context
+        _LOGGER.warning(f"[数值状态条件] 检查实体: {entity_id}，当前状态: {entity_state.state}，上下文ID: {context.id}")
+        # 构建条件描述（如 "check numeric State >20 <30"）
+        
+        if above is not None:
+            condition_desc += f" > {above}"
+        if below is not None:
+            condition_desc += f" < {below}"
+        if attribute:
+            condition_desc += f" (属性: {attribute})"
+        _LOGGER.warning(f"[数值状态条件] 检查条件: {condition_desc}")
+
+        # ===== 原有数值检查逻辑 =====
+        if attribute is not None and attribute not in entity_state.attributes:
+            condition_trace_set_result(
+                False,
+                message=f"attribute '{attribute}' of entity {entity_id} does not exist",
+            )
+            return False
 
-    value: Any = None
-    if value_template is None:
-        if attribute is None:
-            value = entity.state
+        value: Any = None
+        if value_template is None:
+            if attribute is None:
+                value = entity_state.state
+            else:
+                value = entity_state.attributes.get(attribute)
         else:
-            value = entity.attributes.get(attribute)
-    else:
-        variables = dict(variables or {})
-        variables["state"] = entity
+            variables = dict(variables or {})
+            variables["state"] = entity
+            try:
+                value = value_template.async_render(variables)
+            except TemplateError as ex:
+                raise ConditionErrorMessage(
+                    "numeric_state", f"template error: {ex}"
+                ) from ex
+
+        # Known states or attribute values that never match the numeric condition
+        if value in (None, STATE_UNAVAILABLE, STATE_UNKNOWN):
+            condition_desc += f" | 失败原因: 实体状态不可用或未知 ({value})"
+            check_result = False # 确保 finally 块能记录到 False
+            condition_trace_set_result(
+                False,
+                message=f"value '{value}' is non-numeric and treated as False",
+            )
+            return False
+
         try:
-            value = value_template.async_render(variables)
-        except TemplateError as ex:
+            fvalue = float(value)
+        except (ValueError, TypeError) as ex:
+            # 这里也可以加一条记录
+            condition_desc += f" | 失败原因: 无法转换为数字 ({value})"
+            check_result = False
             raise ConditionErrorMessage(
-                "numeric_state", f"template error: {ex}"
+                "numeric_state",
+                f"entity {entity_id} state '{value}' cannot be processed as a number",
             ) from ex
 
-    # Known states or attribute values that never match the numeric condition
-    if value in (None, STATE_UNAVAILABLE, STATE_UNKNOWN):
-        condition_trace_set_result(
-            False,
-            message=f"value '{value}' is non-numeric and treated as False",
-        )
-        return False
-
-    try:
-        fvalue = float(value)
-    except (ValueError, TypeError) as ex:
-        raise ConditionErrorMessage(
-            "numeric_state",
-            f"entity {entity_id} state '{value}' cannot be processed as a number",
-        ) from ex
-
-    if below is not None:
-        if isinstance(below, str):
-            if not (below_entity := hass.states.get(below)):
-                raise ConditionErrorMessage(
-                    "numeric_state", f"unknown 'below' entity {below}"
-                )
-            if below_entity.state in (
-                STATE_UNAVAILABLE,
-                STATE_UNKNOWN,
-            ):
-                return False
-            try:
-                if fvalue >= float(below_entity.state):
-                    condition_trace_set_result(
-                        False,
-                        state=fvalue,
-                        wanted_state_below=float(below_entity.state),
+        if below is not None:
+            if isinstance(below, str):
+                if not (below_entity := hass.states.get(below)):
+                    raise ConditionErrorMessage(
+                        "numeric_state", f"unknown 'below' entity {below}"
                     )
+                if below_entity.state in (
+                    STATE_UNAVAILABLE,
+                    STATE_UNKNOWN,
+                ):
                     return False
-            except (ValueError, TypeError) as ex:
-                raise ConditionErrorMessage(
-                    "numeric_state",
-                    (
-                        f"the 'below' entity {below} state '{below_entity.state}'"
-                        " cannot be processed as a number"
-                    ),
-                ) from ex
-        elif fvalue >= below:
-            condition_trace_set_result(False, state=fvalue, wanted_state_below=below)
-            return False
-
-    if above is not None:
-        if isinstance(above, str):
-            if not (above_entity := hass.states.get(above)):
-                raise ConditionErrorMessage(
-                    "numeric_state", f"unknown 'above' entity {above}"
-                )
-            if above_entity.state in (
-                STATE_UNAVAILABLE,
-                STATE_UNKNOWN,
-            ):
+                try:
+                    if fvalue >= float(below_entity.state):
+                        _LOGGER.warning(f"[数值状态条件] 不满足below: {fvalue} >= {below_entity.state}")
+                        condition_trace_set_result(
+                            False,
+                            state=fvalue,
+                            wanted_state_below=float(below_entity.state),
+                        )
+                        #new added 
+                        check_result = False
+                        return False
+                except (ValueError, TypeError) as ex:
+                    raise ConditionErrorMessage(
+                        "numeric_state",
+                        (
+                            f"the 'below' entity {below} state '{below_entity.state}'"
+                            " cannot be processed as a number"
+                        ),
+                    ) from ex
+            elif fvalue >= below:
+                # 动态增加失败原因，这样 provenance 的 JSON 里会记录具体为什么没过
+                condition_desc += f" (实际值 {fvalue} 不小于阈值 {below})" 
+                condition_trace_set_result(False, state=fvalue, wanted_state_below=below)
+                _LOGGER.warning(f"[数值状态条件] 不满足below: {fvalue} >= {below}")
+                check_result = False
                 return False
-            try:
-                if fvalue <= float(above_entity.state):
-                    condition_trace_set_result(
-                        False,
-                        state=fvalue,
-                        wanted_state_above=float(above_entity.state),
+
+        if above is not None:
+            if isinstance(above, str):
+                if not (above_entity := hass.states.get(above)):
+                    raise ConditionErrorMessage(
+                        "numeric_state", f"unknown 'above' entity {above}"
                     )
+                if above_entity.state in (
+                    STATE_UNAVAILABLE,
+                    STATE_UNKNOWN,
+                ):
                     return False
-            except (ValueError, TypeError) as ex:
-                raise ConditionErrorMessage(
-                    "numeric_state",
-                    (
-                        f"the 'above' entity {above} state '{above_entity.state}'"
-                        " cannot be processed as a number"
-                    ),
-                ) from ex
-        elif fvalue <= above:
-            condition_trace_set_result(False, state=fvalue, wanted_state_above=above)
-            return False
-
-    condition_trace_set_result(True, state=fvalue)
-    return True
-
+                try:
+                    if fvalue <= float(above_entity.state):
+                        condition_trace_set_result(
+                            False,
+                            state=fvalue,
+                            wanted_state_above=float(above_entity.state),
+                        )
+                        _LOGGER.warning(f"[数值状态条件] 不满足above: {fvalue} <= {above_entity.state}")
+                        check_result = False
+                        return False
+                except (ValueError, TypeError) as ex:
+                    raise ConditionErrorMessage(
+                        "numeric_state",
+                        (
+                            f"the 'above' entity {above} state '{above_entity.state}'"
+                            " cannot be processed as a number"
+                        ),
+                    ) from ex
+            elif fvalue <= above:
+                _LOGGER.warning(f"[数值状态条件] 不满足above: {fvalue} <= {above}")
+                check_result = False
+                condition_trace_set_result(False, state=fvalue, wanted_state_above=above)
+                return False
+        
+        #new_added_ 所有条件满足
+        check_result = True
+        _LOGGER.warning(f"[数值状态条件] 检查通过: {fvalue} 满足 {condition_desc}")
 
+        condition_trace_set_result(True, state=fvalue)
+        return True
+   
+    except Exception as e:
+        _LOGGER.error(f"[数值状态条件] 执行异常: {str(e)}", exc_info=True)
+        raise
+    
+    finally:
+        # 1. 纠正变量冲突：使用 value 或 fvalue，严禁使用 check_value
+        current_val = str(fvalue) if 'fvalue' in locals() and fvalue is not None else str(value) if 'value' in locals() else "unknown"
+        
+        # 2. 强制提取 Context：Agent 事件依赖 context.id 建立溯源链
+        # 如果 context 为空，尝试从 variables 提取
+        safe_context = context
+        if not safe_context and variables:
+            safe_context = variables.get("trigger", {}).get("context")
+
+        # 3. 确定 Automation ID：这是关联 Agent 事件的“钥匙”
+        # 如果 automation_id 为空，尝试从 this 实体中提取
+        final_automation_id = locals().get('automation_id')
+        if not final_automation_id and variables and "this" in variables:
+            final_automation_id = variables["this"].get("entity_id")
+
+        # 4. 调用 log_condition (它内部会调用 log_agent_event)
+        if final_automation_id:
+            log_condition(
+                automation_name=automation_name if 'automation_name' in locals() else final_automation_id,
+                entity_id=entity_id if 'entity_id' in locals() else "unknown_sensor",
+                condition_desc=condition_desc if 'condition_desc' in locals() else "Condition Check",
+                result=check_result if 'check_result' in locals() else False,
+                context=safe_context,
+                condition_state=current_val,
+                automation_id=final_automation_id,
+                variables=variables
+            )
+        
 def async_numeric_state_from_config(config: ConfigType) -> ConditionCheckerType:
     """Wrap action method with state based condition."""
     entity_ids = config.get(CONF_ENTITY_ID, [])
@@ -533,6 +631,8 @@
     return if_numeric_state
 
 
+
+#new added here
 def state(
     hass: HomeAssistant,
     entity: None | str | State,
@@ -545,67 +645,180 @@
 
     Async friendly.
     """
-    if entity is None:
-        raise ConditionErrorMessage("state", "no entity specified")
-
-    if isinstance(entity, str):
-        entity_id = entity
-
-        if (entity := hass.states.get(entity)) is None:
-            raise ConditionErrorMessage("state", f"unknown entity {entity_id}")
-    else:
-        entity_id = entity.entity_id
-
-    if attribute is not None and attribute not in entity.attributes:
-        condition_trace_set_result(
-            False,
-            message=f"attribute '{attribute}' of entity {entity_id} does not exist",
-        )
-        return False
+    """Test if state matches requirements."""
+    _LOGGER.warning("[状态匹配条件] 开始检查...")
+    automation_name = "unknown_automation"
+    entity_id = ""
+    context = None
+    check_value = None
+    check_result = False  # 默认为False，后续更新
+    condition_desc = ""
 
-    assert isinstance(entity, State)
+    try:
+        if entity is None:
+            raise ConditionErrorMessage("state", "no entity specified")
 
-    if attribute is None:
-        value: Any = entity.state
-    else:
-        value = entity.attributes.get(attribute)
+        _LOGGER.warning(variables)
+        # 获取自动化名称
+        if variables and "this" in variables:
+            automation_name = variables["this"].get("entity_id", "unknown_automation")
+        _LOGGER.warning(f"[状态匹配条件] 自动化名称: {automation_name}")
+
+        #lqg added
+        #automation_name = variables["this"]["entity_id"] if variables and "this" in variables else "unknown_automation"
+        if isinstance(entity, str):
+            entity_id = entity
+            # 字符串类型：通过实体ID获取State对象，赋值给entity_state
+            entity_state = hass.states.get(entity_id)
+            if entity_state is None:
+                raise ConditionErrorMessage("state", f"unknown entity {entity_id}")
+        else:
+            # 非字符串类型（已是State对象）：直接赋值
+            entity_id = entity.entity_id
+            entity_state = entity
+
+
+        # 提取上下文
+        context = entity_state.context
+        _LOGGER.warning(f"[状态匹配条件] 检查实体: {entity_id}，当前状态: {entity_state.state}，上下文ID: {context.id}")
+
+         # 处理属性
+        check_value = entity_state.state if attribute is None else entity_state.attributes.get(attribute)
+        attr_desc = f"（属性: {attribute}）" if attribute else ""
+        _LOGGER.warning(f"[状态匹配条件] 检查值{attr_desc}: {check_value}")
+
+
+        if attribute is not None and attribute not in entity.attributes:
+            condition_trace_set_result(
+                False,
+                message=f"attribute '{attribute}' of entity {entity_id} does not exist",
+            )
+            return False
 
-    if not isinstance(req_state, list):
-        req_state = [req_state]
+        assert isinstance(entity_state, State)
 
-    is_state = False
-    for req_state_value in req_state:
-        state_value = req_state_value
-        if (
-            isinstance(req_state_value, str)
-            and INPUT_ENTITY_ID.match(req_state_value) is not None
-        ):
-            if not (state_entity := hass.states.get(req_state_value)):
-                raise ConditionErrorMessage(
-                    "state", f"the 'state' entity {req_state_value} is unavailable"
-                )
-            state_value = state_entity.state
-        is_state = value == state_value
-        if is_state:
-            break
-
-    if for_period is None or not is_state:
-        condition_trace_set_result(is_state, state=value, wanted_state=state_value)
-        return is_state
 
-    try:
-        for_period = cv.positive_time_period(render_complex(for_period, variables))
-    except TemplateError as ex:
-        raise ConditionErrorMessage("state", f"template error: {ex}") from ex
-    except vol.Invalid as ex:
-        raise ConditionErrorMessage("state", f"schema error: {ex}") from ex
-
-    duration = dt_util.utcnow() - cast(timedelta, for_period)
-    duration_ok = duration > entity.last_changed
-    condition_trace_set_result(duration_ok, state=value, duration=duration)
-    return duration_ok
+        #if attribute is None:
+        #    value: Any = entity.state
+        #else:
+        #    value = entity.attributes.get(attribute)
+
+        #if not isinstance(req_state, list):
+        #    req_state = [req_state]
+
+        """
+        2025-06-20 23:34:35.709 WARNING (MainThread) [homeassistant.helpers.condition] check state
+        2025-06-20 23:34:35.709 WARNING (MainThread) [homeassistant.helpers.condition] ['off']
+        2025-06-20 23:34:35.709 WARNING (MainThread) [homeassistant.helpers.condition] light.lumi_v3_6063_light_3
+        2025-06-20 23:34:35.709 WARNING (MainThread) [homeassistant.helpers.condition] <state light.lumi_v3_6063_light_3=on; supported_color_modes=[<ColorMode.ONOFF: 'onoff'>], color_mode=onoff, light.on=False, friendly_name=网关 Light, supported_features=0 @ 2025-06-20T23:34:33.885485+08:00>
+        """
+        #condition function name
+        #check_function_name = "Check" + " "+ entity_id + "=="+ " "+ req_state[0] + '?'
+        #check_state = entity.as_dict()['state']
+        #check_timestamp = parse_datetime(entity.as_dict()['last_updated']).isoformat()
+
+        #check_state_node = f"{entity_id}@{check_state}@{check_timestamp}"
+
+        #check_state_entity= createEntity("State", check_state_node)
+        #contextid = entity.as_dict()['context']['id']
+
+        #createActivity("Function", check_state, " ")
+        """
+        {'entity_id': 'light.lumi_v3_6063_light_3', 'state': 'on', 'attributes': {'supported_color_modes': [<ColorMode.ONOFF: 'onoff'>], 'color_mode': <ColorMode.ONOFF: 'onoff'>, 'light.on': True, 'friendly_name': '网关 Light', 'supported_features': <LightEntityFeature: 0>}, 'last_changed': '2025-06-20T15:45:48.108248+00:00', 'last_updated': '2025-06-20T15:45:48.108248+00:00', 'context': {'id': '01JY708Z2CK2SY0P857SQNNR73', 'parent_id': None, 'user_id': None}}
+        """
+        #lqg
+        #check_state_node = f"{entity_id}:{req_state[0]}@#{entity_state['last_updated'].isoformat()}"
+        #    condition_activity = f"check state #{req_state}"
+        #_LOGGER.warning(req_state)
+
+
+        # 处理期望状态
+        req_states = req_state if isinstance(req_state, list) else [req_state]
+        resolved_states = []
+        for req in req_states:
+            if isinstance(req, str) and INPUT_ENTITY_ID.match(req):
+                ref_entity = hass.states.get(req)
+                resolved = ref_entity.state if ref_entity else "unknown"
+                resolved_states.append(resolved)
+                _LOGGER.warning(f"[状态匹配条件] 解析引用实体 {req} -> 状态: {resolved}")
+            else:
+                resolved_states.append(req)
+        condition_desc = f"check state {attr_desc} in {resolved_states}"
+        _LOGGER.warning(f"[状态匹配条件] 检查条件: {condition_desc}")
+        
+        # 状态匹配检查
+        is_state = check_value in resolved_states
+        _LOGGER.warning(f"[状态匹配条件] 状态匹配结果: {is_state}（当前值: {check_value}，期望: {resolved_states}）")
+
+        # 状态匹配检查
+        """
+        is_state = False
+        for req_state_value in req_state:
+            state_value = req_state_value
+            if (
+                isinstance(req_state_value, str)
+                and INPUT_ENTITY_ID.match(req_state_value) is not None
+            ):
+                if not (state_entity := hass.states.get(req_state_value)):
+                    raise ConditionErrorMessage(
+                        "state", f"the 'state' entity {req_state_value} is unavailable"
+                    )
+                state_value = state_entity.state
+            is_state = value == state_value
+            if is_state:
+                break
 
+        """
+        #lqg add
+        #conditionTrack(automation_name, contextid, entity_id, check_function_name, #check_state_node, is_state)
 
+        # 持续时间检查
+        if for_period is not None and is_state:
+            try:
+                for_period = cv.positive_time_period(render_complex(for_period, variables))
+                duration_ok = (dt_util.utcnow() - for_period) > entity_state.last_changed
+                _LOGGER.debug(f"[状态匹配条件] 持续时间检查: {for_period} -> {'通过' if duration_ok else '未通过'}")
+                check_result = duration_ok
+            except (TemplateError, vol.Invalid) as ex:
+                _LOGGER.error(f"[状态匹配条件] 持续时间解析失败: {ex}")
+                raise ConditionErrorMessage("state", f"invalid 'for' period: {ex}") from ex
+        else:
+            check_result = is_state
+            
+        condition_trace_set_result(check_result, state=check_value, wanted_state=resolved_states)
+        return check_result
+    
+    except Exception as e:
+        _LOGGER.error(f"[状态匹配条件] 执行异常: {str(e)}", exc_info=True)
+        raise
+    finally:
+        # 1. 确保 variables 不是 None，防止报错
+        safe_vars = variables or {}
+        
+        # 2. 尝试从多种渠道提取 automation_id (这是 provenance.py 状态机的钥匙)
+        # 优先从 this 提取，其次从 trigger 提取
+        final_automation_id = None
+        if "this" in safe_vars:
+            final_automation_id = safe_vars["this"].get("entity_id")
+        if not final_automation_id and "trigger" in safe_vars:
+            final_automation_id = safe_vars.get("automation_id")
+
+        # 3. 确定上下文：优先使用自动化触发的上下文
+        trigger_context = safe_vars.get("trigger_context")
+        final_context = trigger_context or context
+
+        # 4. 严格按照你 provenance.py 里的 log_condition 签名传参
+        # 顺序：automation_name, entity_id, condition_desc, result, context, condition_state, automation_id
+        log_condition(
+            automation_name=automation_name,      # 自动化实体的友好名称或 ID
+            entity_id=entity_id,                  # 被检查的设备（如传感器）
+            condition_desc=condition_desc,        # “温度 > 25”
+            result=check_result,                  # 布尔值 True/False
+            context=final_context,                # 上下文用于追踪
+            condition_state=str(check_value) if check_value is not None else None,
+            automation_id=final_automation_id,     # 传给状态机做关联
+            variables=variables
+        )
 def state_from_config(config: ConfigType) -> ConditionCheckerType:
     """Wrap action method with state based condition."""
     entity_ids = config.get(CONF_ENTITY_ID, [])
@@ -783,8 +996,43 @@
     def template_if(hass: HomeAssistant, variables: TemplateVarsType = None) -> bool:
         """Validate template based if-condition."""
         value_template.hass = hass
+        
+        # 1. 初始化基础信息
+        safe_vars = variables if variables is not None else {}
+        automation_name = safe_vars.get("this", {}).get("attributes", {}).get("friendly_name") or \
+                          safe_vars.get("this", {}).get("entity_id", "unknown_automation")
+        
+        entity_id = "condition.template"
+        condition_desc = f"Template: {value_template.template[:50]}..." # 记录模板前50个字符方便识别
+        check_result = False
 
-        return async_template(hass, value_template, variables)
+        try:
+            check_result = async_template(hass, value_template, variables, trace_result=False)
+            return check_result
+        finally:
+            # 2. 竭尽全力获取 automation_id (状态机的 Key)
+            final_a_id = safe_vars.get("automation_id") or \
+                         safe_vars.get("this", {}).get("entity_id")
+            
+            # 3. 竭尽全力获取 Context (溯源链的 Key)
+            final_ctx = safe_vars.get("trigger", {}).get("context") or \
+                        safe_vars.get("trigger_context")
+            
+            # 如果依然没有 automation_id，尝试从 automation_name 降级获取
+            if not final_a_id and automation_name != "unknown_automation":
+                final_a_id = automation_name
+
+            if final_a_id:
+                _LOGGER.warning(f"[Provenance] 模板条件检查记录: {final_a_id} -> {check_result}")
+                log_condition(
+                    automation_name=automation_name,
+                    entity_id=entity_id,
+                    condition_desc=condition_desc,
+                    result=check_result,
+                    context=final_ctx,
+                    automation_id=final_a_id,
+                    variables=safe_vars
+                )
 
     return template_if
 
diff -urN -x __pycache__ -x '*.pyc' /tmp/homeassistant-2024.1.5/homeassistant/helpers/provenance-bk-20251223.py /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/helpers/provenance-bk-20251223.py
--- /tmp/homeassistant-2024.1.5/homeassistant/helpers/provenance-bk-20251223.py	1970-01-01 08:00:00.000000000 +0800
+++ /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/helpers/provenance-bk-20251223.py	2025-12-23 16:13:58.252795696 +0800
@@ -0,0 +1,615 @@
+from __future__ import annotations
+from contextvars import ContextVar
+from typing import Any, Dict, List, Optional, Tuple, Sequence
+import logging
+import json
+import os
+from datetime import datetime
+import uuid
+
+# 引入注册表以获取富语义信息
+from homeassistant.helpers import entity_registry as er
+from homeassistant.helpers import device_registry as dr
+from homeassistant.core import HomeAssistant
+
+_LOGGER = logging.getLogger(__name__)
+
+# 全局 HASS 引用，由 Core 启动时注入
+_HASS_REF: Optional[HomeAssistant] = None
+
+def set_global_hass(hass: HomeAssistant):
+    """注入HASS实例，用于查表"""
+    global _HASS_REF
+    _HASS_REF = hass
+    
+# 定义事件类型
+EVENT_TYPE_ENTITY = "Entity"
+EVENT_TYPE_COMMAND = "Command"
+EVENT_TYPE_AGENT = "Agent"
+
+# 全局事件存储
+event_log: List[Dict[str, Any]] = []
+event_id_counter = 1
+context_id_map: Dict[str, int] = {}  # context.id -> event_ID
+context_vars: ContextVar[Dict[str, Any]] = ContextVar(
+    "context_vars", default={}
+)
+
+
+# 状态机：跟踪自动化执行状态和条件关联
+class StateMachine:
+    def __init__(self):
+        # automation_id -> state (存储完整条件链和目标活动)
+        self.automation_states: Dict[str, Dict[str, Any]] = {}
+        self.automation_commands: Dict[str,
+                                       List[Dict[str, Any]]] = {}  # 自动化命令跟踪
+        self.automation_conditions: Dict[str, List[int]] = {}  # 存储所有条件事件ID
+
+    def start_automation(self, automation_id: str, trigger_event_id: int) -> None:
+        """记录自动化开始执行，初始化条件链"""
+        self.automation_states[automation_id] = {
+            "active": True,
+            "trigger_event_id": trigger_event_id,
+            "last_condition_id": None,
+            "condition_passed": True,
+            "current_step": "trigger",
+            "target_activity": None  # 最终触发的Command ID
+        }
+        self.automation_conditions[automation_id] = []  # 初始化条件ID列表
+
+    def record_condition(self, automation_id: str, condition_event_id: int, result: bool) -> None:
+        """记录条件检查结果，维护完整条件链"""
+        if automation_id not in self.automation_states:
+            _LOGGER.warning(
+                f"Automation {automation_id} not active when recording condition")
+            return
+
+        state = self.automation_states[automation_id]
+        state["last_condition_id"] = condition_event_id
+        state["condition_passed"] = state["condition_passed"] and result
+        state["current_step"] = "condition"
+        # 存储所有条件ID（无论是否通过）
+        self.automation_conditions[automation_id].append(condition_event_id)
+
+    def set_target_activity(self, automation_id: str, activity_id: int) -> None:
+        """记录自动化触发的目标Command ID"""
+        if automation_id in self.automation_states:
+            self.automation_states[automation_id]["target_activity"] = activity_id
+
+    def get_conditions(self, automation_id: str) -> List[int]:
+        """获取自动化的所有条件事件ID"""
+        return self.automation_conditions.get(automation_id, [])
+
+    def is_automation_active(self, automation_id: str) -> bool:
+        """检查自动化是否仍在活跃状态（条件未失败）"""
+        state = self.automation_states.get(automation_id, {})
+        return state.get("active", False) and state.get("condition_passed", False)
+
+    def is_automation_active_with_reason(self, automation_id: str) -> Tuple[bool, Optional[int]]:
+        """检查自动化是否活跃并返回阻塞原因ID"""
+        state = self.automation_states.get(automation_id, {})
+        is_active = state.get("active", False) and state.get(
+            "condition_passed", False)
+        return is_active, state.get("last_condition_id") if not is_active else None
+
+    def end_automation(self, automation_id: str) -> None:
+        """标记自动化执行结束"""
+        if automation_id in self.automation_states:
+            self.automation_states[automation_id]["active"] = False
+            self.automation_states[automation_id]["current_step"] = "completed"
+
+    def get_automation_context(self, automation_id: str) -> Optional[Dict[str, Any]]:
+        """获取自动化上下文信息"""
+        return self.automation_states.get(automation_id)
+
+    def track_commands(self, automation_id: str, sequence: Sequence[dict]) -> None:
+        """解析自动化的动作配置，提取目标设备和命令"""
+        parsed_commands = []
+        for action in sequence:
+            # 解析HomeAssistant动作配置中的核心信息：
+            # 示例动作配置：{"service": "light.turn_on", "target": {"entity_id": "light.lumi_v3_6063_light_3"}}
+            service = action.get("service")  # 命令类型（如"light.turn_on"）
+            target_entity = action.get("target", {}).get("entity_id")  # 目标设备ID
+            # 处理目标设备为列表的情况（取第一个）
+            if isinstance(target_entity, list):
+                target_entity = target_entity[0] if target_entity else None
+            if service and target_entity:
+                parsed_commands.append({
+                    "target_device": target_entity,  # 目标设备实体ID
+                    "command": service,  # 命令类型
+                    "description": f"Execute {service.split('.')[-1]}"  # 描述（如"turn_on"）
+                })
+        # 存储解析后的命令，关联到自动化ID
+        self.automation_commands[automation_id] = parsed_commands
+
+    
+    def get_blocked_commands(self, automation_id: str) -> List[Dict[str, Any]]:
+        """获取因条件失败而被阻止的命令"""
+        return self.automation_commands.get(automation_id, [])
+
+
+# 初始化状态机
+state_machine = StateMachine()
+
+
+def get_session_id() -> str:
+    """从上下文获取当前会话ID（支持多会话隔离）"""
+    vars = context_vars.get()
+    if "session_id" not in vars:
+        vars["session_id"] = str(uuid.uuid4())
+        context_vars.set(vars)
+    return vars["session_id"]
+
+
+def clear_log() -> None:
+    """清除事件日志并重置会话"""
+    global event_log, event_id_counter, context_id_map
+    event_log = []
+    event_id_counter = 1
+    context_id_map = {}
+    # 重置上下文变量（保留结构，清空内容）
+    vars = context_vars.get()
+    vars.clear()
+    context_vars.set(vars)
+    # 重置状态机
+    state_machine.automation_states.clear()
+    state_machine.automation_commands.clear()
+    state_machine.automation_conditions.clear()
+    _LOGGER.info("Event log cleared and new session started")
+
+
+
+# ========== 核心优化：富语义信息获取 ==========
+def get_rich_entity_info(entity_id: str) -> dict:
+    """获取实体名称、区域、型号等富语义信息，解决‘脏数据’问题"""
+    info = {
+        "friendly_name": entity_id.split('.')[-1].replace('_', ' ').title(),
+        "area_id": None,
+        "model": None,
+        "domain": entity_id.split('.')[0]
+    }
+    
+    if not _HASS_REF or not entity_id:
+        return info
+
+    try:
+        ent_reg = er.async_get(_HASS_REF)
+        dev_reg = dr.async_get(_HASS_REF)
+        
+        # 1. 查询 Entity Registry
+        entry = ent_reg.async_get(entity_id)
+        if entry:
+            if entry.name:
+                info["friendly_name"] = entry.name
+            elif entry.original_name:
+                info["friendly_name"] = entry.original_name
+            
+            # 2. 查询 Device Registry
+            if entry.device_id:
+                device = dev_reg.async_get(entry.device_id)
+                if device:
+                    info["model"] = device.model
+                    info["area_id"] = device.area_id # 之后可以进一步转为 area name
+    except Exception:
+        pass # 查表失败降级处理
+
+    # 3. 尝试从 State 获取 (运行时名称通常最准)
+    state = _HASS_REF.states.get(entity_id)
+    if state and "friendly_name" in state.attributes:
+        info["friendly_name"] = state.attributes["friendly_name"]
+
+    return info
+
+
+def record_event(
+    event_type: str,
+    device: str,
+    description: str,
+    context: Any,
+    action: Optional[str] = None,  # "triggered" 或 "condition_check"
+    condition: Optional[Dict[str, Any]] = None,
+    extra_attributes: Optional[Dict[str, Any]] = None,
+    # 三类事件特有字段（顶级参数）
+    entity_id: Optional[str] = None,  # Entity特有：实体唯一ID
+    target_activity: Optional[int] = None,  # Agent特有：触发的Command ID
+    forbidden_activity: Optional[int] = None,  # Agent特有：阻止的Command ID
+    condition_ids: Optional[List[int]] = None,  # Command特有：依赖的条件ID列表
+) -> int:
+    """记录事件的核心函数，支持三类事件特有字段和关联逻辑"""
+    global event_id_counter
+
+    if ("unknown" in description.lower()) or ("None" in description.lower()) or ("unavailable" in description.lower()):
+        _LOGGER.debug(f"过滤包含unknown的事件：{description}")
+        return -1  # 返回无效ID表示事件未被记录
+
+    # 1. 从上下文获取会话ID
+    current_session_id = get_session_id()
+
+    # 2. 解析source（优先显式传入，再 fallback 到上下文）
+    source = None
+    if extra_attributes and "source" in extra_attributes:
+        source = extra_attributes.pop("source")  # 提取显式source
+    else:
+        if context and context.parent_id:
+            source = context_id_map.get(context.parent_id)
+    
+    rich_info = {}
+    display_name = device
+    if entity_id:
+        rich_info = get_rich_entity_info(entity_id)
+        display_name = rich_info.get("friendly_name", device)
+    elif "." in device and "_" in device: # 猜测是 entity_id
+        rich_info = get_rich_entity_info(device)
+        display_name = rich_info.get("friendly_name", device)
+
+    # 4. 构建基础事件结构
+    event = {
+        "timestamp": datetime.now().strftime("%H:%M:%S.%f")[:-3],
+        "device": display_name, # 用户可见名称
+        "raw_device_id": entity_id or device, # 保留技术 ID
+        "event_type": event_type,
+        "description": description,
+        "source": source,
+        "event_ID": event_id_counter,
+        "session_id": current_session_id,
+        "action": action,
+        "context_id": context.id if context else None,
+        "parent_context_id": context.parent_id if context else None
+    }
+
+    if rich_info.get("area_id"):
+        event["area"] = rich_info["area_id"]
+
+    # 5. 添加事件类型特有字段（顶级字段）
+    if event_type == EVENT_TYPE_ENTITY and entity_id:
+        event["entity_id"] = entity_id
+        event["old_state"] = extra_attributes.pop(
+            "old_state", "") if extra_attributes else ""
+        event["new_state"] = extra_attributes.pop(
+            "new_state", "") if extra_attributes else ""
+
+    elif event_type == EVENT_TYPE_AGENT:
+        if target_activity is not None:
+            event["target_activity"] = target_activity
+        if forbidden_activity is not None:
+            event["forbidden_activity"] = forbidden_activity
+
+    elif event_type == EVENT_TYPE_COMMAND:
+        if condition_ids is not None:
+            event["condition_ids"] = condition_ids
+        event["command"] = extra_attributes.pop(
+            "command", "") if extra_attributes else ""
+        event["target_device"] = extra_attributes.pop(
+            "target_device", "") if extra_attributes else ""
+
+    # 6. 添加条件信息（如Agent的条件检查结果）
+    if condition is not None:
+        event.update(condition)
+    
+    # 7. 添加剩余额外属性
+    if extra_attributes:
+        event.update(extra_attributes)
+
+    # 8. 存储事件并更新映射
+    event_log.append(event)
+    if context and hasattr(context, 'id'):
+        context_id_map[context.id] = event_id_counter  # 上下文ID -> 事件ID
+
+    event_id_counter += 1
+    _LOGGER.debug(f"Recorded {event_type} event: {event}")
+    return event_id_counter - 1
+
+
+def save_log(file_path: str) -> None:
+    """保存事件日志到JSON文件"""
+    try:
+        os.makedirs(os.path.dirname(file_path), exist_ok=True)
+        with open(file_path, 'w') as f:
+            json.dump(event_log, f, indent=2, ensure_ascii=False)
+        _LOGGER.info(
+            f"Event log saved to {file_path} with {len(event_log)} events")
+    except Exception as e:
+        _LOGGER.error(f"Failed to save event log: {e}")
+
+
+# ========== 事件记录工具函数 ==========
+def log_agent_event(device: str, description: str, context: Any, condition: Optional[Dict[str, Any]] = None, extra_attributes: Optional[Dict[str, Any]] = None, automation_id: Optional[str] = None, target_activity: Optional[int] = None, forbidden_activity: Optional[int] = None, action: Optional[str] = None) -> int:
+    event_id = record_event(EVENT_TYPE_AGENT, device, description, context, action, condition, extra_attributes, target_activity=target_activity, forbidden_activity=forbidden_activity)
+    if condition and automation_id:
+        state_machine.record_condition(automation_id, event_id, condition.get("condition_result", False))
+        if not condition.get("condition_result", False):
+            if event_log and event_log[-1]["event_ID"] == event_id:
+                event_log[-1]["description"] = f"Condition failed: {description}. Stopping automation."
+            state_machine.end_automation(automation_id)
+    return event_id
+    
+def log_trigger(action: str, entity_id: str, state: str, automation_name: str, context: Any, automation_id: str, sequence: Optional[Sequence[dict]] = None, is_start_point: bool = True) -> int:
+    # 获取触发源 Entity 事件 ID（实现 Trigger 溯源）
+    vars = context_vars.get()
+    trigger_entity_id = vars.get(context.id, {}).get("entity_event_id")
+    
+    rich_name = automation_name
+    if _HASS_REF:
+        rich_info = get_rich_entity_info(automation_name) # 这里 automation_name 其实是 entity_id
+        rich_name = rich_info.get("friendly_name", automation_name)
+
+    agent_event_id = log_agent_event(
+        device=rich_name, # 使用富语义名称
+        description=f"Triggered by {entity_id} state change",
+        context=context,
+        automation_id=automation_id,
+        extra_attributes={"source": trigger_entity_id, "automation_entity_id": automation_name},
+        action="triggered"
+    )
+    state_machine.start_automation(automation_id, agent_event_id)
+    if sequence:
+        state_machine.track_commands(automation_id, sequence)
+    
+    # 记录触发源 Entity 事件 (如果这是链条起点)
+    if is_start_point:
+        rich_entity = get_rich_entity_info(entity_id)
+        entity_event_id = record_event(
+            event_type=EVENT_TYPE_ENTITY,
+            device=rich_entity.get("friendly_name", entity_id),
+            description=f"Trigger state: {state}",
+            context=context,
+            entity_id=entity_id,
+            extra_attributes={"old_state": "", "new_state": state}
+        )
+        vars[context.id] = {"automation": automation_name, "automation_id": automation_id, "trigger_event_id": agent_event_id, "entity_event_id": entity_event_id}
+        context_vars.set(vars)
+    return agent_event_id
+    
+
+def log_condition_check(
+    automation_name: str,
+    automation_id: str,
+    entity_id: str,
+    condition_desc: str,
+    result: bool,
+    context: Any,
+    condition_state: Optional[str] = None
+) -> None:
+    """记录条件检查事件（用于构建isConditionOf边）"""
+    try:
+        if not state_machine.is_automation_active(automation_id):
+            _LOGGER.debug(
+                f"Skipping condition check for inactive automation {automation_name}")
+            return
+
+        device_name = get_friendly_name(entity_id)
+        condition_info = f"{condition_desc} - {'Passed' if result else 'Failed'}"
+
+        # new+add: 获取同自动化Trigger的source（原始Entity事件ID）
+        vars = context_vars.get()
+        automation_context = vars.get(context.parent_id, {})
+        trigger_source = automation_context.get("entity_event_id")  # 共享Trigger的source
+
+        # 构建条件数据（包含关联的触发事件）
+        condition_data = {
+            "condition_result": result,
+            "condition_entity": device_name,
+            "condition_entity_id": entity_id,
+            "condition_ID": event_id_counter,
+            "condition_state": condition_state,
+            "related_trigger_id": state_machine.get_automation_context(automation_id).get("trigger_event_id")
+        }
+
+        # 记录Agent条件事件
+        condition_event_id = log_agent_event(
+            device=automation_name,
+            description=condition_info,
+            context=context,
+            condition=condition_data,
+            automation_id=automation_id,
+            extra_attributes={
+                "source": trigger_source  # 核心：与Trigger共享同一个source
+            },
+            action="condition_check"
+        )
+
+        # 条件失败时记录被阻止的命令（构建Forbid边）
+        if not result:
+            log_blocked_commands(automation_id, context, condition_event_id)
+
+    except Exception as e:
+        _LOGGER.error(f"Error in log_condition_check: {e}")
+
+
+def log_condition(
+    automation_name: str,
+    entity_id: str,
+    condition_desc: str,
+    result: bool,
+    context: Any,
+    condition_state: Optional[str] = None,
+    automation_id: Optional[str] = None
+) -> None:
+    """对接HomeAssistant条件检查逻辑的事件记录"""
+    try:
+        # 新增：从 variables 强制提取自动化名称，覆盖原 automation_name
+        vars = context_vars.get()
+        if variables and "this" in variables:
+            automation_name = variables["this"].get("entity_id", automation_name)
+        elif variables and "trigger" in variables:
+            automation_name = variables["trigger"].get("automation_id", automation_name)
+
+        # 自动解析自动化ID（增强容错）
+        final_automation_id = automation_id
+        if not final_automation_id and hasattr(context, 'parent_id'):
+            vars = context_vars.get()
+            final_automation_id = vars.get(
+                context.parent_id, {}).get("automation_id")
+        if not final_automation_id and automation_name.startswith("automation."):
+            final_automation_id = automation_name
+
+        if final_automation_id:
+            log_condition_check(
+                automation_name=automation_name,
+                automation_id=final_automation_id,
+                entity_id=entity_id,
+                condition_desc=condition_desc,
+                result=result,
+                context=context,
+                condition_state=condition_state
+            )
+        else:
+            _LOGGER.warning(
+                f"Cannot determine automation ID for condition: {condition_desc}")
+
+    except Exception as e:
+        _LOGGER.error(f"Error in log_condition: {e}")
+
+
+def log_blocked_commands(
+    automation_id: str,
+    context: Any,
+    source_agent_id: int  # 条件检查事件的ID（作为来源）
+) -> None:
+    """记录被条件阻止的命令"""
+    # 从状态机获取该自动化的所有预设命令
+    blocked_commands = state_machine.automation_commands.get(automation_id, [])
+    if not blocked_commands:
+        _LOGGER.debug(f"Automation {automation_id} has no commands to block")
+        return
+
+    # 为每个被阻止的命令生成事件
+    for cmd in blocked_commands:
+        # 调用record_event记录被阻止的命令
+        record_event(
+            event_type=EVENT_TYPE_COMMAND,
+            device=cmd["target_device"],  # 目标设备ID
+            # 描述（如"Blocked: turn_on"）
+            description=f"Blocked: {cmd['description']}",
+            context=context,
+            condition_ids=state_machine.get_conditions(
+                automation_id),  # 关联所有条件ID
+            extra_attributes={
+                "command": cmd["command"],  # 被阻止的命令（如"light.turn_on"）
+                "target_device": cmd["target_device"],  # 目标设备
+                "status": "blocked",  # 标记为“被阻止”
+                "source": source_agent_id  # 关联条件检查事件ID
+            }
+        )
+
+def log_state_change(
+    entity_id: str,
+    new_state: str,
+    old_state: str,
+    context: Any,
+    source_activity_id: Optional[int] = None  # 触发该状态变化的Activity事件ID
+) -> None:
+    """记录实体状态变化（构建Derive/Generate边）"""
+    try:
+        device_name = get_friendly_name(entity_id)
+        description = f"{old_state} → {new_state}" if old_state else f"Initialized to {new_state}"
+
+        # 自动获取source_activity_id（如果未手动传入）
+        if source_activity_id is None and context:
+            # 1. 从上下文的parent_id找到触发源头的context.id
+            # 实体状态变化的parent_id通常指向触发它的命令/活动的context.id
+            source_context_id = getattr(context, 'parent_id', None)
+            
+            if not source_context_id:
+                # 特殊情况：直接使用当前上下文ID（如面板操作）
+                source_context_id = getattr(context, 'id', None)
+            
+            # 2. 通过context_id_map将context.id转换为事件ID（即source_activity_id）
+            if source_context_id:
+                source_activity_id = context_id_map.get(source_context_id)
+
+        record_event(
+            event_type=EVENT_TYPE_ENTITY,
+            device=device_name,
+            description=description,
+            context=context,
+            entity_id=entity_id,
+            extra_attributes={
+                "old_state": old_state,
+                "new_state": new_state,
+                "source": source_activity_id  # 核心：source=触发活动的事件ID
+            }
+        )
+
+    except Exception as e:
+        _LOGGER.error(f"Error in log_state_change: {e}")
+
+def log_command(
+    device_id: str,
+    command: str,
+    context: Any,
+    source: Optional[int] = None,
+    automation_id: Optional[str] = None,
+    status: str = "executed",
+    blocked_by: Optional[int] = None
+) -> None:
+    """记录命令执行（构建wasAssociatedWith/isConditionOf边）"""
+    try:
+        device_name = get_friendly_name(
+            device_id) or get_friendly_name(command.split('.')[0])
+        description = f"{command.split('.')[-1].replace('_', ' ').title()}"
+
+        # 获取依赖的条件ID列表（从状态机）
+        condition_ids = state_machine.get_conditions(
+            automation_id) if automation_id else None
+
+        # 记录Command事件
+        cmd_event_id = record_event(
+            event_type=EVENT_TYPE_COMMAND,
+            device=device_name,
+            description=description,
+            context=context,
+            condition_ids=condition_ids,
+            extra_attributes={
+                "command": command,
+                "target_device": device_id,
+                "context_id": context.id if context else None,
+                "automation_id": automation_id,
+                "status": status,
+                "source": source
+            }
+        )
+        if not context:
+            from homeassistant.context import Context
+            context = Context()  # 生成新上下文
+        # 补充：显式记录上下文映射（防止遗漏）
+        context_id_map[context.id] = cmd_event_id
+
+        # 关联Agent与Command（更新状态机）
+        if automation_id and status == "executed":
+            state_machine.set_target_activity(automation_id, cmd_event_id)
+            state_machine.end_automation(automation_id)
+
+        # 被阻塞时补充关联
+        #if status == "blocked" and blocked_by:
+        #    for event in event_log:
+        #        if event["event_ID"] == cmd_event_id:
+        #            event["blocked_by"] = blocked_by
+        #            break
+
+    except Exception as e:
+        _LOGGER.error(f"Error in log_command: {e}")
+
+
+
+# 需要传入 hass 实例才能查表
+def get_friendly_name(hass: HomeAssistant, entity_id: str) -> str:
+    """从Entity Registry获取真实的友好名称，Fallback到State Attributes"""
+    if not entity_id:
+        return "Unknown"
+    
+    # 1. 尝试从 Registry 获取 (用户自定义名称)
+    registry = er.async_get(hass)
+    entry = registry.async_get(entity_id)
+    if entry and entry.name:
+        return entry.name
+    if entry and entry.original_name:
+        return entry.original_name
+        
+    # 2. 尝试从 State Machine 获取 (当前运行态名称)
+    state = hass.states.get(entity_id)
+    if state and "friendly_name" in state.attributes:
+        return state.attributes["friendly_name"]
+        
+    # 3. 最后退化为 entity_id 处理
+    return entity_id.split('.')[-1].replace('_', ' ').title()
\ No newline at end of file
diff -urN -x __pycache__ -x '*.pyc' "/tmp/homeassistant-2024.1.5/homeassistant/helpers/provenance copy 2.py" "/home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/helpers/provenance copy 2.py"
--- "/tmp/homeassistant-2024.1.5/homeassistant/helpers/provenance copy 2.py"	1970-01-01 08:00:00.000000000 +0800
+++ "/home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/helpers/provenance copy 2.py"	2025-07-29 15:49:31.775875674 +0800
@@ -0,0 +1,338 @@
+# tracing_data_collector.py
+from __future__ import annotations
+from contextvars import ContextVar
+from typing import Any, Dict, List, Optional
+import logging
+import json
+import os
+from datetime import datetime
+
+_LOGGER = logging.getLogger(__name__)
+
+# 定义节点类型
+NODE_TYPE_ENTITY = "Entity"
+NODE_TYPE_ACTIVITY = "Activity"
+NODE_TYPE_AGENT = "Agent"
+
+# 定义关系类型（新）
+RELATION_TYPE_WAS_USED_BY = "wasUsedBy"           # 活动使用实体
+RELATION_TYPE_INFORM = "Inform"                   # 活动触发活动
+RELATION_TYPE_FORBID = "Forbid"                   # 活动阻止活动
+RELATION_TYPE_WAS_ASSOCIATED_WITH = "wasAssociateWith"  # 活动与代理关联
+RELATION_TYPE_DERIVE = "Derive"                   # 实体状态演进
+RELATION_TYPE_GENERATE = "Generate"               # 活动生成实体
+RELATION_TYPE_FORBID = "Forbid"               # 活动生成实体
+
+# 数据存储结构
+tracing_data: Dict[str, Any] = {
+    "nodes": [],
+    "edges": [],
+    "variables": {},
+    "metadata": {
+        "start_time": datetime.now().isoformat(),
+        "version": "1.0"
+    }
+}
+
+# 上下文变量
+Graph_variables_cv: ContextVar[Dict[str, Any]] = ContextVar(
+    "Graph_variables_cv", default={}
+)
+
+
+def clear_data() -> None:
+    """清除跟踪数据"""
+    global tracing_data
+    tracing_data = {
+        "nodes": [],
+        "edges": [],
+        "variables": {},
+        "metadata": {
+            "start_time": datetime.now().isoformat(),
+            "version": "1.0"
+        }
+    }
+    Graph_variables_cv.set({})
+
+
+def get_variable(key: str) -> Any:
+    """从上下文获取变量"""
+    return Graph_variables_cv.get().get(key)
+
+
+def set_variable(key: str, value: Any) -> None:
+    """在上下文中设置变量"""
+    variables = Graph_variables_cv.get()
+    variables[key] = value
+    Graph_variables_cv.set(variables)
+
+
+def create_node(node_id: str, node_type: str, label: str,
+                attributes: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
+    """创建节点并添加到跟踪数据"""
+    node = {
+        "id": node_id,
+        "type": node_type,
+        "label": label,
+        "attributes": attributes or {},
+        "timestamp": datetime.now().isoformat()
+    }
+    tracing_data["nodes"].append(node)
+    return node
+
+
+def create_edge(source_id: str, target_id: str, relation_type: str,
+                attributes: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
+    """创建边并添加到跟踪数据"""
+    edge = {
+        "source": source_id,
+        "target": target_id,
+        "type": relation_type,
+        "attributes": attributes or {},
+        "timestamp": datetime.now().isoformat()
+    }
+    tracing_data["edges"].append(edge)
+    return edge
+
+
+def save_data(file_path: str) -> None:
+    """保存跟踪数据到JSON文件"""
+    try:
+        # 更新元数据
+        tracing_data["metadata"]["end_time"] = datetime.now().isoformat()
+        tracing_data["metadata"]["node_count"] = len(tracing_data["nodes"])
+        tracing_data["metadata"]["edge_count"] = len(tracing_data["edges"])
+
+        os.makedirs(os.path.dirname(file_path), exist_ok=True)
+        with open(file_path, 'w') as f:
+            json.dump(tracing_data, f, indent=2)
+        _LOGGER.warning(f"Tracing data saved to {file_path}")
+    except Exception as e:
+        _LOGGER.error(f"Failed to save tracing data: {e}")
+
+
+def createStateTransition(_from_node: str, _to_node: str) -> Dict[str, Any]:
+    """创建状态转换关系 (Derive)"""
+    return create_edge(_from_node, _to_node, RELATION_TYPE_DERIVE)
+
+
+def CreateRelation(_from_node: str, _to_node: str, relation: str) -> Dict[str, Any]:
+    """创建两个节点之间的关系"""
+    _LOGGER.warning(
+        f"Creating relation: {relation} from {_from_node} to {_to_node}")
+    return create_edge(_from_node, _to_node, relation)
+
+
+def createEntity(argTag: str, argValue: str) -> str:
+    """创建实体节点"""
+    node_id = f"{argTag}:{argValue}"
+    create_node(node_id, NODE_TYPE_ENTITY, argValue, {
+        "tag": argTag
+    })
+    return node_id
+
+
+def createActivity(activityTag: str, activityName: str, label: str,
+                   usedVar: str = None, args: str = None) -> str:
+    """创建活动节点"""
+    node_id = f"{activityTag}:{activityName}"
+    create_node(node_id, NODE_TYPE_ACTIVITY, activityName, {
+        "tag": activityTag,
+        "label": label,
+        "used_var": usedVar,
+        "args": args
+    })
+    return node_id
+
+
+def triggerentryMethod(argTag: str, argValue: Any, agent: str, activityTag: str,
+                       activityName: str, trigger_context: Any, if_start_point: bool,
+                       timestamp: str, historyNode: str) -> None:
+    """触发器入口方法，记录自动化触发信息"""
+    _LOGGER.warning("trigger procenance")
+    _LOGGER.warning(trigger_context)
+    try:
+        if if_start_point:
+            entity_node = createEntity(argTag, argValue)
+            agent_node = f"Agent:{agent}"  # agent参数现在是automation name
+            
+            automation_context = trigger_context.as_dict()['id']
+            
+            # 在变量中存储信息
+            tmp_variables = Graph_variables_cv.get()
+            tmp_variables[automation_context] = {
+                "entity_node": entity_node, "finished": False,
+                "an": agent,
+                'agent_node': agent_node}  # 存储automation name
+            Graph_variables_cv.set(tmp_variables)
+            
+            _LOGGER.warning("trigger_entry")
+            _LOGGER.warning(Graph_variables_cv.get())
+            _LOGGER.warning("trigger_context")
+            _LOGGER.warning(trigger_context.as_dict())
+            
+            # 创建状态演进关系 (Entity -> Entity)
+            if historyNode:
+                createStateTransition(historyNode, entity_node)
+                
+        else:
+            # 查找先前的自动化
+            parent_id = trigger_context.as_dict()['parent_id']
+            _LOGGER.warning(parent_id)
+            
+            if parent_id in Graph_variables_cv.get().keys():
+                _LOGGER.warning("automation here")
+                trigger_dict = Graph_variables_cv.get()[parent_id]
+                
+                _LOGGER.warning(trigger_dict)
+                # 查找由先前自动化动作产生的实体
+                action_entity = trigger_dict['action_entity']
+                _LOGGER.warning(action_entity)
+                
+                # 创建新活动
+                act_node = createActivity(activityTag, activityName, timestamp)
+                
+                # 活动使用实体数据 (Activity -> Entity)
+                CreateRelation(act_node, action_entity, RELATION_TYPE_WAS_USED_BY)
+                
+                # 活动与代理关联 (Activity -> Agent)
+                agent_node = f"Agent:{agent}"  # agent是automation name
+                CreateRelation(act_node, agent_node, RELATION_TYPE_WAS_ASSOCIATED_WITH)
+                
+                # 为自动化创建新项目
+                action_id = trigger_context.as_dict()['id']
+                condition_id = trigger_context.as_dict()['parent_id']
+                
+                tmp_variables = Graph_variables_cv.get()
+                tmp_variables[action_id] = {
+                    "act_node": act_node, "finished": False,  'an': agent}  # 存储automation name
+                Graph_variables_cv.set(tmp_variables)
+                _LOGGER.warning(Graph_variables_cv)
+                
+                # 创建状态演进关系 (Entity -> Entity)
+                if historyNode:
+                    #这里有一个判定是historyNode有没有被创建过
+                    createStateTransition(historyNode, action_entity)
+                    
+    except Exception as e:
+        _LOGGER.warning(f"Error in triggerentryMethod: {e}")
+        
+    _LOGGER.warning("Triggered")
+    _LOGGER.warning(Graph_variables_cv.get())
+
+def conditionTrack(an: str, conid:str, device: str, activity_node: str, entity_node: Any, forbid: bool = False) -> None:
+    """记录条件跟踪信息"""
+    try:
+        _LOGGER.warning("condition filtering")
+        tempkey = None
+        for key, value in Graph_variables_cv.get().items():
+            if an.split('.')[-1] == value['an'] and value["finished"] == False:
+                _LOGGER.warning(an.split('.')[-1])
+                _LOGGER.warning(value['an'])
+                _LOGGER.warning(value["finished"])
+                tempkey = key
+        tmp_variables = Graph_variables_cv.get()
+        tmp_variables[key]["check_state"] = entity_node
+        tmp_variables[key]["check_function"] = activity_node
+        tmp_variables[key]["check_result"] = forbid
+        Graph_variables_cv.set(tmp_variables)
+        CreateRelation(entity_node, activity_node, RELATION_TYPE_WAS_USED_BY)
+        _LOGGER.warning(
+                    f"Condition track: {activity_node} -> {entity_node}")
+    except Exception as e:
+        _LOGGER.warning(e)
+
+
+def actionFilterModule(state_dict: dict, old_state_dict: Any) -> None:
+    """过滤状态机生成的状态并记录"""
+    context_dict = state_dict['context']
+    _id = context_dict['id']
+
+    _LOGGER.warning("---------actionFilterModule--------")
+    _LOGGER.warning(state_dict)
+
+    if _id in Graph_variables_cv.get().keys():
+        trigger_dict = Graph_variables_cv.get()[_id]
+        _LOGGER.warning(trigger_dict)
+        command_node = trigger_dict['action_command']
+
+        _LOGGER.warning("---------Filterted!!--------")
+        # 为自动化生成状态实体
+        node_name = state_dict['entity_id']
+        state = state_dict['state']
+        state_node = f"{state}\n{str(state_dict['last_updated'])}"
+        entity_node = createEntity('State', state_node)
+
+        _LOGGER.warning(state)
+        # 活动生成实体 (Activity -> Entity)
+        CreateRelation(command_node, entity_node, RELATION_TYPE_GENERATE)
+
+        # 实体与代理关联 (Entity -> Agent)
+        agent_node = f"Agent:{node_name}"
+        CreateRelation(entity_node, agent_node,
+                       RELATION_TYPE_WAS_ASSOCIATED_WITH)
+
+        _LOGGER.warning(Graph_variables_cv.get())
+
+        tmp_variables = Graph_variables_cv.get()
+        tmp_variables[_id]["action_entity"] = entity_node
+        tmp_variables[_id]["finished"] = True
+        Graph_variables_cv.set(tmp_variables)
+
+        try:
+            length = len(Graph_variables_cv.get().keys())
+            file_path = f"/home/homeassistant/.homeassistant/trigger_logic_{length}.json"
+            save_data(file_path)
+            if length % 10 == 0:
+                clear_data()
+            _LOGGER.warning("SAVE Successful!")
+        except Exception as e:
+            _LOGGER.warning("SAVE ERROR!")
+            _LOGGER.warning(e)
+
+
+def traceAction(command, device, _context_dict, label) -> None:
+    """跟踪动作执行信息"""
+    _LOGGER.warning("traceAction")
+    _LOGGER.warning(_context_dict)
+
+    _LOGGER.warning(Graph_variables_cv.get())
+
+    #这个Label是具体的context
+    #length = len(Graph_variables_cv.get().keys())
+    #file_path = f"/home/homeassistant/.homeassistant/trigger_logic_{length}.json"
+    #save_data(file_path)
+
+    _parent_id = _context_dict['parent_id']
+    _id = _context_dict['id']
+    
+    entity_node = Graph_variables_cv.get()[_id]["entity_node"]
+    #activity_node = Graph_variables_cv.get()[_id]#["act_node"]
+    _LOGGER.warning("entity_node")
+    _LOGGER.warning(entity_node)
+    _LOGGER.warning(device)
+    # 创建命令活动
+    command_node = createActivity("Function", command, label)
+    try:
+        check_node = Graph_variables_cv.get()[_id]["check_function"]
+        check_result = Graph_variables_cv.get()[_id]["check_result"]
+        _LOGGER.warning(command_node)
+        _LOGGER.warning(check_node)
+        if check_node and check_result:
+            CreateRelation(check_node, command_node, RELATION_TYPE_INFORM)  
+    except:
+        _LOGGER.warning("No checkcondition?")
+        _LOGGER.warning(Graph_variables_cv.get())
+    # 活动间的通知关系 (Activity -> Activity)
+    CreateRelation(entity_node, command_node, RELATION_TYPE_WAS_USED_BY)
+
+    # 命令活动与代理关联 (Activity -> Agent)
+    agent_node = Graph_variables_cv.get()[_id]['agent_node']
+
+    CreateRelation(command_node, agent_node, RELATION_TYPE_WAS_ASSOCIATED_WITH)
+
+    # 在变量中存储信息
+    tmp_variables = Graph_variables_cv.get()
+    tmp_variables[_id]["action_command"] = command_node
+    tmp_variables[_id]["action_label"] = label
+    Graph_variables_cv.set(tmp_variables)
diff -urN -x __pycache__ -x '*.pyc' "/tmp/homeassistant-2024.1.5/homeassistant/helpers/provenance copy.py" "/home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/helpers/provenance copy.py"
--- "/tmp/homeassistant-2024.1.5/homeassistant/helpers/provenance copy.py"	1970-01-01 08:00:00.000000000 +0800
+++ "/home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/helpers/provenance copy.py"	2025-06-20 15:21:22.239032211 +0800
@@ -0,0 +1,274 @@
+from __future__ import annotations
+from contextlib import contextmanager
+
+from prov.dot import prov_to_dot
+from prov.graph import prov_to_graph
+
+
+from prov.model import ProvDocument, Namespace
+from contextvars import ContextVar
+from typing import Any
+import logging
+
+_LOGGER = logging.getLogger(__name__)
+
+Default_graph = ProvDocument()
+
+
+Default_graph.add_namespace('State', 'http://www.provbook.org/nownews/')
+Default_graph.add_namespace('Function', 'http://www.provbook.org/nownews/people/')
+Default_graph.add_namespace('Automation', 'http://www.provbook.org/ns/#')
+Default_graph.add_namespace('Device', 'ftp://ftp.bls.gov/pub/special.requests/oes/')
+
+
+Graph_cv: ContextVar[Any| None] = ContextVar(
+    "provenance_graph", default= Default_graph 
+)
+
+Graph_variables_cv: ContextVar[dict[str, Any]] = ContextVar(
+    "Graph_variables_cv", default={}
+)
+
+
+def Graph_clear() -> None:
+    """Clear the Graph"""
+    Graph_cv.set(ProvDocument())
+    Graph_variables_cv.set({})
+    
+
+def Graph_get(clear: bool = True):
+    if clear:
+        Graph_clear()
+    return Graph_cv.get()
+
+        
+
+# new added relationship
+def createTemporalRelation(_from_node: Any, _to_node: Any):
+    """Create a temporal relation between two states of the same device."""
+    rel =  Graph_cv.get().wasDerivedFrom(_from_node, _to_node)
+    return rel
+
+
+def CreateRelation(_from_node: Any, _to_node: Any, relation:str):
+    _LOGGER.warning(str(Graph_cv.get().get_provn()))
+    if relation == "Used":
+        Graph_cv.get().used(_from_node, _to_node)
+    elif relation == "wasAttributedTo":
+        Graph_cv.get().wasAttributedTo(_from_node, _to_node)
+    elif relation == "wasInformedBy":
+        Graph_cv.get().wasInformedBy(_from_node, _to_node)
+    elif relation == "wasAssociatedWith":
+        Graph_cv.get().wasAssociatedWith(_from_node, _to_node)
+    elif relation == "wasGeneratedBy":
+        Graph_cv.get().wasGeneratedBy(_from_node, _to_node)
+  
+
+
+def createEntity(argTag:str, argValue: str):
+    node = Graph_cv.get().entity(argTag +":"+argValue)
+    #self.entity[argValue] = node
+    return node
+
+
+def createActivity(activityTag: str, activityName: str, label:str, usedVar:str = None, args:str = None):
+    activity_node = Graph_cv.get().activity(activityTag+":" + label+'\n'+activityName)
+    #if usedVar and args:     
+    return activity_node
+
+
+
+#def createActivity(activityTag: str, activityName: str, usedVar:str = None, args:str = None):
+ #   activity_node = Graph_cv.get().activity(activityTag+":" + activityName)
+    #if usedVar and args:
+               
+ #   return activity_node
+
+def save(length):
+    _LOGGER.warning("testtest")
+    _LOGGER.warning(Graph_cv.get())
+    
+    dot2 = prov_to_dot(Graph_cv.get(), direction= "BT")
+    _LOGGER.warning(dot2)
+    #_LOGGER.warning(dot)
+    route = "/home/homeassistant/.homeassistant/"
+    dot2.write_png(route+'trigger_logic' + str(length) + '.png')
+
+
+#entrypoint method embed into the trigger implementation logic
+def triggerentryMethod(argTag: str, argValue: Any, agent: str, activityTag: str, activityName: str, trigger_context: Any, if_start_point: bool,timestamp: str, historyNode :Any):
+    _LOGGER.warning("trigger procenance")
+    _LOGGER.warning(trigger_context)
+    try:
+        if if_start_point:
+            entity_node = createEntity(argTag, argValue)
+            CreateRelation(entity_node, Graph_cv.get().agent('Device:'+ agent),"wasAttributedTo")
+            #CreateRelation(entity_node, Graph_cv.get().agent('Device:'+ agent+'\n'+timestamp),"wasAttributedTo")
+            act_node = createActivity(activityTag, activityName, timestamp)
+            CreateRelation(act_node, entity_node, "Used")
+
+            # get the action/automation context id
+            #condition_id = trigger_context.as_dict()['parent_id']
+            automation_context = trigger_context.as_dict()['id']
+            
+            #create a new item in traces
+            #pass the automation_node into the Global variables
+            tmp_variables = Graph_variables_cv.get()
+            tmp_variables[automation_context] = {"act_node": act_node, "finished": False, 'an': activityName}
+            Graph_variables_cv.set(tmp_variables)
+
+            _LOGGER.warning("trigger_entry")
+            _LOGGER.warning(Graph_variables_cv.get())
+            _LOGGER.warning(trigger_context)
+
+            #new add
+            createTemporalRelation(historyNode, entity_node)
+
+        else:
+            # find the preceding automation
+            parent_id = trigger_context.as_dict()['parent_id']
+            _LOGGER.warning(parent_id)
+
+            if parent_id in Graph_variables_cv.get().keys():
+                _LOGGER.warning("automation here")
+                trigger_dict = Graph_variables_cv.get()[parent_id]
+
+                _LOGGER.warning(trigger_dict)
+                #find the entity produced by the preceding automation action
+                action_entity = trigger_dict['action_entity']
+                _LOGGER.warning(action_entity)
+
+                act_node = createActivity(activityTag, activityName, timestamp)
+                CreateRelation(act_node, action_entity,"Used")
+
+                #create the new item to the automation
+                action_id = trigger_context.as_dict()['id']
+                condition_id = trigger_context.as_dict()['parent_id']
+
+                tmp_variables = Graph_variables_cv.get()
+                tmp_variables[action_id] = {"act_node": act_node, "finished": False,  'an': activityName}
+                Graph_variables_cv.set(tmp_variables)
+                _LOGGER.warning(Graph_variables_cv)
+                
+                CreateRelation(action_entity, Graph_cv.get().agent('Device:'+ agent),"wasAttributedTo")
+                #CreateRelation(action_entity, Graph_cv.get().agent('Device:'+ agent+'\n'+timestamp),"wasAttributedTo")
+
+                #new added
+                createTemporalRelation(historyNode, action_entity)
+
+    except Exception as e:
+        _LOGGER.warning(e)
+
+    _LOGGER.warning("Triggered")
+    _LOGGER.warning(Graph_variables_cv.get())
+
+
+
+def conditionTrack(an: str, device: str, activity: str, entity_node: Any):  
+    try:
+        _LOGGER.warning("condition")
+        for key, value in Graph_variables_cv.get().items():
+            if value['an'] == an:
+                #find the corresponding automation
+                activity_node = Graph_variables_cv.get()[key]["act_node"]
+
+                #create the state validation function
+                validate_node = createActivity("Function", activity, device)
+
+                #create the checked State
+                check_node = createEntity("State", entity_node)
+
+                #check_node ->Used-> validation function
+                CreateRelation(validate_node, check_node, "Used")
+                _LOGGER.warning(check_node)
+                #automation -> wasInformedBy -> results of the validation function
+                CreateRelation(activity_node, validate_node, "wasInformedBy")
+                CreateRelation(check_node, Graph_cv.get().agent('Device:'+ device), "wasAttributedTo")
+                #CreateRelation(validate_node, Graph_cv.get().agent('Device:'+ device),"wasAssociatedWith")
+    except Exception as e:
+        _LOGGER.warning(e)
+    
+
+#filter the State generated from the State Machine
+def actionFilterModule(state_dict: dict, old_state_dict: Any):
+    context_dict = state_dict['context']
+    _id = context_dict['id']
+
+    _LOGGER.warning("---------actionFilterModule--------")
+    _LOGGER.warning(state_dict)
+
+    if _id in Graph_variables_cv.get().keys():
+        trigger_dict = Graph_variables_cv.get()[_id]
+        _LOGGER.warning(trigger_dict)
+        command_node = trigger_dict['action_command']
+
+        _LOGGER.warning("---------Filterted!!--------")
+        #generate the State Entity for the automation
+        node_name = state_dict['entity_id']
+        state = state_dict['state']
+        state_node  = state + '\n' +str(state_dict['last_updated'])
+        entity_node = createEntity('State', state_node)
+
+        _LOGGER.warning(state)
+        CreateRelation(entity_node, command_node, "wasGeneratedBy")
+        CreateRelation(entity_node, Graph_cv.get().agent('Device:'+ node_name),"wasAttributedTo")
+
+        #CreateRelation(entity_node, Graph_cv.get().agent('Device:'+ node_name+'\n'+str(state_dict['last_updated'])),"wasAttributedTo")
+        _LOGGER.warning(Graph_variables_cv.get())
+
+        #generate the previous state of the action device
+        """if old_state_dict:
+            old_state_dict = old_state_dict.as_dict()
+            old_node_name = old_state_dict['entity_id']
+            old_state = old_state_dict['state']
+            old_state_node  = old_state + '\n' +str(old_state_dict['last_updated'])
+            old_entity_node = createEntity('State', old_state_node)
+            
+            createTemporalRelation(old_entity_node, entity_node)
+            
+            #CreateRelation(old_entity_node, Graph_cv.get().agent('Device:'+ #old_node_name),"wasAttributedTo")
+
+        CreateRelation(trigger_dict['act_node'],old_entity_node, "Used")"""
+
+
+
+        tmp_variables = Graph_variables_cv.get()
+        tmp_variables[_id]["action_entity"] = entity_node
+        tmp_variables[_id]["finished"] = True
+        Graph_variables_cv.set(tmp_variables)
+        
+
+        try:
+            length = len(Graph_variables_cv.get().keys())
+            save(length)
+            if (length %10 ==0):
+                Graph_clear()
+            _LOGGER.warning("SAVE Successful!")
+        except Exception as e:
+            _LOGGER.warning("SAVE ERROR!")
+            _LOGGER.warning(e)
+        
+
+
+def traceAction(command, device, _context_dict,label):
+    _LOGGER.warning("traceAction")
+    _LOGGER.warning(_context_dict)
+    
+    length = len(Graph_variables_cv.get().keys())
+    save(length)
+    
+    _parent_id = _context_dict['parent_id']
+    _id = _context_dict['id']
+    activity_node = Graph_variables_cv.get()[_id]["act_node"]
+    
+    _LOGGER.warning(device)
+    command_node = createActivity("Function", command, label)
+    CreateRelation(command_node, activity_node, "wasInformedBy") 
+    #CreateRelation(command_node, Graph_cv.get().agent('Device:'+ device),"wasAssociatedWith")
+
+
+    #create a new item in traces
+    #pass the automation_node into the Global variables
+    tmp_variables = Graph_variables_cv.get()
+    tmp_variables[_id]["action_command"] = command_node
+    Graph_variables_cv.set(tmp_variables)
diff -urN -x __pycache__ -x '*.pyc' /tmp/homeassistant-2024.1.5/homeassistant/helpers/provenance.py /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/helpers/provenance.py
--- /tmp/homeassistant-2024.1.5/homeassistant/helpers/provenance.py	1970-01-01 08:00:00.000000000 +0800
+++ /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/helpers/provenance.py	2026-02-12 21:25:25.091955109 +0800
@@ -0,0 +1,685 @@
+from __future__ import annotations
+from contextvars import ContextVar
+from typing import Any, Dict, List, Optional, Tuple, Sequence, TYPE_CHECKING
+import logging
+import json
+import os
+from datetime import datetime
+import uuid
+
+if TYPE_CHECKING:
+    from homeassistant.core import HomeAssistant
+
+_LOGGER = logging.getLogger(__name__)
+
+# 全局 HASS 引用，由 Core 启动时注入
+_HASS_REF: Optional[Any] = None
+
+def set_global_hass(hass: Any):
+    """注入HASS实例，用于查表"""
+    global _HASS_REF
+    _HASS_REF = hass
+    
+# 定义事件类型
+EVENT_TYPE_ENTITY = "Entity"
+EVENT_TYPE_COMMAND = "Command"
+EVENT_TYPE_AGENT = "Agent"
+
+# 全局事件存储
+event_log: List[Dict[str, Any]] = []
+event_id_counter = 1
+context_id_map: Dict[str, int] = {}  # context.id -> event_ID
+context_vars: ContextVar[Dict[str, Any]] = ContextVar(
+    "context_vars", default={}
+)
+
+
+# 状态机：跟踪自动化执行状态和条件关联
+class StateMachine:
+    def __init__(self):
+        # automation_id -> state (存储完整条件链和目标活动)
+        self.automation_states: Dict[str, Dict[str, Any]] = {}
+        self.automation_commands: Dict[str,
+                                       List[Dict[str, Any]]] = {}  # 自动化命令跟踪
+        self.automation_conditions: Dict[str, List[int]] = {}  # 存储所有条件事件ID
+
+    def start_automation(self, automation_id: str, trigger_event_id: int) -> None:
+        """记录自动化开始执行，初始化条件链"""
+        self.automation_states[automation_id] = {
+            "active": True,
+            "trigger_event_id": trigger_event_id,
+            "last_condition_id": None,
+            "condition_passed": True,
+            "current_step": "trigger",
+            "target_activity": None  # 最终触发的Command ID
+        }
+        self.automation_conditions[automation_id] = []  # 初始化条件ID列表
+
+    def record_condition(self, automation_id: str, condition_event_id: int, result: bool) -> None:
+        """记录条件检查结果，维护完整条件链"""
+        if automation_id not in self.automation_states:
+            _LOGGER.warning(
+                f"Automation {automation_id} not active when recording condition")
+            return
+
+        state = self.automation_states[automation_id]
+        state["last_condition_id"] = condition_event_id
+        state["condition_passed"] = state["condition_passed"] and result
+        state["current_step"] = "condition"
+        # 存储所有条件ID（无论是否通过）
+        self.automation_conditions[automation_id].append(condition_event_id)
+
+    def set_target_activity(self, automation_id: str, activity_id: int) -> None:
+        """记录自动化触发的目标Command ID"""
+        if automation_id in self.automation_states:
+            self.automation_states[automation_id]["target_activity"] = activity_id
+
+    def get_conditions(self, automation_id: str) -> List[int]:
+        """获取自动化的所有条件事件ID"""
+        return self.automation_conditions.get(automation_id, [])
+
+    def is_automation_active(self, automation_id: str) -> bool:
+        """检查自动化是否仍在活跃状态（条件未失败）"""
+        state = self.automation_states.get(automation_id, {})
+        return state.get("active", False) and state.get("condition_passed", False)
+
+    def is_automation_active_with_reason(self, automation_id: str) -> Tuple[bool, Optional[int]]:
+        """检查自动化是否活跃并返回阻塞原因ID"""
+        state = self.automation_states.get(automation_id, {})
+        is_active = state.get("active", False) and state.get(
+            "condition_passed", False)
+        return is_active, state.get("last_condition_id") if not is_active else None
+
+    def end_automation(self, automation_id: str) -> None:
+        """标记自动化执行结束"""
+        if automation_id in self.automation_states:
+            self.automation_states[automation_id]["active"] = False
+            self.automation_states[automation_id]["current_step"] = "completed"
+
+    def get_automation_context(self, automation_id: str) -> Optional[Dict[str, Any]]:
+        """获取自动化上下文信息"""
+        return self.automation_states.get(automation_id)
+
+    def track_commands(self, automation_id: str, sequence: Sequence[dict]) -> None:
+        """解析自动化的动作配置，提取目标设备和命令"""
+        parsed_commands = []
+        for action in sequence:
+            # 解析HomeAssistant动作配置中的核心信息：
+            # 示例动作配置：{"service": "light.turn_on", "target": {"entity_id": "light.lumi_v3_6063_light_3"}}
+            service = action.get("service")  # 命令类型（如"light.turn_on"）
+            target_entity = action.get("target", {}).get("entity_id")  # 目标设备ID
+            # 处理目标设备为列表的情况（取第一个）
+            if isinstance(target_entity, list):
+                target_entity = target_entity[0] if target_entity else None
+            if service and target_entity:
+                parsed_commands.append({
+                    "target_device": target_entity,  # 目标设备实体ID
+                    "command": service,  # 命令类型
+                    "description": f"Execute {service.split('.')[-1]}"  # 描述（如"turn_on"）
+                })
+        # 存储解析后的命令，关联到自动化ID
+        # 强制将 ID 转为字符串存储，防止类型不匹配
+        self.automation_commands[str(automation_id)] = parsed_commands
+        _LOGGER.warning(f"[Trace] Tracked {len(parsed_commands)} commands for {automation_id}")
+        #self.automation_commands[automation_id] = parsed_commands
+
+    
+    def get_blocked_commands(self, automation_id: str) -> List[Dict[str, Any]]:
+        """获取因条件失败而被阻止的命令"""
+        return self.automation_commands.get(automation_id, [])
+
+
+# 初始化状态机
+state_machine = StateMachine()
+
+
+def get_session_id() -> str:
+    """从上下文获取当前会话ID（支持多会话隔离）"""
+    vars = context_vars.get()
+    if "session_id" not in vars:
+        vars["session_id"] = str(uuid.uuid4())
+        context_vars.set(vars)
+    return vars["session_id"]
+
+
+def clear_log() -> None:
+    """清除事件日志并重置会话"""
+    global event_log, event_id_counter, context_id_map
+    event_log = []
+    event_id_counter = 1
+    context_id_map = {}
+    # 重置上下文变量（保留结构，清空内容）
+    vars = context_vars.get()
+    vars.clear()
+    context_vars.set(vars)
+    # 重置状态机
+    state_machine.automation_states.clear()
+    state_machine.automation_commands.clear()
+    state_machine.automation_conditions.clear()
+    _LOGGER.info("Event log cleared and new session started")
+
+
+
+# ========== 核心优化：富语义信息获取 ==========
+def get_rich_entity_info(entity_id: str) -> dict:
+    """获取实体名称、区域、型号等富语义信息，解决‘脏数据’问题"""
+    # 引入注册表以获取富语义信息
+    from homeassistant.helpers import entity_registry as er
+    from homeassistant.helpers import device_registry as dr
+    
+    info = {
+        "friendly_name": entity_id.split('.')[-1].replace('_', ' ').title(),
+        "area_id": None,
+        "model": None,
+        "domain": entity_id.split('.')[0]
+    }
+    
+    if not _HASS_REF or not entity_id:
+        return info
+
+    try:
+        ent_reg = er.async_get(_HASS_REF)
+        dev_reg = dr.async_get(_HASS_REF)
+        
+        # 1. 查询 Entity Registry
+        entry = ent_reg.async_get(entity_id)
+        if entry:
+            if entry.name:
+                info["friendly_name"] = entry.name
+            elif entry.original_name:
+                info["friendly_name"] = entry.original_name
+            
+            # 2. 查询 Device Registry
+            if entry.device_id:
+                device = dev_reg.async_get(entry.device_id)
+                if device:
+                    info["model"] = device.model
+                    info["area_id"] = device.area_id # 之后可以进一步转为 area name
+    except Exception:
+        pass # 查表失败降级处理
+
+    # 3. 尝试从 State 获取 (运行时名称通常最准)
+    state = _HASS_REF.states.get(entity_id)
+    if state and "friendly_name" in state.attributes:
+        info["friendly_name"] = state.attributes["friendly_name"]
+
+    return info
+
+
+def record_event(
+    event_type: str,
+    device: str,
+    description: str,
+    context: Any,
+    action: Optional[str] = None,  # "triggered" 或 "condition_check"
+    condition: Optional[Dict[str, Any]] = None,
+    extra_attributes: Optional[Dict[str, Any]] = None,
+    # 三类事件特有字段（顶级参数）
+    entity_id: Optional[str] = None,  # Entity特有：实体唯一ID
+    target_activity: Optional[int] = None,  # Agent特有：触发的Command ID
+    forbidden_activity: Optional[int] = None,  # Agent特有：阻止的Command ID
+    condition_ids: Optional[List[int]] = None,  # Command特有：依赖的条件ID列表
+) -> int:
+    """记录事件的核心函数，支持三类事件特有字段和关联逻辑"""
+    global event_id_counter
+
+    """if ("unknown" in description.lower()) or ("None" in description.lower()) or ("unavailable" in description.lower()):
+        _LOGGER.debug(f"过滤包含unknown的事件：{description}")
+        return -1  # 返回无效ID表示事件未被记录"""
+    
+    # ===== 优化后的过滤逻辑 =====
+    # 只有当事件类型是 Entity 时，才检查是否包含 unknown/None/unavailable
+    # Agent 和 Command 事件即便包含这些词也必须记录，因为它们代表了逻辑路径
+    if event_type == EVENT_TYPE_ENTITY:
+        if any(word in description.lower() for word in ["unknown", "none", "unavailable"]):
+            _LOGGER.debug(f"过滤 Entity 脏数据：{description}")
+            return -1 
+    # ===========================
+
+
+    # 1. 从上下文获取会话ID
+    current_session_id = get_session_id()
+
+    # 2. 解析source（优先显式传入，再 fallback 到上下文）
+    source = None
+    if extra_attributes and "source" in extra_attributes:
+        source = extra_attributes.pop("source")  # 提取显式source
+    else:
+        if context and context.parent_id:
+            source = context_id_map.get(context.parent_id)
+    
+    rich_info = {}
+    display_name = device
+    if entity_id:
+        rich_info = get_rich_entity_info(entity_id)
+        display_name = rich_info.get("friendly_name", device)
+    elif "." in device and "_" in device: # 猜测是 entity_id
+        rich_info = get_rich_entity_info(device)
+        display_name = rich_info.get("friendly_name", device)
+
+    # 4. 构建基础事件结构
+    event = {
+        "timestamp": datetime.now().strftime("%H:%M:%S.%f")[:-3],
+        "device": display_name, # 用户可见名称
+        "raw_device_id": entity_id or device, # 保留技术 ID
+        "event_type": event_type,
+        "description": description,
+        "source": source,
+        "event_ID": event_id_counter,
+        "session_id": current_session_id,
+        "action": action,
+        "context_id": context.id if context else None,
+        "parent_context_id": context.parent_id if context else None
+    }
+
+    if rich_info.get("area_id"):
+        event["area"] = rich_info["area_id"]
+
+    # 5. 添加事件类型特有字段（顶级字段）
+    if event_type == EVENT_TYPE_ENTITY and entity_id:
+        event["entity_id"] = entity_id
+        event["old_state"] = extra_attributes.pop(
+            "old_state", "") if extra_attributes else ""
+        event["new_state"] = extra_attributes.pop(
+            "new_state", "") if extra_attributes else ""
+
+    elif event_type == EVENT_TYPE_AGENT:
+        if target_activity is not None:
+            event["target_activity"] = target_activity
+        if forbidden_activity is not None:
+            event["forbidden_activity"] = forbidden_activity
+
+    elif event_type == EVENT_TYPE_COMMAND:
+        if condition_ids is not None:
+            event["condition_ids"] = condition_ids
+        event["command"] = extra_attributes.pop(
+            "command", "") if extra_attributes else ""
+        event["target_device"] = extra_attributes.pop(
+            "target_device", "") if extra_attributes else ""
+
+    # 6. 添加条件信息（如Agent的条件检查结果）
+    if condition is not None:
+        event.update(condition)
+    
+    # 7. 添加剩余额外属性
+    if extra_attributes:
+        event.update(extra_attributes)
+
+    # 8. 存储事件并更新映射
+    event_log.append(event)
+    if context and hasattr(context, 'id'):
+        context_id_map[context.id] = event_id_counter  # 上下文ID -> 事件ID
+
+    event_id_counter += 1
+    _LOGGER.debug(f"Recorded {event_type} event: {event}")
+    return event_id_counter - 1
+
+
+def save_log(base_dir: str, prefix: str = "provenance_log") -> str:
+    """
+    保存带时间戳的事件日志。
+    参数 base_dir: 存储目录，如 '/home/homeassistant/.homeassistant/logs/'
+    参数 prefix: 文件名前缀
+    """
+    try:
+        # 1. 生成人类可读的时间戳
+        timestamp = datetime.now().strftime("%Y-%m-%d-%H-%M-%S")
+        filename = f"{prefix}_{timestamp}.json"
+        full_path = os.path.join(base_dir, filename)
+
+        # 2. 确保目录存在
+        os.makedirs(base_dir, exist_ok=True)
+
+        # 3. 写入文件
+        with open(full_path, 'w', encoding='utf-8') as f:
+            json.dump(event_log, f, indent=2, ensure_ascii=False)
+        
+        _LOGGER.warning(f"===== Provenance Log Saved: {full_path} =====")
+        return full_path
+    except Exception as e:
+        _LOGGER.error(f"Failed to save event log: {e}")
+        return ""
+
+
+
+
+# ========== 事件记录工具函数 ==========
+def log_agent_event(device: str, description: str, context: Any, condition: Optional[Dict[str, Any]] = None, extra_attributes: Optional[Dict[str, Any]] = None, automation_id: Optional[str] = None, target_activity: Optional[int] = None, forbidden_activity: Optional[int] = None, action: Optional[str] = None) -> int:
+    _LOGGER.warning(f"Entering log_agent_event: Device={device}, Action={action}, AutoID={automation_id}")
+
+    event_id = record_event(EVENT_TYPE_AGENT, device, description, context, action, condition, extra_attributes, target_activity=target_activity, forbidden_activity=forbidden_activity)
+    if condition and automation_id:
+        result = condition.get("condition_result", False)
+        state_machine.record_condition(str(automation_id), event_id, result)
+        if not result:
+            if event_log and event_log[-1]["event_ID"] == event_id:
+                event_log[-1]["description"] = f"Condition failed: {description}. Stopping automation." 
+            _LOGGER.warning(f"[Trace] Condition Failed. Triggering block logging for {automation_id}")
+            log_blocked_commands(str(automation_id), context, event_id)
+            state_machine.end_automation(str(automation_id))
+    return event_id
+    
+def log_trigger(action: str, entity_id: str, state: str, automation_name: str, context: Any, automation_id: str, sequence: Optional[Sequence[dict]] = None, is_start_point: bool = True) -> int:
+    _LOGGER.warning(f"[Trace] Trigger Start: {automation_name} (ID: {automation_id})")
+    
+    # 获取触发源 Entity 事件 ID（实现 Trigger 溯源）
+    vars = context_vars.get()
+    trigger_entity_id = vars.get(context.id, {}).get("entity_event_id")
+    
+    rich_name = automation_name
+    if _HASS_REF:
+        rich_info = get_rich_entity_info(automation_name) # 这里 automation_name 其实是 entity_id
+        rich_name = rich_info.get("friendly_name", automation_name)
+
+    agent_event_id = log_agent_event(
+        device=rich_name, # 使用富语义名称
+        description=f"Triggered by {entity_id} state change",
+        context=context,
+        automation_id=automation_id,
+        extra_attributes={"source": trigger_entity_id, "automation_entity_id": automation_name},
+        action="triggered"
+    )
+    # 核心修复：同时用数字 ID 和 实体名注册状态机，解决匹配不上问题
+    state_machine.start_automation(str(automation_id), agent_event_id)
+    if automation_name and automation_name.startswith("automation."):
+        state_machine.start_automation(automation_name, agent_event_id)
+
+
+    if sequence:
+        state_machine.track_commands(automation_id, sequence)
+        if automation_name.startswith("automation."):
+                state_machine.track_commands(automation_name, sequence)
+    
+    # 记录触发源 Entity 事件 (如果这是链条起点)
+    if is_start_point:
+        rich_entity = get_rich_entity_info(entity_id)
+        entity_event_id = record_event(
+            event_type=EVENT_TYPE_ENTITY,
+            device=rich_entity.get("friendly_name", entity_id),
+            description=f"Trigger state: {state}",
+            context=context,
+            entity_id=entity_id,
+            extra_attributes={"old_state": "", "new_state": state}
+        )
+        vars[context.id] = {"automation": automation_name, "automation_id": automation_id, "trigger_event_id": agent_event_id, "entity_event_id": entity_event_id}
+        context_vars.set(vars)
+    return agent_event_id
+    
+
+def log_condition_check(
+    automation_name: str,
+    automation_id: str,
+    entity_id: str,
+    condition_desc: str,
+    result: bool,
+    context: Any,
+    condition_state: Optional[str] = None
+) -> None:
+    """记录条件检查事件（用于构建isConditionOf边）"""
+    _LOGGER.warning(f"[Trace] Condition Check: {automation_name} | ID: {automation_id} | Result: {result}")
+    try:
+        # 即使状态机里没有 active，我们也要继续记录日志，不要 return
+        is_active = state_machine.is_automation_active(automation_id)
+        if not is_active:
+            _LOGGER.warning(f"[Trace] ID {automation_id} not found/active in state_machine, recording anyway.")
+
+        device_name = get_friendly_name(entity_id)
+        condition_info = f"{condition_desc} - {'Passed' if result else 'Failed'}"
+
+        vars = context_vars.get()
+        # 增加溯源健壮性：从当前或父 context 寻找 trigger source
+        automation_context = vars.get(context.parent_id, {}) or vars.get(context.id, {})
+        trigger_source = automation_context.get("entity_event_id")
+
+        # 构造 condition 详情，增加 fallback 逻辑防止 related_trigger_id 报错
+        auto_ctx = state_machine.get_automation_context(automation_id)
+        related_trigger = auto_ctx.get("trigger_event_id") if auto_ctx else None
+
+        condition_data = {
+            "condition_result": result,
+            "condition_entity": device_name,
+            "condition_entity_id": entity_id,
+            "condition_state": condition_state,
+            "related_trigger_id": related_trigger
+        }
+
+        condition_event_id = log_agent_event(
+            device=automation_name,
+            description=condition_info,
+            context=context,
+            condition=condition_data,
+            automation_id=automation_id,
+            extra_attributes={"source": trigger_source},
+            action="condition_check"
+        )
+
+        # 无论如何都要尝试记录被阻止的命令
+        if not result:
+            _LOGGER.warning(f"[Trace] Condition Failed, logging blocked commands for {automation_id}")
+            log_blocked_commands(automation_id, context, condition_event_id)
+    except Exception as e:
+        _LOGGER.warning(f"Error in log_condition_check: {e}")
+
+
+def log_condition(
+    automation_name: str,
+    entity_id: str,
+    condition_desc: str,
+    result: bool,
+    context: Any,
+    condition_state: Optional[str] = None,
+    automation_id: Optional[str] = None,
+    variables: Optional[Dict[str, Any]] = None
+) -> None:
+    """对接HomeAssistant条件检查逻辑的事件记录"""
+    try:
+        # --- 新增：ID 对齐逻辑 ---
+        final_id = automation_id
+        
+        if variables:
+            # 1. 尝试从 variables 直接拿数字 ID (最准)
+            if "automation_id" in variables:
+                final_id = variables["automation_id"]
+            # 2. 尝试从 this 对象拿 (YAML 里的 id)
+            elif "this" in variables and "attributes" in variables["this"]:
+                final_id = variables["this"]["attributes"].get("id", final_id)
+        
+        # 3. 实在没有就用实体名，但加上警告
+        if not final_id:
+            final_id = automation_name 
+            _LOGGER.debug(f"Using entity name as fallback ID: {final_id}")
+
+        # --- 强制插入 Debug 日志 ---
+        _LOGGER.warning(f"[Condition Trace] Name: {automation_name} | ID: {final_id} | Result: {result}")
+        _LOGGER.warning(f"[Trace] Entering log_condition: {automation_name} | TargetID: {final_id}")
+
+        log_condition_check(
+            automation_name=automation_name,
+            automation_id=str(final_id), # 统一转字符串防止类型冲突
+            entity_id=entity_id,
+            condition_desc=condition_desc,
+            result=result,
+            context=context,
+            condition_state=condition_state
+        )
+    except Exception as e:
+        _LOGGER.error(f"Error in log_condition: {e}")
+
+
+def log_blocked_commands(
+    automation_id: str,
+    context: Any,
+    source_agent_id: int  # 条件检查事件的ID（作为来源）
+) -> None:
+    """记录被条件阻止的命令"""
+    # 尝试多种 ID 获取命令列表
+    blocked_commands = state_machine.automation_commands.get(str(automation_id))
+    if not blocked_commands:
+        vars = context_vars.get()
+        # 尝试从当前或父 context 变量里找回关联的实体名或 ID
+        ctx_data = vars.get(context.id) or vars.get(context.parent_id)
+        if ctx_data:
+            alt_id = ctx_data.get("automation_id") or ctx_data.get("automation")
+            blocked_commands = state_machine.automation_commands.get(str(alt_id))
+    if not blocked_commands:
+        _LOGGER.warning(f"[Trace] No commands found in StateMachine for block-logging (ID: {automation_id})")
+        return
+
+    # 为每个被阻止的命令生成事件
+    for cmd in blocked_commands:
+        # 调用record_event记录被阻止的命令
+        record_event(
+            event_type=EVENT_TYPE_COMMAND,
+            device=cmd["target_device"],  # 目标设备ID
+            # 描述（如"Blocked: turn_on"）
+            description=f"Blocked: {cmd['description']}",
+            context=context,
+            condition_ids=state_machine.get_conditions(
+                automation_id),  # 关联所有条件ID
+            extra_attributes={
+                "command": cmd["command"],  # 被阻止的命令（如"light.turn_on"）
+                "target_device": cmd["target_device"],  # 目标设备
+                "status": "blocked",  # 标记为“被阻止”
+                "source": source_agent_id  # 关联条件检查事件ID
+            }
+        )
+
+def log_state_change(
+    entity_id: str,
+    new_state: str,
+    old_state: str,
+    context: Any,
+    source_activity_id: Optional[int] = None  # 触发该状态变化的Activity事件ID
+) -> None:
+    """记录实体状态变化（构建Derive/Generate边）"""
+    try:
+        device_name = get_friendly_name(entity_id)
+        description = f"{old_state} → {new_state}" if old_state else f"Initialized to {new_state}"
+
+        # 自动获取source_activity_id（如果未手动传入）
+        if source_activity_id is None and context:
+            # 1. 从上下文的parent_id找到触发源头的context.id
+            # 实体状态变化的parent_id通常指向触发它的命令/活动的context.id
+            source_context_id = getattr(context, 'parent_id', None)
+            
+            if not source_context_id:
+                # 特殊情况：直接使用当前上下文ID（如面板操作）
+                source_context_id = getattr(context, 'id', None)
+            
+            # 2. 通过context_id_map将context.id转换为事件ID（即source_activity_id）
+            if source_context_id:
+                source_activity_id = context_id_map.get(source_context_id)
+
+        record_event(
+            event_type=EVENT_TYPE_ENTITY,
+            device=device_name,
+            description=description,
+            context=context,
+            entity_id=entity_id,
+            extra_attributes={
+                "old_state": old_state,
+                "new_state": new_state,
+                "source": source_activity_id  # 核心：source=触发活动的事件ID
+            }
+        )
+
+    except Exception as e:
+        _LOGGER.error(f"Error in log_state_change: {e}")
+
+def log_command(
+    device_id: str,
+    command: str,
+    context: Any,
+    source: Optional[int] = None,
+    automation_id: Optional[str] = None,
+    status: str = "executed",
+    blocked_by: Optional[int] = None
+) -> None:
+    """记录命令执行（构建wasAssociatedWith/isConditionOf边）"""
+    try:
+        device_name = get_friendly_name(
+            device_id) or get_friendly_name(command.split('.')[0])
+        description = f"{command.split('.')[-1].replace('_', ' ').title()}"
+
+        # 获取依赖的条件ID列表（从状态机）
+        _LOGGER.warning("automation_id")
+        _LOGGER.warning(automation_id)
+        condition_ids = state_machine.get_conditions(
+            automation_id) if automation_id else None
+
+        # 记录Command事件
+        cmd_event_id = record_event(
+            event_type=EVENT_TYPE_COMMAND,
+            device=device_name,
+            description=description,
+            context=context,
+            condition_ids=condition_ids,
+            extra_attributes={
+                "command": command,
+                "target_device": device_id,
+                "context_id": context.id if context else None,
+                "automation_id": automation_id,
+                "status": status,
+                "source": source
+            }
+        )
+        if not context:
+            from homeassistant.context import Context
+            context = Context()  # 生成新上下文
+        # 补充：显式记录上下文映射（防止遗漏）
+        context_id_map[context.id] = cmd_event_id
+
+        # 关联Agent与Command（更新状态机）
+        if automation_id and status == "executed":
+            state_machine.set_target_activity(automation_id, cmd_event_id)
+            state_machine.end_automation(automation_id)
+
+        # 被阻塞时补充关联
+        #if status == "blocked" and blocked_by:
+        #    for event in event_log:
+        #        if event["event_ID"] == cmd_event_id:
+        #            event["blocked_by"] = blocked_by
+        #            break
+
+    except Exception as e:
+        _LOGGER.error(f"Error in log_command: {e}")
+
+
+
+def get_friendly_name(entity_id: str) -> str:
+    """从全局 HASS 引用中获取友好名称，支持无 HASS 时的降级处理"""
+    if not entity_id:
+        return "Unknown"
+    
+    # 1. 如果全局 HASS 引用存在，尝试从状态机获取
+    if _HASS_REF:
+        state = _HASS_REF.states.get(entity_id)
+        if state and "friendly_name" in state.attributes:
+            return state.attributes["friendly_name"]
+            
+        # 2. 尝试从 Registry 获取 (如果需要更精准，可以取消注释下面部分)
+        # from homeassistant.helpers import entity_registry as er
+        # registry = er.async_get(_HASS_REF) # 注意：在同步环境下调用 async_get 可能有风险
+        # entry = registry.async_get(entity_id)
+        # if entry and entry.name: return entry.name
+    
+    # 3. 降级处理：将 input_boolean.system_armed 变为 System Armed
+    return entity_id.split('.')[-1].replace('_', ' ').title()
+    
+
+def init_startup_log():
+    """初始化新日志会话"""
+    try:
+        # 1. 重置全局变量和状态机
+        clear_log() 
+        
+        # 2. 记录系统启动事件作为 Log 的第一条数据
+        record_event(
+            event_type=EVENT_TYPE_AGENT,
+            device="System",
+            description="Home Assistant Startup: Logging Session Started",
+            context=None,
+            action="system_init"
+        )
+    except Exception as e:
+        _LOGGER.error(f"Error initializing startup log: {e}")
\ No newline at end of file
diff -urN -x __pycache__ -x '*.pyc' /tmp/homeassistant-2024.1.5/homeassistant/helpers/script.py /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/helpers/script.py
--- /tmp/homeassistant-2024.1.5/homeassistant/helpers/script.py	2024-01-21 04:41:26.000000000 +0800
+++ /home/homeassistant/homeassistant/lib/python3.11/site-packages/homeassistant/helpers/script.py	2026-01-11 22:19:17.629147382 +0800
@@ -1,5 +1,17 @@
 """Helpers to execute scripts."""
 from __future__ import annotations
+"""from homeassistant.helpers.provenance import(
+    traceAction
+)"""
+
+import uuid
+from homeassistant.helpers.provenance import(
+    log_command,
+    get_friendly_name,
+    state_machine
+)
+
+import logging
 
 import asyncio
 from collections.abc import AsyncGenerator, Callable, Mapping, Sequence
@@ -12,7 +24,8 @@
 import itertools
 import logging
 from types import MappingProxyType
-from typing import Any, TypedDict, TypeVar, cast
+from typing import Any, TypedDict, TypeVar, cast, List, Dict  # <-- 新增 List 和 Dict 导入
+
 
 import voluptuous as vol
 
@@ -75,6 +88,7 @@
 )
 from homeassistant.util import slugify
 from homeassistant.util.dt import utcnow
+from homeassistant.util import dt as dt_util
 
 from . import condition, config_validation as cv, service, template
 from .condition import ConditionCheckerType, trace_condition_function
@@ -419,6 +433,11 @@
 
         try:
             self._log("Running %s", self._script.running_description)
+            # [lqg insert] 确保 automation_id 存在
+            if "automation_id" not in self._variables:
+                # 如果是纯 Script 调用（非 Automation），生成一个临时 ID
+                self._variables["automation_id"] = f"script_{uuid.uuid4()}"
+
             for self._step, self._action in enumerate(self._script.sequence):
                 if self._stop.is_set():
                     script_execution_set("cancelled")
@@ -681,14 +700,56 @@
         """Call the service specified in the action."""
         self._step_log("call service")
 
+
+        #lqg tag
+        """执行服务调用步骤前的验证"""
+        # 提取当前自动化ID（从变量中获取）
+        automation_id = self._variables.get("automation_id")
+        agent_event_id = self._variables.get("agent_event_id")
         params = service.async_prepare_call_from_config(
             self._hass, self._action, self._variables
         )
 
+        _LOGGER.warning(f"[服务调用] 准备调用服务: {params[CONF_DOMAIN]}.{params[CONF_SERVICE]}")
+        
+        #command = params["service"]
+        command = f"{params[CONF_DOMAIN]}.{params[CONF_SERVICE]}"  # 命令格式：域.服务（如light.turn_on）
+        target = params.get(CONF_TARGET, {})
+        device_id = "unknown"
+
+        if ATTR_ENTITY_ID in target:
+            entity_ids = target[ATTR_ENTITY_ID]
+            device_id = entity_ids[0] if (isinstance(entity_ids, list) and entity_ids) else entity_ids
+        elif ATTR_DEVICE_ID in target:
+            device_ids = target[ATTR_DEVICE_ID]
+            device_id = device_ids[0] if (isinstance(device_ids, list) and device_ids) else device_ids
+        elif ATTR_ENTITY_ID in params:
+            device_id = params[ATTR_ENTITY_ID]
+
+
+        timestamp = dt_util.utcnow()
+        _LOGGER.warning("Log Command")
+        _LOGGER.warning(command)
+        agent_event_id = self._variables.get("agent_event_id")  # 需在自动化触发时传入
+        log_command(
+            device_id=device_id,
+            command=command,
+            context=self._context,  # 传递原始Context对象，而非字典
+            source=agent_event_id,  # 关联到触发命令的Agent事件ID
+            automation_id=automation_id
+        )
+        #traceAction(command, device, self._context.as_dict(),self._variables["this"]["context"]["id"])
+        #------------------------
+        #_LOGGER.warning("service_published")
+        #_LOGGER.warning(timestamp)
+        
         # Validate response data parameters. This check ignores services that do
         # not exist which will raise an appropriate error in the service call below.
         response_variable = self._action.get(CONF_RESPONSE_VARIABLE)
         return_response = response_variable is not None
+        _LOGGER.warning(response_variable)
+
+
         if self._hass.services.has_service(params[CONF_DOMAIN], params[CONF_SERVICE]):
             supports_response = self._hass.services.supports_response(
                 params[CONF_DOMAIN], params[CONF_SERVICE]
@@ -709,7 +770,10 @@
             and params[CONF_SERVICE] == "trigger"
             or params[CONF_DOMAIN] in ("python_script", "script")
         )
+        _LOGGER.warning(running_script)
+
         trace_set_result(params=params, running_script=running_script)
+        
         response_data = await self._async_run_long_action(
             self._hass.async_create_task(
                 self._hass.services.async_call(
@@ -726,6 +790,26 @@
     async def _async_device_step(self):
         """Perform the device automation specified in the action."""
         self._step_log("device automation")
+
+        _LOGGER.warning('async_device_step')
+        #lqg tag
+        action =self._action
+        _LOGGER.warning(action)
+        command = action.get("type", "unknown.device.action")  # 设备自动化类型作为命令
+        device_id = action.get(CONF_DEVICE_ID, "")  # 提取设备ID
+        #device_name = get_friendly_name(device_id) or "unknown device"
+        # 记录设备自动化命令
+        agent_event_id = self._variables.get("agent_event_id")
+        automation_id = self._variables.get("automation_id")
+        log_command(
+            device_id=device_id,
+            command=command,
+            context=self._context,
+            source=agent_event_id,  # 补充source
+            automation_id=automation_id  # 关联自动化ID
+        )
+        #traceAction(command, device, self._context.as_dict(),self._variables["this"]["context"]["id"])
+        #------------------------
         await device_action.async_call_action_from_config(
             self._hass, self._action, self._variables, self._context
         )
@@ -1294,6 +1378,132 @@
         ):
             self._change_listener_job = HassJob(change_listener)
 
+    
+    #lqg add
+    @staticmethod
+    def _extract_commands(sequence: Sequence[dict[str, Any]]) -> List[Dict[str, Any]]:
+        """提取自动化序列中所有命令步骤，支持所有嵌套结构（if/choose/repeat/parallel等）"""
+        commands = []
+        for step in sequence:
+            # 跳过禁用的步骤
+            if not step.get(CONF_ENABLED, True):
+                continue
+                
+            action = cv.determine_script_action(step)
+            
+            # 1. 处理服务调用命令（最常见的命令类型）
+            if action == cv.SCRIPT_ACTION_CALL_SERVICE:
+                domain = step.get(CONF_DOMAIN)
+                service = step.get(CONF_SERVICE)
+                if not domain or not service:
+                    continue  # 无效的服务调用配置
+                
+                # 提取目标设备/实体（优先从target获取，再从service_data获取）
+                target = step.get(CONF_TARGET, {})
+                service_data = step.get(CONF_SERVICE_DATA, {}) or step.get(CONF_SERVICE_DATA_TEMPLATE, {})
+                device_id = ""
+                
+                # 从target中提取（适用于HA 2021.12+的target语法）
+                if ATTR_ENTITY_ID in target:
+                    entity_ids = target[ATTR_ENTITY_ID]
+                    if isinstance(entity_ids, list) and entity_ids:
+                        device_id = entity_ids[0]  # 取第一个实体
+                    elif isinstance(entity_ids, str):
+                        device_id = entity_ids
+                elif ATTR_DEVICE_ID in target:
+                    device_ids = target[ATTR_DEVICE_ID]
+                    if isinstance(device_ids, list) and device_ids:
+                        device_id = device_ids[0]  # 取第一个设备
+                    elif isinstance(device_ids, str):
+                        device_id = device_ids
+                
+                # 从service_data中提取（兼容旧版语法）
+                if not device_id and ATTR_ENTITY_ID in service_data:
+                    entity_ids = service_data[ATTR_ENTITY_ID]
+                    if isinstance(entity_ids, list) and entity_ids:
+                        device_id = entity_ids[0]
+                    elif isinstance(entity_ids, str):
+                        device_id = entity_ids
+
+                # 生成命令描述（如"turn_on" → "Turn On"）
+                description = service.replace('_', ' ').title()
+                device_name = get_friendly_name(device_id) or f"{domain}.{service}"
+                
+                commands.append({
+                    "command": f"{domain}.{service}",
+                    "device": device_name,
+                    "description": f"{domain.title()} {description}",
+                    "target_device": device_id,
+                    "step_type": "service_call"
+                })
+            
+            # 2. 处理设备自动化命令（如按钮触发的设备动作）
+            elif action == cv.SCRIPT_ACTION_DEVICE_AUTOMATION:
+                device_id = step.get(CONF_DEVICE_ID, "")
+                action_type = step.get("type", "unknown_action")
+                domain = action_type.split(".")[0] if "." in action_type else "device"
+                
+                device_name = get_friendly_name(device_id) or f"Device {device_id}"
+                commands.append({
+                    "command": action_type,
+                    "device": device_name,
+                    "description": f"Device action: {action_type}",
+                    "target_device": device_id,
+                    "step_type": "device_automation"
+                })
+            
+            # 3. 处理场景激活命令
+            elif action == cv.SCRIPT_ACTION_ACTIVATE_SCENE:
+                scene_id = step.get(CONF_SCENE, "")
+                device_name = get_friendly_name(scene_id) or f"Scene {scene_id}"
+                commands.append({
+                    "command": f"scene.turn_on",
+                    "device": device_name,
+                    "description": f"Activate scene: {scene_id}",
+                    "target_device": scene_id,
+                    "step_type": "scene"
+                })
+            
+            # 4. 递归处理嵌套结构：If-Then-Else
+            elif action == cv.SCRIPT_ACTION_IF:
+                # 处理If分支
+                if CONF_THEN in step:
+                    commands.extend(Script._extract_commands(step[CONF_THEN]))
+                # 处理Else分支
+                if CONF_ELSE in step:
+                    commands.extend(Script._extract_commands(step[CONF_ELSE]))
+            
+            # 5. 递归处理嵌套结构：Choose（多分支选择）
+            elif action == cv.SCRIPT_ACTION_CHOOSE:
+                # 处理每个选择分支
+                for choice in step.get(CONF_CHOOSE, []):
+                    if CONF_SEQUENCE in choice:
+                        commands.extend(Script._extract_commands(choice[CONF_SEQUENCE]))
+                # 处理默认分支
+                if CONF_DEFAULT in step:
+                    commands.extend(Script._extract_commands(step[CONF_DEFAULT]))
+            
+            # 6. 递归处理嵌套结构：Repeat（循环）
+            elif action == cv.SCRIPT_ACTION_REPEAT:
+                repeat_config = step.get(CONF_REPEAT, {})
+                # 处理循环体内的命令（count/while/until/for_each的循环体）
+                if CONF_SEQUENCE in repeat_config:
+                    commands.extend(Script._extract_commands(repeat_config[CONF_SEQUENCE]))
+            
+            # 7. 递归处理嵌套结构：Parallel（并行执行）
+            elif action == cv.SCRIPT_ACTION_PARALLEL:
+                # 处理每个并行分支
+                for parallel_branch in step.get(CONF_PARALLEL, []):
+                    if CONF_SEQUENCE in parallel_branch:
+                        commands.extend(Script._extract_commands(parallel_branch[CONF_SEQUENCE]))
+            
+            # 8. 其他无需处理的动作类型（如delay/wait_template等）
+            # 这些类型不产生命令，无需记录
+        
+        return commands
+
+
+
     def _set_logger(self, logger: logging.Logger | None = None) -> None:
         if logger:
             self._logger = logger
@@ -1319,15 +1529,15 @@
                 if_data["if_else"].update_logger(self._logger)
 
     def _changed(self) -> None:
-        if self._change_listener_job:
-            self._hass.async_run_hass_job(self._change_listener_job)
+            if self._change_listener_job:
+                self._hass.async_run_hass_job(self._change_listener_job)
 
     @callback
     def _chain_change_listener(self, sub_script: Script) -> None:
         if sub_script.is_running:
             self.last_action = sub_script.last_action
             self._changed()
-
+        
     @property
     def is_running(self) -> bool:
         """Return true if script is on."""
@@ -1356,7 +1566,7 @@
     @staticmethod
     def _find_referenced_areas(
         referenced: set[str], sequence: Sequence[dict[str, Any]]
-    ) -> None:
+        ) -> None:
         for step in sequence:
             action = cv.determine_script_action(step)
 
@@ -1365,7 +1575,7 @@
                     step.get(CONF_TARGET),
                     step.get(CONF_SERVICE_DATA),
                     step.get(CONF_SERVICE_DATA_TEMPLATE),
-                ):
+                    ):
                     _referenced_extract_ids(data, ATTR_AREA_ID, referenced)
 
             elif action == cv.SCRIPT_ACTION_CHOOSE:
@@ -1403,10 +1613,9 @@
             if action == cv.SCRIPT_ACTION_CALL_SERVICE:
                 for data in (
                     step.get(CONF_TARGET),
-                    step.get(CONF_SERVICE_DATA),
-                    step.get(CONF_SERVICE_DATA_TEMPLATE),
+                    step.get(CONF_SERVICE_DATA),                        step.get(CONF_SERVICE_DATA_TEMPLATE),
                 ):
-                    _referenced_extract_ids(data, ATTR_DEVICE_ID, referenced)
+                     _referenced_extract_ids(data, ATTR_DEVICE_ID, referenced)
 
             elif action == cv.SCRIPT_ACTION_CHECK_CONDITION:
                 referenced |= condition.async_extract_devices(step)
@@ -1490,7 +1699,7 @@
         """Run script."""
         asyncio.run_coroutine_threadsafe(
             self.async_run(variables, context), self._hass.loop
-        ).result()
+            ).result()
 
     async def async_run(
         self,
@@ -1592,7 +1801,7 @@
 
     async def _async_stop(
         self, aws: list[asyncio.Task], update_state: bool, spare: _ScriptRun | None
-    ) -> None:
+        ) -> None:
         await asyncio.wait(aws)
         if update_state:
             self._changed()
@@ -1644,85 +1853,71 @@
             self._repeat_script[step] = sub_script
         return sub_script
 
-    async def _async_prep_choose_data(self, step: int) -> _ChooseData:
-        action = self.sequence[step]
-        step_name = action.get(CONF_ALIAS, f"Choose at step {step+1}")
-        choices = []
-        for idx, choice in enumerate(action[CONF_CHOOSE], start=1):
-            conditions = [
-                await self._async_get_condition(config)
-                for config in choice.get(CONF_CONDITIONS, [])
-            ]
-            choice_name = choice.get(CONF_ALIAS, f"choice {idx}")
-            sub_script = Script(
-                self._hass,
-                choice[CONF_SEQUENCE],
-                f"{self.name}: {step_name}: {choice_name}",
-                self.domain,
-                running_description=self.running_description,
-                script_mode=SCRIPT_MODE_PARALLEL,
-                max_runs=self.max_runs,
-                logger=self._logger,
-                top_level=False,
-            )
-            sub_script.change_listener = partial(
-                self._chain_change_listener, sub_script
-            )
-            choices.append((conditions, sub_script))
-
-        default_script: Script | None
-        if CONF_DEFAULT in action:
-            default_script = Script(
-                self._hass,
-                action[CONF_DEFAULT],
-                f"{self.name}: {step_name}: default",
-                self.domain,
-                running_description=self.running_description,
-                script_mode=SCRIPT_MODE_PARALLEL,
-                max_runs=self.max_runs,
-                logger=self._logger,
-                top_level=False,
-            )
-            default_script.change_listener = partial(
-                self._chain_change_listener, default_script
-            )
-        else:
-            default_script = None
-
-        return {"choices": choices, "default": default_script}
+        async def _async_prep_choose_data(self, step: int) -> _ChooseData:
+            action = self.sequence[step]
+            step_name = action.get(CONF_ALIAS, f"Choose at step {step+1}")
+            choices = []
+            for idx, choice in enumerate(action[CONF_CHOOSE], start=1):
+                conditions = [
+                    await self._async_get_condition(config)
+                    for config in choice.get(CONF_CONDITIONS, [])
+                ]
+                choice_name = choice.get(CONF_ALIAS, f"choice {idx}")
+                sub_script = Script(
+                    self._hass,
+                    choice[CONF_SEQUENCE],
+                    f"{self.name}: {step_name}: {choice_name}",
+                    self.domain,
+                    running_description=self.running_description,
+                    script_mode=SCRIPT_MODE_PARALLEL,
+                    max_runs=self.max_runs,
+                    logger=self._logger,
+                    top_level=False,
+                )
+                sub_script.change_listener = partial(
+                    self._chain_change_listener, sub_script
+                )
+                choices.append((conditions, sub_script))
 
-    async def _async_get_choose_data(self, step: int) -> _ChooseData:
-        if not (choose_data := self._choose_data.get(step)):
-            choose_data = await self._async_prep_choose_data(step)
-            self._choose_data[step] = choose_data
-        return choose_data
+            default_script: Script | None
+            if CONF_DEFAULT in action:
+                default_script = Script(
+                    self._hass,
+                    action[CONF_DEFAULT],
+                    f"{self.name}: {step_name}: default",
+                    self.domain,
+                    running_description=self.running_description,
+                    script_mode=SCRIPT_MODE_PARALLEL,
+                    max_runs=self.max_runs,
+                    logger=self._logger,
+                    top_level=False,
+                )
+                default_script.change_listener = partial(
+                    self._chain_change_listener, default_script
+                )
+            else:
+                default_script = None
 
-    async def _async_prep_if_data(self, step: int) -> _IfData:
-        """Prepare data for an if statement."""
-        action = self.sequence[step]
-        step_name = action.get(CONF_ALIAS, f"If at step {step+1}")
+            return {"choices": choices, "default": default_script}
 
-        conditions = [
-            await self._async_get_condition(config) for config in action[CONF_IF]
-        ]
+        async def _async_get_choose_data(self, step: int) -> _ChooseData:
+            if not (choose_data := self._choose_data.get(step)):
+                choose_data = await self._async_prep_choose_data(step)
+                self._choose_data[step] = choose_data
+            return choose_data
+
+        async def _async_prep_if_data(self, step: int) -> _IfData:
+            """Prepare data for an if statement."""
+            action = self.sequence[step]
+            step_name = action.get(CONF_ALIAS, f"If at step {step+1}")
 
-        then_script = Script(
-            self._hass,
-            action[CONF_THEN],
-            f"{self.name}: {step_name}",
-            self.domain,
-            running_description=self.running_description,
-            script_mode=SCRIPT_MODE_PARALLEL,
-            max_runs=self.max_runs,
-            logger=self._logger,
-            top_level=False,
-        )
-        then_script.change_listener = partial(self._chain_change_listener, then_script)
+            conditions = [
+                await self._async_get_condition(config) for config in action[CONF_IF]
+            ]
 
-        if CONF_ELSE in action:
-            else_script = Script(
+            then_script = Script(
                 self._hass,
-                action[CONF_ELSE],
+                action[CONF_THEN],
                 f"{self.name}: {step_name}",
                 self.domain,
                 running_description=self.running_description,
@@ -1731,17 +1926,31 @@
                 logger=self._logger,
                 top_level=False,
             )
-            else_script.change_listener = partial(
-                self._chain_change_listener, else_script
-            )
-        else:
-            else_script = None
+            then_script.change_listener = partial(self._chain_change_listener, then_script)
 
-        return _IfData(
-            if_conditions=conditions,
-            if_then=then_script,
-            if_else=else_script,
-        )
+            if CONF_ELSE in action:
+                else_script = Script(
+                    self._hass,
+                    action[CONF_ELSE],
+                    f"{self.name}: {step_name}",
+                    self.domain,
+                    running_description=self.running_description,
+                    script_mode=SCRIPT_MODE_PARALLEL,
+                    max_runs=self.max_runs,
+                    logger=self._logger,
+                    top_level=False,
+                )
+                else_script.change_listener = partial(
+                    self._chain_change_listener, else_script
+                )
+            else:
+                else_script = None
+
+            return _IfData(
+                if_conditions=conditions,
+                if_then=then_script,
+                if_else=else_script,
+            )
 
     async def _async_get_if_data(self, step: int) -> _IfData:
         if not (if_data := self._if_data.get(step)):
